# Модуль для работы с провайдером DeepAI
## Обзор

Модуль `DeepAi.py` предназначен для взаимодействия с сервисом DeepAI для создания чат-ботов. Он предоставляет функцию `_create_completion`, которая отправляет запросы к API DeepAI и возвращает ответы в потоковом режиме. Модуль использует библиотеку `requests` для отправки HTTP-запросов и `hashlib` для генерации MD5-хешей.

## Подробней

Этот модуль является частью проекта `hypotez` и используется для интеграции с сервисом DeepAI. Он позволяет отправлять сообщения в чат-бот DeepAI и получать ответы в режиме реального времени. Модуль использует уникальный API-ключ, который генерируется на основе User-Agent пользователя, для аутентификации запросов.

## Функции

### `_create_completion`

```python
def _create_completion(model: str, messages: list, stream: bool, **kwargs):
    """
    Создает запрос к API DeepAI и возвращает ответы в потоковом режиме.

    Args:
        model (str): Идентификатор модели, используемой для генерации ответа.
        messages (list): Список сообщений в формате истории чата.
        stream (bool): Флаг, указывающий, следует ли возвращать ответ в потоковом режиме.
        **kwargs: Дополнительные аргументы.

    Returns:
        Generator[str, None, None]: Генератор строк, содержащих части ответа от API DeepAI.

    Raises:
        requests.exceptions.HTTPError: Если возникает HTTP-ошибка при запросе к API.

    """
```

**Как работает функция**:

1.  Функция принимает параметры `model` (идентификатор модели), `messages` (история чата), `stream` (флаг потоковой передачи) и `kwargs` (дополнительные аргументы).
2.  Внутри функции определена вложенная функция `md5`, которая генерирует MD5-хеш для переданного текста.
3.  Также определена вложенная функция `get_api_key`, которая генерирует API-ключ на основе User-Agent пользователя.
4.  Формируются заголовки запроса, включающие API-ключ и User-Agent.
5.  Формируются файлы для отправки в теле запроса, включающие стиль чата и историю сообщений в формате JSON.
6.  Отправляется POST-запрос к API DeepAI по адресу `"https://api.deepai.org/chat_response"` с использованием библиотеки `requests`.
7.  Функция возвращает генератор, который итерируется по содержимому ответа от API DeepAI, декодирует каждый чанк и возвращает его.
8.  Если во время запроса возникает HTTP-ошибка, функция вызывает исключение `requests.exceptions.HTTPError`.

**Внутренние функции**:

#### `md5`

```python
def md5(text: str) -> str:
    """
    Генерирует MD5-хеш для переданного текста.

    Args:
        text (str): Текст, для которого необходимо сгенерировать хеш.

    Returns:
        str: MD5-хеш текста в виде строки.

    """
```

**Как работает функция**:

1.  Функция `md5` принимает строку `text` в качестве аргумента.
2.  Она кодирует строку в байты, используя кодировку UTF-8.
3.  Затем она вычисляет MD5-хеш этих байтов с помощью функции `hashlib.md5`.
4.  Результат преобразуется в шестнадцатеричное представление с помощью метода `hexdigest()`.
5.  Полученная строка разворачивается в обратном порядке с помощью среза `[::-1]`.
6.  Функция возвращает полученный MD5-хеш в виде строки.

#### `get_api_key`

```python
def get_api_key(user_agent: str) -> str:
    """
    Генерирует API-ключ на основе User-Agent пользователя.

    Args:
        user_agent (str): User-Agent пользователя.

    Returns:
        str: Сгенерированный API-ключ.

    """
```

**Как работает функция**:

1.  Функция `get_api_key` принимает строку `user_agent` в качестве аргумента.
2.  Она генерирует случайное число в диапазоне от 0 до 10^11 и преобразует его в строку `part1`.
3.  Затем она вычисляет MD5-хеш строки, состоящей из `user_agent`, MD5-хеша `user_agent`, MD5-хеша `user_agent`, `part1` и строки `"x"`.
4.  Результат сохраняется в переменной `part2`.
5.  Функция формирует API-ключ, объединяя строку `"tryit-"`, `part1` и `part2`.
6.  Функция возвращает полученный API-ключ.

**Примеры**:

```python
# Пример вызова функции _create_completion
model = "gpt-3.5-turbo"
messages = [{"role": "user", "content": "Hello, how are you?"}]
stream = True
for chunk in _create_completion(model=model, messages=messages, stream=stream):
    print(chunk, end="")

# Пример вызова функции _create_completion без потоковой передачи
model = "gpt-3.5-turbo"
messages = [{"role": "user", "content": "Hello, how are you?"}]
stream = False
try:
    for chunk in _create_completion(model=model, messages=messages, stream=stream):
        print(chunk, end="")
except Exception as ex:
    print(f"Error: {ex}")
```

## Переменные

-   `url` (str): URL-адрес API DeepAI.
-   `model` (list): Список поддерживаемых моделей.
-   `supports_stream` (bool): Флаг, указывающий, поддерживает ли провайдер потоковую передачу.
-   `needs_auth` (bool): Флаг, указывающий, требуется ли аутентификация.
-    `params` (str): Строка, содержащая информацию о поддерживаемых типах параметров функции `_create_completion`.

```python
params = f'g4f.Providers.{os.path.basename(__file__)[:-3]} supports: \' + \\\n    \'(%s)\' % \', \'.join(\n        [f"{name}: {get_type_hints(_create_completion)[name].__name__}" for name in _create_completion.__code__.co_varnames[:_create_completion.__code__.co_argcount]])
```

**Как работает**:

1.  Получает имя файла текущего модуля, удаляя расширение `.py`.
2.  Формирует строку с информацией о поддерживаемых типах параметров функции `_create_completion`.
3.  Использует `get_type_hints` для получения аннотаций типов параметров.
4.  Объединяет информацию в строку, которая показывает имя параметра и его тип.