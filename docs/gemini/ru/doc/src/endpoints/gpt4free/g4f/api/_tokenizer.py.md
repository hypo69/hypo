# Модуль для токенизации текста

## Обзор

Модуль предназначен для токенизации текста с использованием библиотеки `tiktoken`. Он позволяет подсчитывать количество токенов в тексте, что полезно для оценки стоимости запросов к моделям GPT.

## Подробнее

Этот модуль предоставляет функцию `tokenize`, которая принимает текст и название модели GPT в качестве аргументов. Функция возвращает количество токенов и закодированный текст. Токенизация важна для определения стоимости запросов к моделям GPT, так как стоимость часто зависит от количества токенов.

## Функции

### `tokenize`

```python
# def tokenize(text: str, model: str = 'gpt-3.5-turbo') -> Union[int, str]:
#     encoding   = tiktoken.encoding_for_model(model)
#     encoded    = encoding.encode(text)
#     num_tokens = len(encoded)
    
#     return num_tokens, encoded
```

**Назначение**: Токенизация текста с использованием библиотеки `tiktoken` и определение количества токенов.

**Параметры**:
- `text` (str): Текст для токенизации.
- `model` (str): Название модели GPT для использования (по умолчанию `'gpt-3.5-turbo'`).

**Возвращает**:
- `Union[int, str]`: Количество токенов и закодированный текст.

**Как работает функция**:

1. **Определение кодировки**: Функция определяет кодировку, соответствующую указанной модели GPT.
2. **Кодирование текста**: Текст кодируется с использованием определенной кодировки.
3. **Подсчет токенов**: Вычисляется количество токенов в закодированном тексте.
4. **Возврат результата**: Функция возвращает количество токенов и закодированный текст.

**Примеры**:

```python
# from typing import Union
# text = "Пример текста для токенизации."
# model = "gpt-3.5-turbo"
# num_tokens, encoded = tokenize(text, model)
# print(f"Количество токенов: {num_tokens}")
# print(f"Закодированный текст: {encoded}")
```

ASCII flowchart:

```
  Начало
     ↓
Определение кодировки для модели GPT
     ↓
Кодирование текста с использованием кодировки
     ↓
Подсчет количества токенов в закодированном тексте
     ↓
  Возврат количества токенов и закодированного текста
     ↓
    Конец