# Модуль для интеграции с Google Gemini AI
=================================================

Модуль содержит класс :class:`GoogleGenerativeAI`, который используется для взаимодействия с различными моделями Google Generative AI.

Пример использования
----------------------

```python
>>> ai = GoogleGenerativeAI(api_key="YOUR_API_KEY")
>>> response = ai.ask("Как дела?")
>>> print(response)
'У меня все хорошо, спасибо!'
```

## Оглавление

- [Обзор](#обзор)
- [Подробнее](#подробнее)
- [Классы](#классы)
    - [Config](#config)
    - [GoogleGenerativeAI](#googlegenerativeai)
        - [__post_init__](#__post_init__)
        - [normalize_answer](#normalize_answer)
        - [_start_chat](#_start_chat)
        - [clear_history](#clear_history)
        - [_save_chat_history](#_save_chat_history)
        - [_load_chat_history](#_load_chat_history)
        - [chat](#chat)
        - [ask](#ask)
        - [ask_async](#ask_async)
        - [describe_image](#describe_image)
        - [upload_file](#upload_file)
- [Функции](#функции)
    - [main](#main)

## Обзор

Модуль `gemini.py` предназначен для интеграции с сервисами Google Generative AI. Он предоставляет класс `GoogleGenerativeAI`, который позволяет взаимодействовать с моделями Gemini для генерации контента, ведения диалогов и обработки изображений. Модуль включает в себя функциональность для настройки моделей, управления историей чата и обработки различных ошибок API.

## Подробнее

Этот модуль обеспечивает удобный интерфейс для работы с моделями Google Gemini, абстрагируя сложности, связанные с аутентификацией, обработкой ошибок и управлением историей диалогов. Он позволяет пользователям легко интегрировать возможности генеративного ИИ в свои приложения, поддерживая как синхронные, так и асинхронные вызовы API.

## Классы

### `Config`
Описание отсутствует.

### `GoogleGenerativeAI`

**Описание**: Класс `GoogleGenerativeAI` предназначен для взаимодействия с моделями Google Generative AI.

**Принцип работы**: Класс инициализируется с использованием ключа API, имени модели и конфигурации генерации. Он позволяет отправлять запросы к модели, управлять историей чата и обрабатывать ответы. Класс поддерживает различные режимы управления историей чата, включая сохранение, очистку и загрузку из файла.

**Аттрибуты**:
- `api_key` (str): Ключ API для доступа к сервисам Google Generative AI.
- `model_name` (str): Имя используемой модели Gemini. По умолчанию "gemini-2.0-flash-exp".
- `dialogue_txt_path` (Path): Путь к файлу для записи логов диалогов.
- `generation_config` (Dict): Конфигурация генерации, определяющая параметры ответа, такие как `response_mime_type`. По умолчанию {"response_mime_type": "text/plain"}.
- `system_instruction` (Optional[str]): Системная инструкция для модели, задающая контекст и поведение. По умолчанию `None`.
- `history_dir` (Path): Путь к директории для хранения истории чата.
- `history_txt_file` (Path): Путь к файлу для хранения истории чата в текстовом формате.
- `history_json_file` (Path): Путь к файлу для хранения истории чата в формате JSON.
- `config` (SimpleNamespace): Конфигурация, загруженная из файла `gemini.json`.
- `chat_history` (List[Dict]): Список словарей, представляющих историю чата.
- `model` (Any): Объект модели, инициализированный с использованием `google.generativeai`.
- `_chat` (Any): Объект чата, используемый для ведения диалога с моделью.
- `MODELS` (List[str]): Список поддерживаемых моделей Gemini.

#### `__post_init__`

```python
def __post_init__(self):
    """Инициализация модели GoogleGenerativeAI с дополнительными настройками."""
    ...
```

**Назначение**: Инициализация модели `GoogleGenerativeAI` с дополнительными настройками, такими как загрузка конфигурации, определение путей к файлам истории и инициализация модели Gemini.

**Как работает функция**:

1.  **Загрузка конфигурации**: Загружает конфигурацию из файла `gemini.json` с использованием функции `j_loads_ns`.

2.  **Определение путей к файлам истории**: Формирует пути к директории истории и файлам истории (`.txt` и `.json`).

3.  **Инициализация модели**:
    *   Настраивает API-ключ для `google.generativeai`.
    *   Инициализирует модель `GenerativeModel` с указанным именем модели, конфигурацией генерации и системной инструкцией.
    *   Запускает чат с использованием метода `_start_chat`.

**ASCII flowchart**:

```
[Загрузка конфигурации из gemini.json]
    ↓
[Определение путей к файлам истории]
    ↓
[Настройка API-ключа]
    ↓
[Инициализация GenerativeModel]
    ↓
[Запуск чата через _start_chat()]
```

#### `normalize_answer`

```python
def normalize_answer(self, text: str) -> str:
    """Очистка вывода от 
    ```md, ```python, ```json, ```html, ит.п.
    """
    ...
```

**Назначение**: Очищает текстовый вывод модели от различных артефактов, таких как Markdown, Python, JSON и HTML разметка.

**Параметры**:
- `text` (str): Текст для очистки.

**Возвращает**:
- `str`: Очищенный текст.

**Как работает функция**:

1.  **Вызов функции `normalize_answer`**: Использует функцию `normalize_answer` из модуля `src.utils.string.ai_string_normalizer` для очистки текста.

**ASCII flowchart**:

```
[Получение текста]
    ↓
[Очистка текста через normalize_answer()]
    ↓
[Возврат очищенного текста]
```

#### `_start_chat`

```python
def _start_chat(self):
    """Запуск чата с начальной настройкой."""
    ...
```

**Назначение**: Запускает чат с моделью Gemini и устанавливает начальную системную инструкцию, если она предоставлена.

**Возвращает**:
-   `Any`: Объект чата, созданный с использованием `model.start_chat`.

**Как работает функция**:

1.  **Проверка наличия системной инструкции**: Проверяет, задана ли системная инструкция (`self.system_instruction`).
2.  **Запуск чата с системной инструкцией**: Если системная инструкция задана, запускает чат с этой инструкцией в качестве начального сообщения.
3.  **Запуск чата без системной инструкции**: Если системная инструкция не задана, запускает чат без начальных сообщений.

**ASCII flowchart**:

```
[Проверка наличия системной инструкции]
    ↓
[Если есть инструкция] --> [Запуск чата с системной инструкцией]
    ↓
[Если нет инструкции] --> [Запуск чата без инструкции]
    ↓
[Возврат объекта чата]
```

#### `clear_history`

```python
def clear_history(self):
    """
    Очищает историю чата в памяти и удаляет файл истории, если он существует.
    """
    ...
```

**Назначение**: Очищает историю чата, хранящуюся в памяти, и удаляет файл истории чата, если он существует.

**Как работает функция**:

1.  **Очистка истории в памяти**: Устанавливает `self.chat_history` в пустой список, очищая историю чата, хранящуюся в памяти.
2.  **Удаление файла истории**:
    *   Проверяет, существует ли файл истории (`self.history_json_file`).
    *   Если файл существует, удаляет его с использованием `self.history_json_file.unlink()`.
    *   Логирует информацию об удалении файла.
3.  **Обработка исключений**: В случае возникновения ошибки при очистке истории чата, логирует ошибку с использованием `logger.error`.

**ASCII flowchart**:

```
[Очистка истории чата в памяти]
    ↓
[Проверка существования файла истории]
    ↓
[Если файл существует] --> [Удаление файла истории] --> [Логирование информации об удалении]
    ↓
[Обработка исключений: Логирование ошибки при очистке истории чата]
```

#### `_save_chat_history`

```python
async def _save_chat_history(self, chat_data_folder: Optional[str | Path]):
    """Сохраняет всю историю чата в JSON файл"""
    ...
```

**Назначение**: Сохраняет историю чата в формате JSON в указанную папку.

**Параметры**:
- `chat_data_folder` (Optional[str | Path]): Папка для сохранения истории чата.

**Как работает функция**:

1.  **Определение файла истории**: Если указана папка `chat_data_folder`, формирует путь к файлу истории (`history.json`) в этой папке.
2.  **Сохранение истории чата**: Если история чата (`self.chat_history`) не пуста, сохраняет её в JSON файл с использованием функции `j_dumps`.

**ASCII flowchart**:

```
[Проверка наличия chat_data_folder]
    ↓
[Если есть папка] --> [Определение пути к файлу истории]
    ↓
[Проверка, не пуста ли история чата]
    ↓
[Если история не пуста] --> [Сохранение истории чата в JSON файл]
```

#### `_load_chat_history`

```python
async def _load_chat_history(self, chat_data_folder: Optional[str | Path]):
    """Загружает историю чата из JSON файла"""
    ...
```

**Назначение**: Загружает историю чата из JSON-файла, если он существует, и восстанавливает состояние чата.

**Параметры**:
- `chat_data_folder` (Optional[str | Path]): Путь к папке, содержащей файл истории чата.

**Как работает функция**:

1.  **Определение файла истории**: Если указана папка `chat_data_folder`, формирует путь к файлу истории (`history.json`) в этой папке.
2.  **Проверка существования файла истории**: Проверяет, существует ли файл истории (`self.history_json_file`).
3.  **Загрузка истории чата**: Если файл существует, загружает историю чата из JSON файла с использованием функции `j_loads`.
4.  **Восстановление состояния чата**:
    *   Запускает новый чат с использованием метода `_start_chat`.
    *   Добавляет записи из загруженной истории в текущий чат (`self._chat.history`).
    *   Логирует информацию о загрузке истории чата.
5.  **Обработка исключений**: В случае возникновения ошибки при загрузке истории чата, логирует ошибку с использованием `logger.error`.

**ASCII flowchart**:

```
[Проверка наличия chat_data_folder]
    ↓
[Если есть папка] --> [Определение пути к файлу истории]
    ↓
[Проверка существования файла истории]
    ↓
[Если файл существует] --> [Загрузка истории чата из JSON файла]
    ↓
[Восстановление состояния чата: Запуск нового чата, добавление записей из истории]
    ↓
[Обработка исключений: Логирование ошибки при загрузке истории чата]
```

#### `chat`

```python
async def chat(self, q: str, chat_data_folder: Optional[str | Path], flag: str = "save_chat") -> Optional[str]:
    """
    Обрабатывает чат-запрос с различными режимами управления историей чата.

    Args:
        q (str): Вопрос пользователя.
        chat_data_folder (Optional[str | Path]): Папка для хранения истории чата.
        flag (str): Режим управления историей. Возможные значения: 
                    "save_chat", "read_and_clear", "clear", "start_new".

    Returns:
        Optional[str]: Ответ модели.
    """
    ...
```

**Назначение**: Обрабатывает чат-запрос пользователя, управляет историей чата в зависимости от флага и возвращает ответ модели.

**Параметры**:
- `q` (str): Вопрос пользователя.
- `chat_data_folder` (Optional[str | Path]): Папка для хранения истории чата.
- `flag` (str): Режим управления историей чата. Возможные значения: "save_chat", "read_and_clear", "clear", "start_new".

**Возвращает**:
- `Optional[str]`: Ответ модели или `None` в случае ошибки.

**Как работает функция**:

1.  **Управление историей чата**:
    *   В зависимости от значения флага (`flag`) выполняет различные действия с историей чата:
        *   `"save_chat"`: Загружает историю чата из файла.
        *   `"read_and_clear"`: Загружает историю чата из файла и очищает текущую историю.
        *   `"read_and_start_new"`: Загружает историю чата из файла, очищает текущую историю и устанавливает флаг в "start_new".
        *   `"clear"`: Очищает текущую историю чата.
        *   `"start_new"`: Сохраняет текущую историю в архивный файл и начинает новую историю.
2.  **Отправка запроса модели**: Отправляет вопрос пользователя (`q`) модели с использованием метода `_chat.send_message_async`.
3.  **Обработка ответа**:
    *   Если получен ответ от модели и текст ответа не пустой, добавляет вопрос пользователя и ответ модели в историю чата.
    *   Сохраняет историю чата в файл.
    *   Возвращает текст ответа модели.
4.  **Обработка ошибок**: В случае возникновения ошибки при отправке запроса или обработке ответа, логирует ошибку и возвращает `None`.
5.  **Сохранение истории чата**: В блоке `finally`, если флаг равен `"save_chat"`, сохраняет историю чата в файл.

**ASCII flowchart**:

```
[Управление историей чата (в зависимости от значения flag)]
    ↓
[Отправка запроса модели через _chat.send_message_async(q)]
    ↓
[Если получен ответ и текст ответа не пустой] --> [Добавление вопроса и ответа в историю чата]
    ↓
[Сохранение истории чата в файл]
    ↓
[Возврат текста ответа]
    ↓
[Обработка ошибок: Логирование ошибки и возврат None]
    ↓
[Если flag == "save_chat"] --> [Сохранение истории чата в файл]
```

**Примеры**:

```python
# Пример использования с сохранением истории чата
response = await ai.chat("Привет, как дела?", chat_data_folder="/path/to/chat_data", flag="save_chat")

# Пример использования с чтением и очисткой истории чата
response = await ai.chat("Привет, как дела?", chat_data_folder="/path/to/chat_data", flag="read_and_clear")

# Пример использования с очисткой истории чата
response = await ai.chat("Привет, как дела?", chat_data_folder="/path/to/chat_data", flag="clear")

# Пример использования с началом новой истории чата
response = await ai.chat("Привет, как дела?", chat_data_folder="/path/to/chat_data", flag="start_new")
```

#### `ask`

```python
def ask(self, q: str, attempts: int = 15, save_history:bool = False, clean_response:bool = True) -> Optional[str]:
    """
    Метод отправляет текстовый запрос модели и возвращает ответ.
    """
    ...
```

**Назначение**: Отправляет текстовый запрос модели Gemini и возвращает ответ, выполняя несколько попыток в случае неудачи.

**Параметры**:
- `q` (str): Текстовый запрос.
- `attempts` (int): Количество попыток отправки запроса. По умолчанию 15.
- `save_history` (bool): Флаг, указывающий, нужно ли сохранять диалог. По умолчанию `False`.
- `clean_response` (bool): Флаг, указывающий, нужно ли очищать ответ от лишних символов. По умолчанию `True`.

**Возвращает**:
- `Optional[str]`: Ответ модели или `None` в случае неудачи после всех попыток.

**Как работает функция**:

1.  **Цикл попыток**: Выполняет цикл `attempts` раз для отправки запроса.
2.  **Отправка запроса**: Отправляет запрос `q` модели с использованием метода `self.model.generate_content(q)`.
3.  **Проверка ответа**: Проверяет, получен ли ответ от модели и не пустой ли текст ответа.
4.  **Сохранение диалога**: Если `save_history` равен `True`, сохраняет запрос и ответ в историю диалога с использованием метода `self._save_dialogue`.
5.  **Очистка ответа**: Если `clean_response` равен `True`, очищает ответ от лишних символов с использованием метода `self.normalize_answer`.
6.  **Обработка исключений**:
    *   Обрабатывает исключения, такие как `requests.exceptions.RequestException`, `GatewayTimeout`, `ServiceUnavailable`, `ResourceExhausted`, `DefaultCredentialsError`, `RefreshError`, `ValueError`, `TypeError`, `InvalidArgument`, `RpcError` и `Exception`.
    *   В случае ошибки логирует информацию об ошибке и выполняет задержку перед следующей попыткой.
7.  **Возврат ответа**: Возвращает ответ модели, если он получен, или `None` в случае неудачи после всех попыток.

**ASCII flowchart**:

```
[Цикл попыток (attempts раз)]
    ↓
[Отправка запроса: response = self.model.generate_content(q)]
    ↓
[Проверка ответа: if not response.text]
    ↓
[Если ответ пустой] --> [Логирование и ожидание] --> [Следующая попытка]
    ↓
[Если save_history] --> [Сохранение диалога: self._save_dialogue]
    ↓
[Если clean_response] --> [Очистка ответа: self.normalize_answer]
    ↓
[Возврат ответа]
    ↓
[Обработка исключений (разные типы)]
    ↓
[Возврат None после всех попыток]
```

**Примеры**:

```python
# Пример использования с очисткой ответа
response = ai.ask("Расскажи о Python")

# Пример использования без очистки ответа
response = ai.ask("Расскажи о Python", clean_response=False)

# Пример использования с сохранением истории
response = ai.ask("Расскажи о Python", save_history=True)

# Пример использования с указанием количества попыток
response = ai.ask("Расскажи о Python", attempts=5)
```

#### `ask_async`

```python
async def ask_async(self, q: str, attempts: int = 15, save_history: bool = False, clean_response:bool = True) -> Optional[str]:
    """
    Метод асинхронно отправляет текстовый запрос модели и возвращает ответ.
    """
    ...
```

**Назначение**: Асинхронно отправляет текстовый запрос модели Gemini и возвращает ответ, выполняя несколько попыток в случае неудачи.

**Параметры**:
- `q` (str): Текстовый запрос.
- `attempts` (int): Количество попыток отправки запроса. По умолчанию 15.
- `save_history` (bool): Флаг, указывающий, нужно ли сохранять диалог. По умолчанию `False`.
- `clean_response` (bool): Флаг, указывающий, нужно ли очищать ответ от лишних символов. По умолчанию `True`.

**Возвращает**:
- `Optional[str]`: Ответ модели или `None` в случае неудачи после всех попыток.

**Как работает функция**:

1.  **Цикл попыток**: Выполняет цикл `attempts` раз для отправки запроса.
2.  **Отправка запроса**: Отправляет запрос `q` модели асинхронно с использованием `asyncio.to_thread(self.model.generate_content, q)`.
3.  **Проверка ответа**: Проверяет, получен ли ответ от модели и не пустой ли текст ответа.
4.  **Сохранение диалога**: Если `save_history` равен `True`, сохраняет запрос и ответ в историю диалога с использованием метода `self._save_dialogue`.
5.  **Очистка ответа**: Если `clean_response` равен `True`, очищает ответ от лишних символов с использованием метода `self.normalize_answer`.
6.  **Обработка исключений**:
    *   Обрабатывает исключения, такие как `requests.exceptions.RequestException`, `GatewayTimeout`, `ServiceUnavailable`, `ResourceExhausted`, `DefaultCredentialsError`, `RefreshError`, `ValueError`, `TypeError`, `InvalidArgument`, `RpcError` и `Exception`.
    *   В случае ошибки логирует информацию об ошибке и выполняет асинхронную задержку перед следующей попыткой с использованием `asyncio.sleep`.
7.  **Возврат ответа**: Возвращает ответ модели, если он получен, или `None` в случае неудачи после всех попыток.

**ASCII flowchart**:

```
[Цикл попыток (attempts раз)]
    ↓
[Отправка асинхронного запроса: response = await asyncio.to_thread(self.model.generate_content, q)]
    ↓
[Проверка ответа: if not response.text]
    ↓
[Если ответ пустой] --> [Логирование и асинхронное ожидание] --> [Следующая попытка]
    ↓
[Если save_history] --> [Сохранение диалога: self._save_dialogue]
    ↓
[Если clean_response] --> [Очистка ответа: self.normalize_answer]
    ↓
[Возврат ответа]
    ↓
[Обработка исключений (разные типы)]
    ↓
[Возврат None после всех попыток]
```

**Примеры**:

```python
# Пример асинхронного использования с очисткой ответа
response = await ai.ask_async("Расскажи о Python")

# Пример асинхронного использования без очистки ответа
response = await ai.ask_async("Расскажи о Python", clean_response=False)

# Пример асинхронного использования с сохранением истории
response = await ai.ask_async("Расскажи о Python", save_history=True)

# Пример асинхронного использования с указанием количества попыток
response = await ai.ask_async("Расскажи о Python", attempts=5)
```

#### `describe_image`

```python
def describe_image(
    self, image: Path | bytes, mime_type: Optional[str] = 'image/jpeg', prompt: Optional[str] = ''
) -> Optional[str]:
    """
    Отправляет изображение в Gemini Pro Vision и возвращает его текстовое описание.

    Args:
        image: Путь к файлу изображения или байты изображения

    Returns:
        str: Текстовое описание изображения.
        None: Если произошла ошибка.
    """
    ...
```

**Назначение**: Отправляет изображение в Gemini Pro Vision для получения его текстового описания.

**Параметры**:
- `image` (Path | bytes): Путь к файлу изображения или байты изображения.
- `mime_type` (Optional[str]): MIME-тип изображения. По умолчанию 'image/jpeg'.
- `prompt` (Optional[str]): Дополнительный текстовый запрос для описания изображения. По умолчанию пустая строка.

**Возвращает**:
- `Optional[str]`: Текстовое описание изображения или `None` в случае ошибки.

**Как работает функция**:

1.  **Подготовка контента для запроса**:
    *   Если `image` является путем к файлу, считывает байты изображения с использованием функции `get_image_bytes`.
    *   Формирует структуру контента для запроса, включающую MIME-тип и данные изображения.
2.  **Отправка запроса и получение ответа**:
    *   Измеряет время выполнения запроса.
    *   Отправляет запрос модели с использованием метода `self.model.generate_content`.
3.  **Обработка ошибок**:
    *   Обрабатывает исключения, такие как `DefaultCredentialsError`, `InvalidArgument`, `RpcError`, `RetryError` и `Exception`.
    *   В случае ошибки логирует информацию об ошибке и возвращает `None`.
4.  **Возврат описания**:
    *   Если получен ответ и текст ответа не пустой, возвращает текст ответа.
    *   Если текст ответа пустой, логирует информацию и возвращает `None`.

**ASCII flowchart**:

```
[Подготовка контента для запроса]
    ↓
[Отправка запроса модели]
    ↓
[Обработка ошибок]
    ↓
[Если получен ответ и текст не пустой] --> [Возврат текста ответа]
    ↓
[Иначе] --> [Логирование и возврат None]
```

**Примеры**:

```python
# Пример использования с указанием пути к изображению
description = ai.describe_image(Path("image.jpg"), prompt="Опиши изображение")

# Пример использования с передачей байтов изображения
with open("image.jpg", "rb") as f:
    image_bytes = f.read()
description = ai.describe_image(image_bytes, prompt="Опиши изображение")
```

#### `upload_file`

```python
async def upload_file(
    self, file: str | Path | IOBase, file_name: Optional[str] = None
) -> bool:
    """
    https://github.com/google-gemini/generative-ai-python/blob/main/docs/api/google/generativeai/upload_file.md
    response (file_types.File)
    """
    ...
```

**Назначение**: Асинхронно загружает файл в Gemini.

**Параметры**:
- `file` (str | Path | IOBase): Путь к файлу, объект Path или файловый поток.
- `file_name` (Optional[str]): Имя файла для загрузки.

**Возвращает**:
- `bool`: `True` в случае успешной загрузки, `False` в случае ошибки.

**Как работает функция**:

1.  **Загрузка файла**: Пытается загрузить файл с использованием `genai.upload_file_async`.
2.  **Обработка ошибок**:
    *   Если происходит ошибка, логирует ошибку и пытается удалить файл с использованием `genai.delete_file_async`.
    *   После удаления файла пытается повторно загрузить файл.
    *   Если повторная загрузка не удалась, логирует общую ошибку и возвращает `None`.
3.  **Возврат результата**: В случае успешной загрузки логирует информацию и возвращает `response`.

**ASCII flowchart**:

```
[Попытка загрузки файла]
    ↓
[Если ошибка] --> [Логирование ошибки]
    ↓
[Попытка удаления файла]
    ↓
[Попытка повторной загрузки файла]
    ↓
[Если повторная загрузка не удалась] --> [Логирование общей ошибки и возврат None]
    ↓
[В случае успеха] --> [Логирование успеха и возврат True]
```

## Функции

### `main`

```python
async def main():
    ...
```

**Назначение**: Главная асинхронная функция, демонстрирующая примеры использования класса `GoogleGenerativeAI`.

**Как работает функция**:

1.  **Инициализация `GoogleGenerativeAI`**: Создает экземпляр класса `GoogleGenerativeAI` с использованием API-ключа и системной инструкции.
2.  **Пример вызова `describe_image`**:
    *   Определяет путь к файлу изображения (`test.jpg`).
    *   Проверяет, существует ли файл. Если файл не существует, выводит сообщение об ошибке.
    *   Если файл существует, выполняет следующие действия:
        *   Определяет текстовый запрос (`prompt`) для анализа изображения и получения ответа в формате JSON.
        *   Вызывает метод `describe_image` для получения описания изображения.
        *   Если описание получено, выводит описание изображения и пытается распарсить его как JSON.
        *   Если не удается распарсить JSON, выводит сообщение об ошибке и полученный текст.
        *   Выполняет пример без JSON вывода, определяя другой текстовый запрос и вызывая метод `describe_image`.
3.  **Пример вызова `upload_file`**:
    *   Определяет путь к файлу (`test.txt`) и записывает в него текст "Hello, Gemini!".
    *   Вызывает метод `upload_file` для загрузки файла.
    *   Выводит результат загрузки файла.
4.  **Пример чата**:
    *   В бесконечном цикле ожидает ввода сообщения от пользователя.
    *   Если пользователь вводит "exit", выходит из цикла.
    *   Вызывает метод `chat` для отправки сообщения пользователя и получения ответа от модели.
    *   Если ответ получен, выводит ответ модели.
    *   Если ответ не получен, выводит сообщение об ошибке.

**ASCII flowchart**:

```
[Инициализация GoogleGenerativeAI]
    ↓
[Пример вызова describe_image]
    ↓
[Проверка существования файла изображения]
    ↓
[Если файл существует] --> [Вызов describe_image с JSON форматом]
    ↓
[Если описание получено] --> [Вывод описания и попытка распарсить JSON]
    ↓
[Пример вызова describe_image без JSON формата]
    ↓
[Пример вызова upload_file]
    ↓
[Пример чата (в цикле)]
    ↓
[Ожидание ввода сообщения от пользователя]
    ↓
[Вызов chat для отправки сообщения и получения ответа]
    ↓
[Вывод ответа модели или сообщения об ошибке]
```