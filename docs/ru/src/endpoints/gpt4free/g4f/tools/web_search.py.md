# Модуль `web_search`

## Обзор

Модуль предоставляет инструменты для выполнения веб-поиска и извлечения информации из результатов поиска. Он использует библиотеку `duckduckgo_search` для выполнения поисковых запросов и `BeautifulSoup` для извлечения текста из HTML-страниц. Модуль также включает функции для кэширования результатов поиска, чтобы избежать повторных запросов.

## Подробней

Этот модуль является частью проекта `hypotez` и предназначен для интеграции веб-поиска в процессы обработки и анализа данных. Основная цель модуля - предоставить удобный интерфейс для выполнения поисковых запросов и получения структурированных результатов, которые могут быть использованы другими компонентами проекта.

Модуль использует библиотеки `aiohttp` для асинхронных HTTP-запросов, `duckduckgo_search` для выполнения поисковых запросов, `BeautifulSoup` для парсинга HTML и `spacy` для обработки естественного языка.

## Содержание

- [Классы](#Классы)
  - [SearchResults](#SearchResults)
  - [SearchResultEntry](#SearchResultEntry)
- [Функции](#Функции)
  - [scrape_text](#scrape_text)
  - [fetch_and_scrape](#fetch_and_scrape)
  - [search](#search)
  - [do_search](#do_search)
  - [get_search_message](#get_search_message)
  - [spacy_get_keywords](#spacy_get_keywords)

## Классы

### `SearchResults`

**Описание**: Класс представляет собой контейнер для хранения результатов веб-поиска.

**Аттрибуты**:

- `results (list)`: Список объектов `SearchResultEntry`, представляющих результаты поиска.
- `used_words (int)`: Количество слов, использованных в результатах поиска.

**Методы**:

- `from_dict(data: dict)`: Создает экземпляр класса из словаря.
- `__iter__()`: Возвращает итератор по результатам поиска.
- `__str__()`: Возвращает строковое представление результатов поиска.
- `__len__() -> int`: Возвращает количество результатов поиска.
- `get_sources() -> Sources`: Возвращает объект `Sources`, содержащий URL и заголовки результатов поиска.
- `get_dict() -> dict`: Возвращает словарь, представляющий экземпляр класса.

### `SearchResultEntry`

**Описание**: Класс представляет собой запись результата веб-поиска.

**Аттрибуты**:

- `title (str)`: Заголовок результата поиска.
- `url (str)`: URL результата поиска.
- `snippet (str)`: Краткое описание результата поиска (сниппет).
- `text (str, optional)`: Полный текст результата поиска.

**Методы**:

- `set_text(text: str)`: Устанавливает полный текст результата поиска.
- `get_dict() -> dict`: Возвращает словарь, представляющий экземпляр класса.

## Функции

### `scrape_text`

```python
def scrape_text(html: str, max_words: int = None, add_source=True, count_images: int = 2) -> Iterator[str]:
    """
    Извлекает текст из HTML-кода страницы, удаляя лишние элементы и форматируя результат.

    Args:
        html (str): HTML-код страницы.
        max_words (int, optional): Максимальное количество слов для извлечения. По умолчанию `None` (без ограничений).
        add_source (bool): Флаг, указывающий, нужно ли добавлять ссылку на источник в конце извлеченного текста.
        count_images (int): Максимальное количество изображений для извлечения.

    Returns:
        Iterator[str]: Итератор по строкам извлеченного текста.

    Как работает функция:
        1. Преобразует HTML в объект BeautifulSoup для удобного парсинга.
        2. Пытается найти основной контент страницы, используя различные селекторы CSS.
        3. Удаляет нежелательные элементы, такие как глобальные раскрытия.
        4. Извлекает текст из заголовков, параграфов, таблиц и списков.
        5. Добавляет ссылки на изображения, если они есть.
        6. Добавляет ссылку на источник страницы, если `add_source` установлен в `True`.
    """
```

**Назначение**: Извлекает текст из HTML-кода страницы, удаляя лишние элементы и форматируя результат.

**Параметры**:

- `html (str)`: HTML-код страницы.
- `max_words (int, optional)`: Максимальное количество слов для извлечения. По умолчанию `None` (без ограничений).
- `add_source (bool)`: Флаг, указывающий, нужно ли добавлять ссылку на источник в конце извлеченного текста.
- `count_images (int)`: Максимальное количество изображений для извлечения.

**Возвращает**:

- `Iterator[str]`: Итератор по строкам извлеченного текста.

**Как работает функция**:

1.  **Преобразование HTML в объект BeautifulSoup**:
    - Полученный HTML преобразуется в объект `BeautifulSoup`, что позволяет удобно манипулировать и извлекать данные из HTML-структуры.

2.  **Поиск основного содержимого страницы**:
    - Функция пытается найти основной контент страницы, используя различные CSS-селекторы, такие как `"main"`, `".main-content-wrapper"`, `".main-content"`, `".emt-container-inner"`, `".content-wrapper"`, `"#content"`, `"#mainContent"`.
    - Если один из этих селекторов найден, функция обновляет объект `soup` для дальнейшей обработки только внутри этого основного контейнера.

3.  **Удаление нежелательных элементов**:
    - Определенные элементы, такие как `".c-globalDisclosure"`, удаляются из структуры HTML, чтобы избежать включения нерелевантного содержимого.

4.  **Извлечение текста из различных элементов**:
    - Функция извлекает текст из различных HTML-элементов, таких как заголовки (`h1, h2, h3, h4, h5, h6`), параграфы (`p`), предварительно форматированный текст (`pre`), таблицы (`table`), и списки (`ul`).
    - Для каждого найденного элемента извлекается текст, который затем разделяется на отдельные слова.

5.  **Обработка изображений**:
    - Если `count_images` больше нуля, функция ищет изображения, связанные с текстом, и формирует ссылку на изображение с использованием `format_link`.
    - Для каждого найденного изображения генерируется строка с ссылкой на изображение. Количество оставшихся изображений для обработки уменьшается.

6.  **Формирование и возврат результата**:
    - Извлеченные слова объединяются в строки и возвращаются через итератор.
    - Если `add_source` равен `True`, функция пытается найти каноническую ссылку на странице и добавляет информацию об источнике в конце извлеченного текста.

**ASCII Flowchart**:

```
HTML --> BeautifulSoup --> Поиск основного контента --> Удаление нежелательных элементов
    |
    V
Извлечение текста из заголовков, параграфов, таблиц, списков
    |
    V
Обработка изображений (если count_images > 0)
    |
    V
Добавление информации об источнике (если add_source == True)
    |
    V
Iterator[str]
```

**Примеры**:

```python
html_content = "<html><body><h1>Заголовок</h1><p>Текст параграфа.</p><img src='image.jpg' alt='Описание'></body></html>"
for text in scrape_text(html_content, max_words=100, add_source=True):
    print(text)

html_content = "<html><body><h1>Заголовок</h1><p>Текст параграфа.</p><img src='image.jpg' alt='Описание'></body></html>"
for text in scrape_text(html_content, max_words=5, add_source=True):
    print(text)
```

### `fetch_and_scrape`

```python
async def fetch_and_scrape(session: ClientSession, url: str, max_words: int = None, add_source: bool = False) -> str:
    """
    Асинхронно загружает HTML-код страницы по URL и извлекает из него текст.
    Использует кэширование для избежания повторных запросов.

    Args:
        session (ClientSession): Асинхронная HTTP-сессия.
        url (str): URL страницы для загрузки.
        max_words (int, optional): Максимальное количество слов для извлечения. По умолчанию `None` (без ограничений).
        add_source (bool): Флаг, указывающий, нужно ли добавлять ссылку на источник в конце извлеченного текста.

    Returns:
        str: Извлеченный текст или `None` в случае ошибки.
    """
```

**Назначение**: Асинхронно загружает HTML-код страницы по URL и извлекает из него текст. Использует кэширование для избежания повторных запросов.

**Параметры**:

- `session (ClientSession)`: Асинхронная HTTP-сессия.
- `url (str)`: URL страницы для загрузки.
- `max_words (int, optional)`: Максимальное количество слов для извлечения. По умолчанию `None` (без ограничений).
- `add_source (bool)`: Флаг, указывающий, нужно ли добавлять ссылку на источник в конце извлеченного текста.

**Возвращает**:

- `str`: Извлеченный текст или `None` в случае ошибки.

**Как работает функция**:

1.  **Определение директории для кэширования**:
    - Определяет путь к директории, где будут храниться кэшированные результаты извлечения текста. Директория создается, если она не существует.

2.  **Формирование имени файла кэша**:
    - Создает MD5-хеш от URL-адреса для использования в качестве части имени файла кэша. Это необходимо для уникальной идентификации каждого URL в кэше.

3.  **Проверка наличия кэшированного файла**:
    - Проверяет, существует ли файл кэша для данного URL-адреса. Если файл существует, функция считывает текст из файла и возвращает его, избегая повторного выполнения HTTP-запроса и извлечения текста.

4.  **Выполнение HTTP-запроса**:
    - Если кэшированный файл не найден, функция выполняет асинхронный HTTP-запрос к указанному URL-адресу, используя предоставленную HTTP-сессию (`session`).

5.  **Извлечение текста из HTML**:
    - После успешного выполнения запроса функция извлекает HTML-код из ответа и использует функцию `scrape_text` для извлечения полезного текста.

6.  **Кэширование извлеченного текста**:
    - Извлеченный текст сохраняется в файл кэша для последующего использования. Это позволяет избежать повторных запросов к одному и тому же URL-адресу.

7.  **Обработка ошибок**:
    - В случае возникновения ошибок во время выполнения HTTP-запроса (например, ошибок клиента или таймаутов), функция перехватывает исключения `ClientError` и `asyncio.TimeoutError` и возвращает `None`.

**ASCII Flowchart**:

```
URL --> Определение директории для кэширования
    |
    V
Формирование имени файла кэша
    |
    V
Проверка наличия кэшированного файла
    |
    +-- Да --> Считывание текста из файла кэша --> Возврат текста
    |
    +-- Нет --> Выполнение HTTP-запроса --> Извлечение текста из HTML (scrape_text)
    |         |
    |         V
    |         Кэширование извлеченного текста
    |         |
    |         V
    |         Возврат текста
    |
    V
Обработка ошибок (ClientError, asyncio.TimeoutError) --> Возврат None
```

**Примеры**:

```python
import asyncio
from aiohttp import ClientSession

async def main():
    async with ClientSession() as session:
        text = await fetch_and_scrape(session, "https://www.example.com", max_words=100)
        if text:
            print(text)

asyncio.run(main())
```

### `search`

```python
async def search(query: str, max_results: int = 5, max_words: int = 2500, backend: str = "auto", add_text: bool = True, timeout: int = 5, region: str = "wt-wt") -> SearchResults:
    """
    Выполняет поиск в DuckDuckGo и возвращает результаты.

    Args:
        query (str): Поисковый запрос.
        max_results (int, optional): Максимальное количество результатов для возврата. По умолчанию 5.
        max_words (int, optional): Максимальное количество слов для извлечения из каждой страницы. По умолчанию 2500.
        backend (str, optional): Бэкенд для использования в DuckDuckGo. По умолчанию "auto".
        add_text (bool, optional): Флаг, указывающий, нужно ли извлекать текст из страниц результатов поиска. По умолчанию True.
        timeout (int, optional): Время ожидания HTTP-запроса в секундах. По умолчанию 5.
        region (str, optional): Регион для поиска. По умолчанию "wt-wt".

    Returns:
        SearchResults: Объект `SearchResults`, содержащий результаты поиска.

    Raises:
        MissingRequirementsError: Если не установлены необходимые библиотеки (`duckduckgo-search` и `beautifulsoup4`).
    """
```

**Назначение**: Выполняет поиск в DuckDuckGo и возвращает результаты.

**Параметры**:

- `query (str)`: Поисковый запрос.
- `max_results (int, optional)`: Максимальное количество результатов для возврата. По умолчанию 5.
- `max_words (int, optional)`: Максимальное количество слов для извлечения из каждой страницы. По умолчанию 2500.
- `backend (str, optional)`: Бэкенд для использования в DuckDuckGo. По умолчанию `"auto"`.
- `add_text (bool, optional)`: Флаг, указывающий, нужно ли извлекать текст из страниц результатов поиска. По умолчанию `True`.
- `timeout (int, optional)`: Время ожидания HTTP-запроса в секундах. По умолчанию 5.
- `region (str, optional)`: Регион для поиска. По умолчанию `"wt-wt"`.

**Возвращает**:

- `SearchResults`: Объект `SearchResults`, содержащий результаты поиска.

**Вызывает исключения**:

- `MissingRequirementsError`: Если не установлены необходимые библиотеки (`duckduckgo-search` и `beautifulsoup4`).

**Как работает функция**:

1.  **Проверка наличия необходимых библиотек**:
    - Проверяет, установлены ли библиотеки `duckduckgo-search` и `beautifulsoup4`. Если хотя бы одна из них не установлена, вызывает исключение `MissingRequirementsError`.

2.  **Выполнение поискового запроса с использованием `duckduckgo_search`**:
    - Использует `ddgs.text` для выполнения поискового запроса в DuckDuckGo. Параметры запроса включают поисковый запрос (`query`), регион (`region`), безопасный поиск (`safesearch`), ограничение по времени (`timelimit`) и максимальное количество результатов (`max_results`).

3.  **Фильтрация результатов**:
    - Исключает результаты, содержащие домен `.google.`.

4.  **Создание объектов `SearchResultEntry`**:
    - Для каждого результата поиска создает объект `SearchResultEntry`, содержащий заголовок, URL и краткое описание.

5.  **Извлечение текста из результатов поиска (если `add_text` равен `True`)**:
    - Использует `aiohttp.ClientSession` для выполнения асинхронных HTTP-запросов к URL-адресам результатов поиска.
    - Для каждого результата поиска вызывает функцию `fetch_and_scrape` для загрузки и извлечения текста из HTML-кода страницы.
    - Параметр `max_words` передается в `fetch_and_scrape`, чтобы ограничить количество извлекаемых слов.

6.  **Форматирование результатов**:
    - Создает список `formatted_results`, содержащий отформатированные результаты поиска.
    - Вычисляет общее количество использованных слов (`used_words`) и оставшееся количество слов (`left_words`).
    - Ограничивает количество результатов поиска в зависимости от параметра `max_words`.

7.  **Создание и возврат объекта `SearchResults`**:
    - Создает объект `SearchResults`, содержащий отформатированные результаты поиска и общее количество использованных слов.
    - Возвращает объект `SearchResults`.

**ASCII Flowchart**:

```
query --> Проверка наличия необходимых библиотек
    |
    +-- Нет --> MissingRequirementsError
    |
    +-- Да --> Выполнение поискового запроса с использованием duckduckgo_search
    |
    V
Фильтрация результатов (исключение .google.)
    |
    V
Создание объектов SearchResultEntry
    |
    V
Извлечение текста из результатов поиска (если add_text == True)
    |
    V
Форматирование результатов
    |
    V
Создание и возврат объекта SearchResults
```

**Примеры**:

```python
import asyncio

async def main():
    results = await search("python programming", max_results=3, max_words=500)
    print(f"Найдено {len(results)} результатов.")
    for result in results:
        print(f"Заголовок: {result.title}")
        print(f"URL: {result.url}")
        print(f"Описание: {result.snippet}")
        if result.text:
            print(f"Текст: {result.text[:100]}...")

asyncio.run(main())
```

### `do_search`

```python
async def do_search(prompt: str, query: str = None, instructions: str = DEFAULT_INSTRUCTIONS, **kwargs) -> tuple[str, Sources]:
    """
    Выполняет поиск в интернете на основе запроса и возвращает результаты, отформатированные для использования в подсказках.

    Args:
        prompt (str): Исходный запрос пользователя.
        query (str, optional): Поисковый запрос. Если не указан, используется первая строка `prompt`.
        instructions (str, optional): Инструкции для форматирования результатов поиска. По умолчанию `DEFAULT_INSTRUCTIONS`.
        **kwargs: Дополнительные аргументы, передаваемые в функцию `search`.

    Returns:
        tuple[str, Sources]: Кортеж, содержащий отформатированный запрос и источники результатов поиска.
    """
```

**Назначение**: Выполняет поиск в интернете на основе запроса и возвращает результаты, отформатированные для использования в подсказках.

**Параметры**:

- `prompt (str)`: Исходный запрос пользователя.
- `query (str, optional)`: Поисковый запрос. Если не указан, используется первая строка `prompt`.
- `instructions (str, optional)`: Инструкции для форматирования результатов поиска. По умолчанию `DEFAULT_INSTRUCTIONS`.
- `**kwargs`: Дополнительные аргументы, передаваемые в функцию `search`.

**Возвращает**:

- `tuple[str, Sources]`: Кортеж, содержащий отформатированный запрос и источники результатов поиска.

**Как работает функция**:

1.  **Проверка наличия инструкций в запросе**:
    - Если `instructions` указаны и уже присутствуют в `prompt`, функция возвращает `prompt` без изменений и `None` в качестве источников.

2.  **Проверка наличия поискового запроса**:
    - Если `prompt` начинается с `"##"` и `query` не указан, функция возвращает `prompt` без изменений и `None` в качестве источников.

3.  **Определение поискового запроса**:
    - Если `query` не указан, функция использует первую строку `prompt` в качестве поискового запроса.

4.  **Кэширование результатов поиска**:
    - Функция использует MD5-хеш от JSON-представления параметров запроса для формирования имени файла кэша.
    - Если файл кэша существует, функция считывает результаты поиска из файла и десериализует их в объект `SearchResults`.

5.  **Выполнение поискового запроса (если результаты не найдены в кэше)**:
    - Если результаты поиска не найдены в кэше, функция вызывает функцию `search` для выполнения поискового запроса.
    - Результаты поиска сохраняются в файл кэша в формате JSON.

6.  **Форматирование результатов поиска**:
    - Если `instructions` указаны, функция форматирует результаты поиска в соответствии с инструкциями и добавляет их в `prompt`.
    - Если `instructions` не указаны, функция просто добавляет результаты поиска в `prompt`.

7.  **Возврат результатов**:
    - Функция возвращает кортеж, содержащий отформатированный запрос и объект `Sources`, содержащий источники результатов поиска.

**ASCII Flowchart**:

```
prompt, query, instructions --> Проверка наличия инструкций в запросе
    |
    +-- Да --> Возврат prompt, None
    |
    +-- Нет --> Проверка наличия поискового запроса
    |
    +-- Нет query --> Определение поискового запроса (первая строка prompt)
    |
    V
Кэширование результатов поиска
    |
    +-- Кэш существует --> Считывание результатов из кэша
    |
    +-- Кэш не существует --> Выполнение поискового запроса (search)
    |         |
    |         V
    |         Сохранение результатов в кэш
    |
    V
Форматирование результатов поиска
    |
    V
Возврат (отформатированный запрос, Sources)
```

**Примеры**:

```python
import asyncio

async def main():
    prompt = "What is the capital of France?"
    formatted_prompt, sources = await do_search(prompt)
    print(f"Отформатированный запрос: {formatted_prompt}")
    if sources:
        print(f"Источники: {sources}")

asyncio.run(main())
```

### `get_search_message`

```python
def get_search_message(prompt: str, raise_search_exceptions=False, **kwargs) -> str:
    """
    Выполняет поиск и возвращает отформатированное сообщение.

    Args:
        prompt (str): Исходный запрос пользователя.
        raise_search_exceptions (bool, optional): Флаг, указывающий, нужно ли вызывать исключения, возникающие при поиске. По умолчанию False.
        **kwargs: Дополнительные аргументы, передаваемые в функцию `do_search`.

    Returns:
        str: Отформатированное сообщение, содержащее результаты поиска.
    """
```

**Назначение**: Выполняет поиск и возвращает отформатированное сообщение.

**Параметры**:

- `prompt (str)`: Исходный запрос пользователя.
- `raise_search_exceptions (bool, optional)`: Флаг, указывающий, нужно ли вызывать исключения, возникающие при поиске. По умолчанию `False`.
- `**kwargs`: Дополнительные аргументы, передаваемые в функцию `do_search`.

**Возвращает**:

- `str`: Отформатированное сообщение, содержащее результаты поиска.

**Как работает функция**:

1.  **Выполнение поискового запроса с использованием `do_search`**:
    - Вызывает асинхронную функцию `do_search` для выполнения поискового запроса на основе предоставленного запроса (`prompt`) и дополнительных аргументов (`kwargs`).

2.  **Обработка исключений**:
    - Перехватывает исключения `DuckDuckGoSearchException` и `MissingRequirementsError`, которые могут возникнуть во время выполнения поискового запроса.

3.  **Возврат отформатированного сообщения**:
    - Если исключения не перехвачены или `raise_search_exceptions` установлен в `False`, функция возвращает исходный запрос (`prompt`).
    - Если исключения перехвачены и `raise_search_exceptions` установлен в `True`, функция вызывает исключение.

**ASCII Flowchart**:

```
prompt, kwargs --> Выполнение поискового запроса с использованием do_search
    |
    V
Обработка исключений (DuckDuckGoSearchException, MissingRequirementsError)
    |
    +-- Исключение не перехвачено или raise_search_exceptions == False --> Возврат prompt
    |
    +-- Исключение перехвачено и raise_search_exceptions == True --> Вызов исключения
```

**Примеры**:

```python
prompt = "What is the capital of France?"
message = get_search_message(prompt)
print(message)

prompt = "What is the capital of France?"
message = get_search_message(prompt, raise_search_exceptions=True)
print(message)
```

### `spacy_get_keywords`

```python
def spacy_get_keywords(text: str):
    """
    Извлекает ключевые слова из текста с помощью библиотеки spaCy.

    Args:
        text (str): Текст для извлечения ключевых слов.

    Returns:
        list: Список ключевых слов.
    """
```

**Назначение**: Извлекает ключевые слова из текста с помощью библиотеки spaCy.

**Параметры**:

- `text (str)`: Текст для извлечения ключевых слов.

**Возвращает**:

- `list`: Список ключевых слов.

**Как работает функция**:

1.  **Проверка наличия библиотеки spaCy**:
    - Проверяет, установлена ли библиотека `spacy`. Если библиотека не установлена, возвращает исходный текст.

2.  **Загрузка языковой модели spaCy**:
    - Загружает языковую модель `en_core_web_sm` с помощью `spacy.load`.

3.  **Обработка текста с помощью spaCy**:
    - Обрабатывает входной текст с помощью загруженной языковой модели, создавая объект `Doc`.

4.  **Извлечение ключевых слов**:
    - Извлекает ключевые слова на основе частей речи (существительные, прилагательные) и именованных сущностей.

5.  **Удаление дубликатов**:
    - Удаляет дубликаты из списка ключевых слов.

6.  **Извлечение фраз**:
    - Извлекает именные группы (noun chunks) из текста.

7.  **Возврат ключевых слов**:
    - Возвращает список ключевых слов.

**ASCII Flowchart**:

```
text --> Проверка наличия библиотеки spaCy
    |
    +-- Нет --> Возврат text
    |
    +-- Да --> Загрузка языковой модели spaCy
    |
    V
Обработка текста с помощью spaCy
    |
    V
Извлечение ключевых слов (части речи, именованные сущности)
    |
    V
Удаление дубликатов
    |
    V
Извлечение фраз (noun chunks)
    |
    V
Возврат списка ключевых слов
```

**Примеры**:

```python
text = "This is an example sentence about Python programming and natural language processing."
keywords = spacy_get_keywords(text)
print(keywords)