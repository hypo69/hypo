# Модуль crawlee_python

## Обзор

Этот модуль предоставляет класс `CrawleePython`, который реализует веб-скрапинг с использованием Playwright.  Он позволяет задать начальный список URL-адресов и извлечь данные с этих страниц и всех страниц, на которые ссылаются из них.  Модуль обрабатывает настройки для запуска, остановки и экспорта данных.

## Классы

### `CrawleePython`

**Описание**: Класс `CrawleePython` отвечает за настройку, запуск и обработку данных, извлеченных веб-скрапером.

**Методы**:

- `__init__`: Инициализирует экземпляр класса `CrawleePython` с параметрами для настройки веб-скрапера.
- `setup_crawler`: Настраивает экземпляр `PlaywrightCrawler`.
- `run_crawler`: Запускает веб-скрапер с заданными URL-адресами.
- `export_data`: Экспортирует собранные данные в JSON-файл.
- `get_data`: Получает извлеченные данные.
- `run`: Главный метод, который объединяет настройку, запуск и экспорт данных.

**Параметры конструктора (`__init__`)**:

- `max_requests` (int): Максимальное количество запросов, которые будет осуществлять скрепер. По умолчанию 5.
- `headless` (bool): Флаг, указывающий на режим работы браузера (с графическим интерфейсом или без). По умолчанию `False`.
- `browser_type` (str): Тип браузера для использования. По умолчанию `'firefox'`.

**Метод `setup_crawler`**:

**Описание**: Настраивает `PlaywrightCrawler`.

**Метод `run_crawler`**:

**Описание**: Запускает `PlaywrightCrawler` с заданными URL-адресами.

**Параметры (`run_crawler`)**:

- `urls` (list[str]): Список начальных URL-адресов для запуска сбора данных.

**Метод `export_data`**:

**Описание**: Экспортирует собранные данные в JSON-файл.

**Параметры (`export_data`)**:

- `file_path` (str): Путь к файлу, в который будут сохранены данные.

**Метод `get_data`**:

**Описание**: Получает собранные данные.

**Возвращает**:
- `dict`: Словарь с извлеченными данными.


**Метод `run`**:

**Описание**: Объединяет настройку, запуск и экспорт данных.

**Параметры (`run`)**:

- `urls` (list[str]): Список начальных URL-адресов.


## Функции

(Нет функций в этом модуле)


## Обработка исключений

(Нет обработки исключений в этом примере)


## Пример использования

```python
if __name__ == '__main__':
    async def main():
        experiment = CrawleePython(max_requests=5, headless=False, browser_type='firefox')
        await experiment.run(['https://ksp.co.il'])

    asyncio.run(main())
```

Этот пример демонстрирует использование класса `CrawleePython` для запуска сбора данных с сайта `https://ksp.co.il`.  Он устанавливает максимальное количество запросов, использует браузер Firefox и сохраняет собранные данные в файл `results.json` в временной папке, заданной в `gs.path.tmp`.
```