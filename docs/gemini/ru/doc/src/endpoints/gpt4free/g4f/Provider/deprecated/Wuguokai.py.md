# Модуль `Wuguokai`

## Обзор

Модуль предоставляет класс `Wuguokai`, который является провайдером для взаимодействия с моделью GPT-3.5 Turbo через API `chat.wuguokai.xyz`. Он позволяет отправлять запросы к модели и получать ответы. Этот модуль помечен как устаревший (`deprecated`).

## Подробней

Данный модуль предназначен для интеграции с API `chat.wuguokai.xyz` для предоставления доступа к модели GPT-3.5 Turbo. Он использует библиотеку `requests` для выполнения HTTP-запросов и форматирует запросы и ответы для соответствия требованиям API. Модуль также обрабатывает возможные ошибки и возвращает результаты в формате, пригодном для дальнейшей обработки.

## Классы

### `Wuguokai`

**Описание**: Класс `Wuguokai` является провайдером для взаимодействия с API `chat.wuguokai.xyz`.

**Наследует**:
- `AbstractProvider`: Абстрактный базовый класс для всех провайдеров.

**Атрибуты**:
- `url` (str): URL-адрес API `chat.wuguokai.xyz`.
- `supports_gpt_35_turbo` (bool): Указывает, что провайдер поддерживает модель GPT-3.5 Turbo.
- `working` (bool): Указывает, работает ли провайдер в данный момент.

**Методы**:
- `create_completion`: Отправляет запрос к API и возвращает ответ.

## Функции

### `create_completion`

```python
@staticmethod
def create_completion(
    model: str,
    messages: list[dict[str, str]],
    stream: bool,
    **kwargs: Any,
) -> CreateResult:
    """ Функция отправляет запрос к API `chat.wuguokai.xyz` и возвращает ответ.

    Args:
        model (str): Имя модели для использования.
        messages (list[dict[str, str]]): Список сообщений для отправки.
        stream (bool): Указывает, нужно ли использовать потоковую передачу.
        **kwargs (Any): Дополнительные аргументы.

    Returns:
        CreateResult: Результат выполнения запроса.

    Raises:
        Exception: Если возникает ошибка при выполнении запроса.

    Example:
        Примеры вызовов со всем спектром параметров. которы можно передать в функцию

    """
```

**Назначение**: Отправляет запрос к API `chat.wuguokai.xyz` и возвращает результат выполнения.

**Параметры**:
- `model` (str): Имя используемой модели.
- `messages` (list[dict[str, str]]): Список сообщений, отправляемых в запросе. Каждое сообщение представлено в виде словаря, содержащего ключи `role` и `content`.
- `stream` (bool): Флаг, указывающий на использование потокового режима.
- `**kwargs` (Any): Дополнительные параметры, такие как `proxy`, передаваемые в функцию.

**Возвращает**:
- `CreateResult`: Результат выполнения запроса к API, который может быть как успешным, так и содержать информацию об ошибке.

**Вызывает исключения**:
- `Exception`: Вызывается, если возникает ошибка HTTP-запроса (например, если `response.status_code` не равен 200).

**Как работает функция**:

1. **Формирование заголовков**: Создаются заголовки HTTP-запроса, включающие информацию о типе контента, User-Agent и другие необходимые параметры.
2. **Формирование данных запроса**: Создается словарь `data`, включающий отформатированные сообщения (`prompt`), параметры (`options`), идентификатор пользователя (`userId`) и флаг использования контекста (`usingContext`).
3. **Выполнение POST-запроса**: Отправляется POST-запрос к API `https://ai-api20.wuguokai.xyz/api/chat-process` с использованием библиотеки `requests`. В запросе передаются заголовки, данные и параметры `timeout` и `proxy`.
4. **Обработка ответа**:
   - Проверяется статус код ответа. Если код не равен 200, вызывается исключение `Exception`.
   - Разделяется текст ответа на части с использованием разделителя `> 若回答失败请重试或多刷新几次界面后重试`.
   - Если разделение успешно, возвращается вторая часть (индекс 1) без лишних пробелов.
   - В противном случае возвращается первая часть (индекс 0) без лишних пробелов.
5. **Генерация результата**: Результат возвращается в виде генератора, который выдает обработанный текст ответа.

**Внутренние функции**: Отсутствуют.

**Примеры**:
```python
# Пример вызова функции create_completion
model = "gpt-3.5-turbo"
messages = [{"role": "user", "content": "Hello, how are you?"}]
stream = False
kwargs = {"proxy": {"http": "http://your_proxy", "https": "https://your_proxy"}}

# response_generator = Wuguokai.create_completion(model, messages, stream, **kwargs)
# for response in response_generator:
#     print(response)
```

ASCII flowchart:

```
A: Формирование заголовков и данных запроса
|
B: Отправка POST-запроса к API
|
C: Проверка статуса ответа (response.status_code == 200)
|
D: Разделение текста ответа по разделителю
|
E: Возврат обработанной части текста ответа