# Модуль Aivvm
## Обзор

Модуль `Aivvm` предоставляет класс `Aivvm`, который является провайдером для взаимодействия с сервисом [chat.aivvm.com](https://chat.aivvm.com/) для получения ответов от языковых моделей, таких как GPT-3.5 и GPT-4. Этот модуль устарел (deprecated) и, вероятно, больше не поддерживается в актуальном состоянии.

## Подробнее

Модуль позволяет отправлять запросы к API `chat.aivvm.com` и получать ответы в потоковом режиме. Он поддерживает выбор модели, передачу истории сообщений, системные указания и температуру для контроля генерации текста.

## Классы

### `Aivvm`
Описание класса для взаимодействия с сервисом Aivvm.
**Наследует**:
    `AbstractProvider` - абстрактный класс-провайдер, определяющий интерфейс для всех провайдеров.

**Атрибуты**:
- `url` (str): URL сервиса Aivvm (`https://chat.aivvm.com`).
- `supports_stream` (bool): Указывает, поддерживает ли провайдер потоковый режим (`True`).
- `working` (bool): Указывает, работает ли провайдер в данный момент (`False`). Возможно, указывает на статус работоспособности провайдера.
- `supports_gpt_35_turbo` (bool): Указывает, поддерживает ли провайдер модель `gpt-3.5-turbo` (`True`).
- `supports_gpt_4` (bool): Указывает, поддерживает ли провайдер модель `gpt-4` (`True`).

### `Aivvm.create_completion`

```python
    @classmethod
    def create_completion(cls,
        model: str,
        messages: Messages,
        stream: bool,
        **kwargs
    ) -> CreateResult:
        """
        Создает запрос к Aivvm для получения ответа от языковой модели.

        Args:
            model (str): Идентификатор модели, которую необходимо использовать (например, "gpt-3.5-turbo").
            messages (Messages): Список сообщений, представляющих историю диалога.
            stream (bool): Указывает, должен ли ответ быть возвращен в потоковом режиме.
            **kwargs: Дополнительные аргументы, такие как "system_message" (системное указание) и "temperature" (температура).

        Returns:
            CreateResult: Результат создания запроса, представляющий собой генератор, выдающий чанки ответа.

        Raises:
            ValueError: Если указанная модель не поддерживается.

        """
```

**Назначение**:
Метод `create_completion` отправляет запрос к API `chat.aivvm.com` для генерации текста на основе заданной модели и истории сообщений. Он преобразует входные данные в формат, требуемый API, и возвращает результат в потоковом режиме, если это указано.

**Параметры**:
- `model` (str): Идентификатор модели, которую необходимо использовать (например, "gpt-3.5-turbo").
- `messages` (Messages): Список сообщений, представляющих историю диалога.
- `stream` (bool): Указывает, должен ли ответ быть возвращен в потоковом режиме.
- `**kwargs`: Дополнительные аргументы, такие как:
    - `"system_message"` (str): Системное указание для модели (по умолчанию "You are ChatGPT, a large language model trained by OpenAI. Follow the user's instructions carefully. Respond using markdown.").
    - `"temperature"` (float): Температура для контроля случайности генерации текста (по умолчанию 0.7).

**Возвращает**:
- `CreateResult`: Результат создания запроса, представляющий собой генератор, выдающий чанки ответа.

**Вызывает исключения**:
- `ValueError`: Если указанная модель не найдена в списке поддерживаемых моделей.
- `requests.exceptions.HTTPError`: Если HTTP запрос завершается с кодом ошибки.

**Как работает функция**:

1.  **Проверка модели**: Функция проверяет, указана ли модель. Если нет, устанавливает значение по умолчанию "gpt-3.5-turbo". Также проверяет, поддерживается ли указанная модель, поднимая исключение `ValueError`, если модель не найдена в словаре `models`.

2.  **Формирование данных запроса**: Создается словарь `json_data`, который включает:
    *   `"model"`: Информация о модели из словаря `models`.
    *   `"messages"`: История сообщений.
    *   `"key"`: Пустая строка (возможно, для ключа API, который не используется).
    *   `"prompt"`: Системное указание (если предоставлено, иначе используется значение по умолчанию).
    *   `"temperature"`: Температура генерации (если предоставлена, иначе используется значение по умолчанию).

3.  **Преобразование данных в JSON**: Словарь `json_data` преобразуется в JSON-строку.

4.  **Формирование заголовков запроса**: Создается словарь `headers` с необходимыми HTTP-заголовками, включая `Content-Type`, `Content-Length`, `User-Agent` и другие.

5.  **Отправка POST-запроса**: Отправляется POST-запрос к API `https://chat.aivvm.com/api/chat` с указанными заголовками и данными.

6.  **Обработка потокового ответа**: Если запрос успешен, функция итерируется по чанкам ответа, декодирует каждый чанк в UTF-8 и возвращает его через `yield`. Если возникает ошибка декодирования Unicode, используется `unicode-escape`.

**Внутренние функции**:
Внутри `create_completion` нет внутренних функций.

**Примеры**:

```python
# Пример вызова create_completion с минимальными параметрами
messages = [{"role": "user", "content": "Hello, world!"}]
result = Aivvm.create_completion(model="gpt-3.5-turbo", messages=messages, stream=True)
for chunk in result:
    print(chunk, end="")

# Пример вызова create_completion с указанием системного сообщения и температуры
messages = [{"role": "user", "content": "Translate to Spanish: Hello, world!"}]
result = Aivvm.create_completion(model="gpt-4", messages=messages, stream=True, system_message="You are a translator", temperature=0.9)
for chunk in result:
    print(chunk, end="")
```

**Как работает функция**:
```
Проверка модели --> Формирование данных запроса --> Преобразование в JSON --> Формирование заголовков --> Отправка POST-запроса --> Обработка потокового ответа
```

ASCII flowchart:

```
    Начало
     ↓
  Проверка модели
     ↓
  Формирование данных запроса
     ↓
  Преобразование в JSON
     ↓
  Формирование заголовков
     ↓
  Отправка POST-запроса
     ↓
  Обработка потокового ответа
     ↓
    Конец
```

## Функции

В данном модуле функции отсутствуют.