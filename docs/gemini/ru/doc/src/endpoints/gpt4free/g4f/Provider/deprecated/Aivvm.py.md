# Модуль `Aivvm`

## Обзор

Модуль `Aivvm` представляет собой реализацию класса `AbstractProvider` для взаимодействия с сервисом `chat.aivvm.com`. Он предоставляет возможность отправки запросов к различным моделям, таким как `gpt-3.5-turbo` и `gpt-4`, и получения ответов в потоковом режиме.

## Подробнее

Модуль предназначен для интеграции с другими частями проекта `hypotez`, где требуется использование моделей GPT для генерации текста или выполнения других задач обработки естественного языка. Он обеспечивает абстракцию от конкретного API сервиса `chat.aivvm.com`, что позволяет легко заменять его другими провайдерами, если это необходимо.  Этот модуль является deprecated и его использование не рекомендуется. <инструкция для модели gemini:Предпочтительно использовать актуальные модули и избегать устаревшего кода.>

## Классы

### `Aivvm(AbstractProvider)`

**Описание**: Класс `Aivvm` является наследником класса `AbstractProvider` и реализует методы для взаимодействия с API `chat.aivvm.com`.

**Наследует**:

- `AbstractProvider`: Абстрактный класс, определяющий интерфейс для провайдеров моделей.

**Атрибуты**:

- `url` (str): URL сервиса `chat.aivvm.com`.
- `supports_stream` (bool): Указывает, поддерживает ли провайдер потоковый режим (`True`).
- `working` (bool): Указывает, находится ли провайдер в рабочем состоянии (`False`).
- `supports_gpt_35_turbo` (bool): Указывает, поддерживает ли провайдер модель `gpt-3.5-turbo` (`True`).
- `supports_gpt_4` (bool): Указывает, поддерживает ли провайдер модель `gpt-4` (`True`).

**Методы**:

- `create_completion`: Отправляет запрос к API `chat.aivvm.com` и возвращает ответ в потоковом режиме.

## Функции

### `create_completion`

```python
    @classmethod
    def create_completion(cls,
        model: str,
        messages: Messages,
        stream: bool,
        **kwargs
    ) -> CreateResult:
        """Отправляет запрос к API chat.aivvm.com и возвращает ответ в потоковом режиме.

        Args:
            model (str): Идентификатор модели, которую необходимо использовать.
            messages (Messages): Список сообщений, составляющих контекст запроса.
            stream (bool): Указывает, следует ли возвращать ответ в потоковом режиме.
            **kwargs: Дополнительные аргументы, такие как `system_message` и `temperature`.

        Returns:
            CreateResult: Результат запроса.

        Raises:
            ValueError: Если указанная модель не поддерживается.
        """
        ...
```

**Назначение**: Метод `create_completion` отправляет запрос к API `chat.aivvm.com` для генерации текста на основе предоставленных сообщений и параметров.

**Параметры**:

- `model` (str): Идентификатор модели, которую необходимо использовать (например, `"gpt-3.5-turbo"`).
- `messages` (Messages): Список сообщений, составляющих контекст запроса.
- `stream` (bool): Флаг, указывающий, следует ли возвращать ответ в потоковом режиме.
- `**kwargs`: Дополнительные аргументы:
  - `system_message` (str): Системное сообщение, определяющее роль и поведение модели. По умолчанию `"You are ChatGPT, a large language model trained by OpenAI. Follow the user's instructions carefully. Respond using markdown."`.
  - `temperature` (float): Параметр, определяющий случайность генерируемого текста. По умолчанию `0.7`.

**Возвращает**:

- `CreateResult`: Тип `Generator[str, None, None]`, представляющий собой генератор чанков текста.

**Вызывает исключения**:

- `ValueError`: Если указанная модель не найдена в списке поддерживаемых моделей.

**Как работает функция**:

1.  **Проверка модели**: Функция проверяет, указана ли модель и поддерживается ли она. Если модель не указана, используется `"gpt-3.5-turbo"` по умолчанию. Если модель не поддерживается, вызывается исключение `ValueError`.
2.  **Формирование данных запроса**: Функция формирует словарь `json_data`, содержащий параметры запроса, такие как модель, сообщения, ключ API, системное сообщение и температуру.
3.  **Преобразование в JSON**: Словарь `json_data` преобразуется в JSON-строку.
4.  **Формирование заголовков**: Функция формирует словарь `headers`, содержащий заголовки HTTP-запроса, включая тип контента, длину контента, User-Agent и другие.
5.  **Отправка запроса**: Функция отправляет POST-запрос к API `chat.aivvm.com/api/chat` с сформированными заголовками и данными.
6.  **Обработка ответа**: Функция итерируется по чанкам ответа, декодирует их в UTF-8 и возвращает в потоковом режиме. Если возникает ошибка `UnicodeDecodeError`, используется кодировка `"unicode-escape"`.

**Внутренние функции**:

Функция `create_completion` содержит в себе цикл, в котором происходит декодирование и выдача чанков ответа. Внутри этого цикла обрабатывается исключение `UnicodeDecodeError`.

**ASCII flowchart**:

```
   Начало
   ↓
   Проверка модели
   ↓
   Формирование данных запроса
   ↓
   Преобразование в JSON
   ↓
   Формирование заголовков
   ↓
   Отправка запроса
   ↓
   Итерация по чанкам ответа
   │
   ├─→ Декодирование чанка (UTF-8)
   │   ↓
   │   Успешно? ── Да → Выдача чанка
   │   ↓   │
   │   Нет  │
   │   ↓   │
   │   Обработка UnicodeDecodeError
   │   ↓
   │   Декодирование чанка (unicode-escape)
   │   ↓
   │   Выдача чанка
   │
   Конец
```

**Примеры**:

```python
# Пример вызова функции create_completion с минимальными параметрами
messages = [{"role": "user", "content": "Hello, how are you?"}]
result = Aivvm.create_completion(model="gpt-3.5-turbo", messages=messages, stream=True)
for chunk in result:
    print(chunk, end="")

# Пример вызова функции create_completion с указанием системного сообщения и температуры
messages = [{"role": "user", "content": "Translate 'hello' to French."}]
result = Aivvm.create_completion(
    model="gpt-4",
    messages=messages,
    stream=True,
    system_message="You are a helpful translation assistant.",
    temperature=0.5,
)
for chunk in result:
    print(chunk, end="")