# Модуль `FastGpt`

## Обзор

Модуль `FastGpt` предоставляет класс `FastGpt`, который является провайдером для работы с API `chat9.fastgpt.me`. Этот модуль позволяет генерировать текст на основе предоставленных сообщений, используя модели, поддерживающие стриминг.

## Подробней

Этот модуль предназначен для интеграции с сервисом `chat9.fastgpt.me` и предоставляет интерфейс для отправки запросов на генерацию текста с использованием различных параметров, таких как модель, температура и штрафы. Он поддерживает стриминг ответов, что позволяет получать результаты по частям, а не ждать завершения всей генерации. В коде реализована логика выбора поддомена для запросов.

## Классы

### `FastGpt`

**Описание**: Класс `FastGpt` наследуется от `AbstractProvider` и представляет собой конкретную реализацию провайдера для работы с `chat9.fastgpt.me`.

**Наследует**:
- `AbstractProvider`: Абстрактный базовый класс для всех провайдеров.

**Атрибуты**:
- `url` (str): URL-адрес сервиса `chat9.fastgpt.me`.
- `working` (bool): Указывает, работает ли провайдер в данный момент (по умолчанию `False`).
- `needs_auth` (bool): Указывает, требуется ли аутентификация для работы с провайдером (по умолчанию `False`).
- `supports_stream` (bool): Указывает, поддерживает ли провайдер стриминг ответов (по умолчанию `True`).
- `supports_gpt_35_turbo` (bool): Указывает, поддерживает ли провайдер модель `gpt-3.5-turbo` (по умолчанию `True`).
- `supports_gpt_4` (bool): Указывает, поддерживает ли провайдер модель `gpt-4` (по умолчанию `False`).

**Методы**:
- `create_completion`: Статический метод для создания запроса на генерацию текста.

## Функции

### `create_completion`

```python
@staticmethod
def create_completion(
    model: str,
    messages: list[dict[str, str]],
    stream: bool, **kwargs: Any) -> CreateResult:
    """
    Создает запрос к API для генерации текста на основе предоставленных сообщений.

    Args:
        model (str): Имя модели для генерации текста.
        messages (list[dict[str, str]]): Список сообщений, используемых для генерации текста.
        stream (bool): Флаг, указывающий, следует ли использовать потоковую передачу данных.
        **kwargs (Any): Дополнительные параметры запроса, такие как температура, штрафы и т.д.

    Returns:
        CreateResult: Генератор токенов, полученных от API.

    Raises:
        Exception: Если возникает ошибка при отправке запроса или обработке ответа.
    """
```

**Назначение**:
Функция `create_completion` отправляет запрос к API `chat9.fastgpt.me` для генерации текста на основе предоставленных сообщений. Она поддерживает потоковую передачу данных, что позволяет получать результаты по частям.

**Параметры**:
- `model` (str): Имя используемой модели (`gpt-3.5-turbo`).
- `messages` (list[dict[str, str]]): Список сообщений, где каждое сообщение является словарем с ключами `role` и `content`.
- `stream` (bool): Флаг, указывающий на использование потоковой передачи данных.
- `**kwargs` (Any): Дополнительные параметры конфигурации, такие как `temperature`, `presence_penalty`, `frequency_penalty`, `top_p`.

**Возвращает**:
- `CreateResult`: Генератор, выдающий токены (части сгенерированного текста) по мере их получения от API.

**Вызывает исключения**:
- `requests.exceptions.RequestException`: В случае проблем с сетевым запросом.
- `json.JSONDecodeError`: Если не удается декодировать JSON из ответа сервера.
- `Exception`: В случае других ошибок при обработке ответа.

**Как работает функция**:

1. **Подготовка заголовков**:
   - Формируются заголовки HTTP-запроса, необходимые для взаимодействия с API `chat9.fastgpt.me`. Устанавливаются параметры, такие как `authority`, `accept`, `content-type`, `origin`, `referer`, `user-agent` и другие.

2. **Подготовка данных JSON**:
   - Формируются данные JSON, которые будут отправлены в теле запроса. Включаются сообщения (`messages`), флаг стриминга (`stream`), имя модели (`model`) и дополнительные параметры из `kwargs`, такие как `temperature`, `presence_penalty`, `frequency_penalty` и `top_p`.

3. **Выбор поддомена**:
   - Случайным образом выбирается один из поддоменов (`jdaen979ew` или `chat9`) для отправки запроса. Это необходимо для балансировки нагрузки или обхода ограничений.

4. **Отправка запроса**:
   - Отправляется POST-запрос к API `chat9.fastgpt.me` с использованием библиотеки `requests`. Указывается URL с выбранным поддоменом, заголовки, данные JSON и флаг стриминга.

5. **Обработка потока ответов**:
   - Функция итерируется по строкам ответа, полученного от API. Каждая строка проверяется на наличие содержимого (`if line:`).
   - Если строка содержит данные (`b'content' in line`), она декодируется из UTF-8, разделяется по строке `data: `, и извлекается JSON-объект.
   - Из JSON-объекта извлекается токен (`token`) из поля `choices[0]['delta']['content']`. Если токен присутствует, он возвращается через `yield token`.
   - В случае возникновения исключений при обработке строки (например, если строка не является корректным JSON), исключение игнорируется, и обработка продолжается со следующей строки.

```
Подготовка заголовков и данных JSON
│
Выбор поддомена (случайный выбор между 'jdaen979ew' и 'chat9')
│
Отправка POST-запроса к API chat9.fastgpt.me
│
Обработка потока ответов
│
Извлечение и возврат токенов (части сгенерированного текста)
```

**Примеры**:

```python
# Пример 1: Создание запроса с минимальными параметрами
model = "gpt-3.5-turbo"
messages = [{"role": "user", "content": "Напиши короткое приветствие."}]
stream = True
result = FastGpt.create_completion(model=model, messages=messages, stream=stream)
for token in result:
    print(token, end="")

# Пример 2: Создание запроса с дополнительными параметрами
model = "gpt-3.5-turbo"
messages = [{"role": "user", "content": "Напиши короткий стих."}]
stream = True
kwargs = {"temperature": 0.7, "top_p": 0.9}
result = FastGpt.create_completion(model=model, messages=messages, stream=stream, **kwargs)
for token in result:
    print(token, end="")

# Пример 3: Пример обработки ошибки при декодировании JSON
import json
import requests

class MockResponse:
    def __init__(self, content, status_code=200):
        self.content = content
        self.status_code = status_code

    def iter_lines(self):
        yield self.content

# Эмулируем ошибочный ответ от сервера
error_response = MockResponse(content=b'data: {\"error\": \"Некорректный JSON\"}')

# Мокируем requests.post, чтобы возвращать наш ошибочный ответ
def mock_requests_post(*args, **kwargs):
    return error_response

# Заменяем requests.post нашей мокированной функцией
requests.post = mock_requests_post

model = "gpt-3.5-turbo"
messages = [{"role": "user", "content": "Hello"}]
stream = True

result = FastGpt.create_completion(model=model, messages=messages, stream=stream)
for token in result:
    print(token)