# Модуль `Berlin`

## Обзор

Модуль предоставляет асинхронный генератор для взаимодействия с AI-моделью Berlin. Он позволяет отправлять запросы к модели и получать ответы в виде асинхронного потока данных. Модуль поддерживает модель `gpt-3.5-turbo`.

## Подробнее

Модуль использует `aiohttp` для асинхронных HTTP-запросов. Для работы с провайдером требуется получить токен аутентификации, который сохраняется в классе. Модуль реализует метод `create_async_generator`, который отправляет запрос к API и возвращает асинхронный генератор для получения ответов.

## Классы

### `Berlin(AsyncGeneratorProvider)`

**Описание**: Класс `Berlin` является подклассом `AsyncGeneratorProvider` и предоставляет функциональность для взаимодействия с AI-моделью Berlin.

**Наследует**:
- `AsyncGeneratorProvider`: Абстрактный базовый класс для асинхронных провайдеров генераторов.

**Атрибуты**:
- `url` (str): URL-адрес API Berlin.
- `working` (bool): Флаг, указывающий, работает ли провайдер.
- `supports_gpt_35_turbo` (bool): Флаг, указывающий, поддерживает ли провайдер модель `gpt-3.5-turbo`.
- `_token` (Optional[str]): Токен аутентификации для доступа к API Berlin.

**Методы**:
- `create_async_generator`: Создает асинхронный генератор для взаимодействия с AI-моделью Berlin.

## Функции

### `create_async_generator`

```python
@classmethod
async def create_async_generator(
    cls,
    model: str,
    messages: Messages,
    proxy: str = None,
    **kwargs
) -> AsyncResult:
    """Создает асинхронный генератор для взаимодействия с AI-моделью Berlin.

    Args:
        cls: Ссылка на класс.
        model (str): Название модели для использования.
        messages (Messages): Список сообщений для отправки в модель.
        proxy (str, optional): URL прокси-сервера для использования. По умолчанию `None`.
        **kwargs: Дополнительные аргументы, которые будут переданы в API.

    Returns:
        AsyncResult: Асинхронный генератор, который возвращает ответы от AI-модели.

    Raises:
        RuntimeError: Если возникает ошибка при обработке ответа от API.

    """
```

**Назначение**: Создает асинхронный генератор для взаимодействия с AI-моделью Berlin.

**Параметры**:
- `cls`: Ссылка на класс.
- `model` (str): Название модели для использования.
- `messages` (Messages): Список сообщений для отправки в модель.
- `proxy` (str, optional): URL прокси-сервера для использования. По умолчанию `None`.
- `**kwargs`: Дополнительные аргументы, которые будут переданы в API.

**Возвращает**:
- `AsyncResult`: Асинхронный генератор, который возвращает ответы от AI-модели.

**Вызывает исключения**:
- `RuntimeError`: Если возникает ошибка при обработке ответа от API.

**Как работает функция**:

1.  **Инициализация**:
    *   Устанавливает модель по умолчанию, если она не была предоставлена.
    *   Определяет заголовки запроса, включая User-Agent, Accept и Content-Type.

2.  **Аутентификация**:
    *   Проверяет, существует ли уже токен аутентификации (`cls._token`).
    *   Если токен отсутствует, отправляет запрос на аутентификацию, используя жестко заданные учетные данные (`'免费使用GPT3.5模型@163.com'`, `'659e945c2d004686bad1a75b708c962f'`).
    *   Сохраняет полученный токен в `cls._token`.

3.  **Формирование запроса**:
    *   Формирует запрос к API, включая prompt, parentMessageId и options.
    *   Использует функцию `format_prompt` для форматирования сообщений.
    *   Добавляет дополнительные параметры из `kwargs` в опции запроса.

4.  **Отправка запроса и обработка ответа**:
    *   Отправляет асинхронный POST-запрос к API `/api/chat/completions`.
    *   Обрабатывает ответ в виде асинхронного потока данных (chunks).
    *   Извлекает содержимое (`content`) из каждого чанка и передает его в генератор.
    *   В случае ошибки при обработке чанка, вызывает исключение `RuntimeError`.

**Внутренние функции**: В данной функции нет внутренних функций.

**Примеры**:

```python
# Пример использования create_async_generator
import asyncio
from typing import List, Dict, AsyncGenerator
from src.endpoints.gpt4free.g4f.Provider.deprecated.Berlin import Berlin

async def main():
    model = "gpt-3.5-turbo"
    messages: List[Dict[str, str]] = [{"role": "user", "content": "Hello, how are you?"}]
    proxy = None
    kwargs = {}

    generator: AsyncGenerator[str, None] = await Berlin.create_async_generator(model, messages, proxy, **kwargs)

    async for chunk in generator:
        print(chunk, end="")

if __name__ == "__main__":
    asyncio.run(main())
```

## ASCII flowchart функции `create_async_generator`

```
A: Проверка наличия токена аутентификации
|
B: Если токена нет -> Аутентификация и получение токена
|
C: Формирование данных запроса (prompt, options)
|
D: Отправка POST-запроса к API
|
E: Обработка ответа в виде асинхронного потока (chunks)
|
F: Извлечение и передача содержимого из каждого чанка в генератор
|
G: Обработка ошибок при обработке чанков