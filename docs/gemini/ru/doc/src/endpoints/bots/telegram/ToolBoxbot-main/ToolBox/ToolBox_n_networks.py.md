# Модуль для работы с нейронными сетями
======================================

Модуль содержит класс `neural_networks`, который предоставляет методы для взаимодействия с различными нейронными сетями, такими как FLUX.1-schnell, mistral_large_2407 и free_gpt_4o_mini.
Модуль предназначен для генерации изображений и обработки текстовых запросов с использованием API различных нейронных сетей.

## Обзор

Модуль предназначен для упрощения взаимодействия с различными нейронными сетями.
Он предоставляет методы для генерации изображений на основе текстовых запросов, а также для обработки текстовых запросов и получения ответов от AI-моделей.
Модуль использует API различных нейронных сетей и предоставляет унифицированный интерфейс для работы с ними.

## Подробнее

Этот модуль предоставляет класс `neural_networks`, который инкапсулирует взаимодействие с несколькими нейронными сетями. Он использует библиотеку `requests` для выполнения HTTP-запросов к API этих сетей. Для работы с модулем необходимо настроить переменные окружения, содержащие токены доступа к API.

## Классы

### `neural_networks`

**Описание**: Класс для работы с нейронными сетями.

**Принцип работы**:
Класс `neural_networks` предоставляет методы для взаимодействия с различными нейронными сетями, включая генерацию изображений и обработку текстовых запросов.
Он использует API различных нейронных сетей, таких как FLUX.1-schnell, mistral_large_2407 и free_gpt_4o_mini.
Для работы с классом необходимо настроить переменные окружения, содержащие токены доступа к API.

**Методы**:

- `_FLUX_schnell(prompt: str, size: list[int, int], seed: int, num_inference_steps: int) -> str|None`
- `__mistral_large_2407(prompt: list[dict[str, str]]) -> tuple[str, int, int]|str`
- `_free_gpt_4o_mini(prompt: list[dict[str, str]]) -> tuple[str, int, int]|str`

## Функции

### `_FLUX_schnell`

```python
def _FLUX_schnell(self, prompt: str, size: list[int, int], seed: int, num_inference_steps: int) -> str|None:
    """
    Отправляет запрос к API black-forest-labs/FLUX.1-schnell для генерации изображения.

    Args:
        prompt (str): Текстовое описание желаемого изображения.
        size (list[int, int]): Размеры изображения в виде списка [ширина, высота].
        seed (int): Зерно для генерации случайного изображения.
        num_inference_steps (int): Количество шагов для генерации изображения.

    Returns:
        str | None: Сгенерированное изображение в формате PIL Image или None в случае ошибки.
    """
```

**Назначение**:
Функция `_FLUX_schnell` отправляет запрос к API black-forest-labs/FLUX.1-schnell для генерации изображения на основе текстового описания.

**Параметры**:
- `prompt` (str): Текстовое описание желаемого изображения.
- `size` (list[int, int]): Размеры изображения в виде списка [ширина, высота].
- `seed` (int): Зерно для генерации случайного изображения.
- `num_inference_steps` (int): Количество шагов для генерации изображения.

**Возвращает**:
- `str | None`: Сгенерированное изображение в формате PIL Image или None в случае ошибки.

**Как работает функция**:

1. **Формирование полезной нагрузки (payload)**:
   - Создается словарь `payload`, содержащий параметры запроса: `prompt`, `guidance_scale`, `num_inference_steps`, `width`, `height`, `seed`.

2. **Цикл запросов к API**:
   - Выполняется цикл из 6 попыток отправки запроса к API "https://api-inference.huggingface.co/models/black-forest-labs/FLUX.1-schnell".
   - Для каждой попытки используется свой токен доступа из переменных окружения `HF_TOKEN{i}` (где `i` от 1 до 6).

3. **Отправка POST-запроса**:
   - Отправляется POST-запрос с использованием библиотеки `requests`.
   - В заголовках запроса передается токен доступа и Content-Type: application/json.
   - В теле запроса передается сформированная полезная нагрузка `payload` в формате JSON.

4. **Обработка ответа**:
   - Проверяется статус код ответа `response.status_code`.
   - Если статус код равен 200 (успешный запрос), выполняется следующее:
     - Открывается изображение из содержимого ответа с использованием `Image.open(io.BytesIO(response.content))`.
     - Возвращается изображение.
   - Если статус код не равен 200, выполняется переход к следующей итерации цикла.

5. **Возврат None в случае неудачи**:
   - Если все попытки запроса завершились неудачей (статус код не равен 200), функция возвращает `None`.

**ASCII flowchart**:

```
Начало
  |
  V
[Формирование payload]
  |
  V
[Цикл запросов (6 попыток)]
  |
  V
[Отправка POST-запроса]
  |
  V
[Проверка status_code == 200]
  |
  V
[status_code == 200?] -- Да --> [Открытие изображения из response.content] --> [Возврат изображения]
  |                 
  Нет
  V
[Переход к следующей итерации цикла]
  |
  V
[Цикл завершен?] -- Да --> [Возврат None]
```

**Примеры**:

```python
# Пример вызова функции _FLUX_schnell
prompt = "A cat sitting on a fence"
size = [512, 512]
seed = 42
num_inference_steps = 50
image = neural_networks()._FLUX_schnell(prompt, size, seed, num_inference_steps)
if image:
    print("Изображение успешно сгенерировано")
    image.save("cat.png")
else:
    print("Не удалось сгенерировать изображение")
```

### `__mistral_large_2407`

```python
def __mistral_large_2407(self, prompt: list[dict[str, str]]) -> tuple[str, int, int]|str:
    """
    Отправляет запрос к API Mistral AI для обработки текстового запроса.

    Args:
        prompt (list[dict[str, str]]): Список словарей, представляющих текстовый запрос.

    Returns:
        tuple[str, int, int] | str: Ответ от API, количество токенов в запросе и ответе или строка с ошибкой.
    """
```

**Назначение**:
Функция `__mistral_large_2407` отправляет запрос к API Mistral AI для обработки текстового запроса и получения ответа от модели `pixtral-12b-2409`.

**Параметры**:
- `prompt` (list[dict[str, str]]): Список словарей, представляющих текстовый запрос.

**Возвращает**:
- `tuple[str, int, int] | str`: Ответ от API, количество токенов в запросе и ответе или строка с ошибкой.

**Как работает функция**:

1. **Формирование данных запроса**:
   - Создается словарь `data`, содержащий параметры запроса: `messages`, `temperature`, `top_p`, `max_tokens`, `model`.

2. **Отправка POST-запроса**:
   - Отправляется POST-запрос к API "https://api.mistral.ai/v1/chat/completions" с использованием библиотеки `requests`.
   - В заголовках запроса передается Content-Type: application/json и токен доступа из переменной окружения `MISTRAL_TOKEN`.
   - В теле запроса передается сформированный словарь `data` в формате JSON.

3. **Обработка ответа**:
   - Преобразует текст ответа `response.text` из формата `json`
   - Извлекается ответ модели из `response["choices"][0]["message"]`.
   - Извлекается количество токенов в запросе и ответе из `response["usage"]["prompt_tokens"]` и `response["usage"]["completion_tokens"]`.
   - Возвращается кортеж, содержащий ответ, количество токенов в запросе и ответе.

**ASCII flowchart**:

```
Начало
  |
  V
[Формирование данных запроса]
  |
  V
[Отправка POST-запроса]
  |
  V
[Обработка ответа]
  |
  V
[Извлечение ответа, токенов запроса и ответа]
  |
  V
[Возврат (ответ, токены запроса, токены ответа)]
```

**Примеры**:

```python
# Пример вызова функции __mistral_large_2407
prompt = [{"role": "user", "content": "What is the capital of France?"}]
response, prompt_tokens, completion_tokens = neural_networks().__mistral_large_2407(prompt)
print(f"Ответ: {response}")
print(f"Токены в запросе: {prompt_tokens}")
print(f"Токены в ответе: {completion_tokens}")
```

### `_free_gpt_4o_mini`

```python
def _free_gpt_4o_mini(self, prompt: list[dict[str, str]]) -> tuple[str, int, int]|str:
    """
    Отправляет запрос к API gpt-4o-mini для обработки текстового запроса.

    Args:
        prompt (list[dict[str, str]]): Список словарей, представляющих текстовый запрос.

    Returns:
        tuple[str, int, int] | str: Ответ от API, количество токенов в запросе и ответе или результат вызова __mistral_large_2407.
    """
```

**Назначение**:
Функция `_free_gpt_4o_mini` отправляет запрос к API gpt-4o-mini для обработки текстового запроса и получения ответа от модели.
Если запрос к API gpt-4o-mini не удался, функция вызывает `__mistral_large_2407` для обработки запроса.

**Параметры**:
- `prompt` (list[dict[str, str]]): Список словарей, представляющих текстовый запрос.

**Возвращает**:
- `tuple[str, int, int] | str`: Ответ от API, количество токенов в запросе и ответе или результат вызова `__mistral_large_2407`.

**Как работает функция**:

1. **Формирование данных запроса**:
   - Создается словарь `data`, содержащий параметры запроса: `messages`, `temperature`, `top_p`, `max_tokens`, `model`.

2. **Цикл запросов к API**:
   - Выполняется цикл из 6 попыток отправки запроса к API "https://models.inference.ai.azure.com/chat/completions".
   - Для каждой попытки используется свой токен доступа из переменных окружения `GIT_TOKEN{i}` (где `i` от 1 до 6).

3. **Отправка POST-запроса**:
   - Отправляется POST-запрос с использованием библиотеки `requests`.
   - В заголовках запроса передается Content-Type: application/json и токен доступа.
   - В теле запроса передается сформированный словарь `data` в формате JSON.

4. **Обработка ответа**:
   - Проверяется статус код ответа `response.status_code`.
   - Если статус код равен 200 (успешный запрос), выполняется следующее:
     - Преобразует текст ответа `response.text` из формата `json`
     - Извлекается ответ модели из `response["choices"][0]["message"]`.
     - Извлекается количество токенов в запросе и ответе из `response["usage"]["prompt_tokens"]` и `response["usage"]["completion_tokens"]`.
     - Возвращается кортеж, содержащий ответ, количество токенов в запросе и ответе.

5. **Обработка неуспешного запроса**:
   - Если все попытки запроса завершились неудачей (статус код не равен 200), функция вызывает `__mistral_large_2407(prompt)` и возвращает результат.

**ASCII flowchart**:

```
Начало
  |
  V
[Формирование данных запроса]
  |
  V
[Цикл запросов (6 попыток)]
  |
  V
[Отправка POST-запроса]
  |
  V
[Проверка status_code == 200]
  |
  V
[status_code == 200?] -- Да --> [Обработка ответа] --> [Извлечение ответа, токенов запроса и ответа] --> [Возврат (ответ, токены запроса, токены ответа)]
  |
  Нет
  V
[Переход к следующей итерации цикла]
  |
  V
[Цикл завершен?] -- Да --> [Вызов __mistral_large_2407(prompt)] --> [Возврат результата __mistral_large_2407]
```

**Примеры**:

```python
# Пример вызова функции _free_gpt_4o_mini
prompt = [{"role": "user", "content": "Translate 'Hello, world!' to French."}]
response, prompt_tokens, completion_tokens = neural_networks()._free_gpt_4o_mini(prompt)
print(f"Ответ: {response}")
print(f"Токены в запросе: {prompt_tokens}")
print(f"Токены в ответе: {completion_tokens}")