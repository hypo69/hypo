# Модуль Vercel (g4f.Provider.deprecated)

## Обзор

Модуль `Vercel` представляет собой реализацию провайдера для взаимодействия с API Vercel AI SDK. Он предоставляет функциональность для создания завершений текста на основе различных моделей, включая `gpt-3.5-turbo`. Модуль поддерживает потоковую передачу данных и использует специальный механизм для обхода защиты от ботов.

## Подробней

Этот модуль является частью проекта `hypotez` и обеспечивает интеграцию с сервисом Vercel для генерации текста с использованием различных моделей машинного обучения. Он включает в себя функции для выполнения запросов к API Vercel, обработки ответов и обеспечения совместимости с различными моделями. Модуль также содержит вспомогательные функции для получения токенов защиты от ботов и определения информации о моделях.

## Классы

### `Vercel`

**Описание**: Класс `Vercel` является наследником `AbstractProvider` и предоставляет методы для взаимодействия с API Vercel AI SDK.

**Наследует**: `AbstractProvider`

**Атрибуты**:
- `url` (str): URL для доступа к API Vercel AI SDK.
- `working` (bool): Указывает, работает ли провайдер в данный момент.
- `supports_message_history` (bool): Указывает, поддерживает ли провайдер историю сообщений.
- `supports_gpt_35_turbo` (bool): Указывает, поддерживает ли провайдер модель `gpt-3.5-turbo`.
- `supports_stream` (bool): Указывает, поддерживает ли провайдер потоковую передачу данных.

**Методы**:
- `create_completion`: Создает завершение текста на основе указанных параметров.

### `ModelInfo`

**Описание**: `TypedDict`, описывающий структуру данных для хранения информации о модели.

**Атрибуты**:
- `id` (str): Идентификатор модели.
- `default_params` (dict[str, Any]): Параметры по умолчанию для модели.

## Функции

### `create_completion`

```python
@staticmethod
def create_completion(
    model: str,
    messages: Messages,
    stream: bool,
    proxy: str = None,
    **kwargs
) -> CreateResult:
    """
    Создает завершение текста на основе указанных параметров, используя API Vercel.

    Args:
        model (str): Идентификатор модели для использования.
        messages (Messages): Список сообщений для передачи в модель.
        stream (bool): Указывает, следует ли использовать потоковую передачу данных.
        proxy (str, optional): URL прокси-сервера для использования. По умолчанию `None`.
        **kwargs: Дополнительные параметры для передачи в API.

    Returns:
        CreateResult: Генератор токенов, представляющих завершение текста.

    Raises:
        MissingRequirementsError: Если не установлен пакет `PyExecJS`.
        ValueError: Если указанная модель не поддерживается Vercel.
    """
```

**Назначение**: Функция `create_completion` создает запрос к API Vercel для генерации текста на основе заданной модели и входных сообщений. Она обрабатывает параметры запроса, устанавливает необходимые заголовки и возвращает результат в виде генератора токенов.

**Параметры**:
- `model` (str): Идентификатор модели, которую необходимо использовать для генерации текста.
- `messages` (Messages): Список сообщений, передаваемых в модель для получения завершения.
- `stream` (bool): Флаг, определяющий, будет ли использоваться потоковая передача данных для получения результата.
- `proxy` (str, optional): URL прокси-сервера, если необходимо использовать прокси для подключения к API Vercel. По умолчанию `None`.
- `**kwargs`: Дополнительные параметры, которые могут быть переданы в API Vercel для настройки генерации текста.

**Возвращает**:
- `CreateResult`: Генератор, который выдает токены сгенерированного текста.

**Вызывает исключения**:
- `MissingRequirementsError`: Если отсутствует необходимый пакет `PyExecJS`.
- `ValueError`: Если указанная модель не поддерживается провайдером Vercel.

**Как работает функция**:

1. **Проверка зависимостей**:
   - Проверяет, установлен ли пакет `PyExecJS`, необходимый для выполнения JavaScript-кода, используемого для получения токена защиты от ботов. Если пакет не установлен, вызывается исключение `MissingRequirementsError`.
2. **Выбор модели**:
   - Если модель не указана, используется модель по умолчанию `gpt-3.5-turbo`.
   - Проверяет, поддерживается ли указанная модель провайдером Vercel. Если модель не поддерживается, вызывается исключение `ValueError`.
3. **Формирование заголовков запроса**:
   - Создает словарь `headers`, содержащий необходимые HTTP-заголовки для запроса к API Vercel.
   - Заголовок `custom-encoding` устанавливается равным токену защиты от ботов, полученному с помощью функции `get_anti_bot_token`.
4. **Формирование тела запроса**:
   - Создает словарь `json_data`, содержащий данные для отправки в API Vercel в формате JSON.
   - Данные включают идентификатор модели, список сообщений, идентификатор игровой площадки и параметры модели по умолчанию.
5. **Выполнение запроса к API Vercel**:
   - Выполняет цикл повторных попыток отправки запроса к API Vercel.
   - Отправляет POST-запрос к API `https://chat.vercel.ai/api/chat` с использованием сформированных заголовков и тела запроса.
   - Если `stream` установлен в `True`, использует потоковую передачу данных для получения ответа.
6. **Обработка ответа**:
   - Если запрос выполнен успешно, функция итерируется по содержимому ответа и выдает токены сгенерированного текста.
   - Если в процессе выполнения запроса возникает ошибка, функция переходит к следующей попытке.

**ASCII flowchart функции**:

```
A[Проверка зависимостей и выбор модели]
|
B[Формирование заголовков и тела запроса]
|
C[Выполнение POST-запроса к API Vercel]
|
D[Обработка ответа: итерация по токенам и выдача результата]
```

**Примеры**:

```python
# Пример 1: Создание завершения текста с использованием модели gpt-3.5-turbo
messages = [{"role": "user", "content": "Hello, how are you?"}]
result = Vercel.create_completion(model="gpt-3.5-turbo", messages=messages, stream=False)
for token in result:
    print(token, end="")

# Пример 2: Создание завершения текста с использованием прокси-сервера
messages = [{"role": "user", "content": "Tell me a joke."}]
result = Vercel.create_completion(model="gpt-3.5-turbo", messages=messages, stream=True, proxy="http://your_proxy:8080")
for token in result:
    print(token, end="")
```

### `get_anti_bot_token`

```python
def get_anti_bot_token() -> str:
    """
    Получает токен для обхода защиты от ботов, используемой Vercel.

    Returns:
        str: Токен защиты от ботов в формате base64.
    """
```

**Назначение**: Функция `get_anti_bot_token` получает токен, используемый для обхода защиты от ботов на сайте Vercel. Этот токен необходим для успешного выполнения запросов к API Vercel.

**Возвращает**:
- `str`: Токен защиты от ботов, закодированный в формате base64.

**Как работает функция**:

1. **Формирование заголовков запроса**:
   - Создает словарь `headers`, содержащий необходимые HTTP-заголовки для запроса к API Vercel.
2. **Получение данных для генерации токена**:
   - Выполняет GET-запрос к `https://sdk.vercel.ai/openai.jpeg`, который возвращает JSON, закодированный в base64.
3. **Декодирование и разбор данных**:
   - Декодирует полученный ответ из base64 и преобразует его в словарь Python.
4. **Формирование JavaScript-скрипта**:
   - Создает JavaScript-скрипт, который использует данные, полученные на предыдущем шаге, для генерации токена.
5. **Выполнение JavaScript-скрипта**:
   - Использует `execjs` для выполнения JavaScript-скрипта и получения токена.
6. **Формирование и кодирование токена**:
   - Формирует JSON-объект, содержащий сгенерированный токен и временную метку.
   - Кодирует JSON-объект в base64.

**ASCII flowchart функции**:

```
A[Формирование заголовков запроса]
|
B[Получение данных с sdk.vercel.ai/openai.jpeg]
|
C[Декодирование и разбор данных JSON из Base64]
|
D[Формирование JavaScript-скрипта]
|
E[Выполнение JavaScript-скрипта с помощью execjs]
|
F[Формирование и кодирование токена в Base64]
```

**Примеры**:

```python
# Пример: Получение токена защиты от ботов
token = get_anti_bot_token()
print(token)
```

## Переменные

### `model_info`

```python
model_info: dict[str, ModelInfo]
```

**Описание**: Словарь, содержащий информацию о поддерживаемых моделях. Ключами словаря являются идентификаторы моделей, а значениями - объекты `ModelInfo`, содержащие идентификатор модели и параметры по умолчанию.