# Модуль AiService

## Обзор

Модуль `AiService` предоставляет класс `AiService`, который является провайдером для взаимодействия с AI Service API. Он используется для создания завершений текста на основе предоставленных сообщений, имитируя поведение чат-бота.

## Подробней

Этот модуль предназначен для интеграции с AI Service API, расположенным по адресу `https://aiservice.vercel.app/`. Он отправляет запросы к API и возвращает сгенерированный текст. Модуль поддерживает модель `gpt-3.5-turbo` и использует HTTP-запросы для взаимодействия с API.

## Классы

### `AiService`

**Описание**:
Класс `AiService` является наследником класса `AbstractProvider` и предоставляет методы для взаимодействия с AI Service API.

**Наследует**:
- `AbstractProvider`: Абстрактный базовый класс для провайдеров.

**Атрибуты**:
- `url` (str): URL-адрес AI Service API (`https://aiservice.vercel.app/`).
- `working` (bool): Указывает, работает ли провайдер (по умолчанию `False`).
- `supports_gpt_35_turbo` (bool): Указывает, поддерживает ли провайдер модель `gpt-3.5-turbo` (по умолчанию `True`).

**Методы**:
- `create_completion`: Создает завершение текста на основе предоставленных сообщений.

## Функции

### `create_completion`

```python
@staticmethod
def create_completion(
    model: str,
    messages: Messages,
    stream: bool,
    **kwargs: Any,
) -> CreateResult:
    """ Функция создает завершение текста на основе предоставленных сообщений.
    Args:
        model (str): Название модели для генерации текста.
        messages (Messages): Список сообщений для передачи в модель.
        stream (bool): Указывает, нужно ли возвращать результат в виде потока.
        **kwargs (Any): Дополнительные аргументы.

    Returns:
        CreateResult: Результат завершения текста.

    Raises:
        requests.exceptions.HTTPError: Если HTTP-запрос завершается с ошибкой.
    """
```

**Назначение**:
Функция `create_completion` отправляет запрос к AI Service API и возвращает сгенерированный текст на основе предоставленных сообщений.

**Параметры**:
- `model` (str): Название модели для генерации текста.
- `messages` (Messages): Список сообщений для передачи в модель.  Сообщения должны быть в формате списка словарей, где каждый словарь имеет ключи `role` (роль отправителя сообщения) и `content` (содержимое сообщения).
- `stream` (bool): Указывает, нужно ли возвращать результат в виде потока.  Если `True`, функция будет генерировать текст по частям.
- `**kwargs` (Any): Дополнительные аргументы.

**Возвращает**:
- `CreateResult`: Результат завершения текста.  Это генератор, который возвращает сгенерированный текст по частям.

**Вызывает исключения**:
- `requests.exceptions.HTTPError`: Если HTTP-запрос завершается с ошибкой.

**Как работает функция**:

1. **Подготовка данных**:
   - Формируется строка `base` из предоставленных сообщений, объединяя роль и содержимое каждого сообщения.
   - Добавляется префикс `"\\nassistant: "` к строке `base`.
2. **Подготовка заголовков**:
   - Определяются заголовки HTTP-запроса, включая `accept`, `content-type`, `sec-fetch-dest`, `sec-fetch-mode`, `sec-fetch-site` и `Referer`.
3. **Подготовка данных для запроса**:
   - Формируется словарь `data` с ключом `"input"` и значением `base`.
4. **Выполнение HTTP-запроса**:
   - Отправляется POST-запрос к AI Service API по адресу `https://aiservice.vercel.app/api/chat/answer` с использованием библиотеки `requests`.
   - В запрос передаются заголовки и данные.
5. **Обработка ответа**:
   - Проверяется статус ответа с помощью `response.raise_for_status()`, чтобы убедиться, что запрос выполнен успешно.
   - Извлекается текст из JSON-ответа (`response.json()["data"]`) и возвращается в виде генератора.

**Внутренние функции**:
В данной функции отсутствуют внутренние функции.

**ASCII flowchart**:

```
A: Подготовка данных (base)
|
B: Подготовка заголовков (headers)
|
C: Подготовка данных для запроса (data)
|
D: Выполнение POST-запроса к AI Service API
|
E: Обработка ответа (извлечение текста)
|
F: Возврат результата в виде генератора
```

**Примеры**:

```python
# Пример использования функции create_completion
messages = [
    {"role": "user", "content": "Привет, как дела?"},
    {"role": "assistant", "content": "Привет! У меня все хорошо, спасибо, что спросили."}
]
model = "gpt-3.5-turbo"
stream = False

result = AiService.create_completion(model=model, messages=messages, stream=stream)
for chunk in result:
    print(chunk, end="")
```
В этом примере функция `create_completion` вызывается с моделью `gpt-3.5-turbo` и списком сообщений. Результат возвращается в виде генератора, и каждый фрагмент текста выводится на экран.
```python
messages = [
    {"role": "user", "content": "Как написать функцию на Python?"}
]
model = "gpt-3.5-turbo"
stream = True

result = AiService.create_completion(model=model, messages=messages, stream=stream)
for chunk in result:
    print(chunk, end="")

```
В этом примере функция `create_completion` вызывается с моделью `gpt-3.5-turbo` и вопросом о написании функции на Python. Результат возвращается в виде потока.