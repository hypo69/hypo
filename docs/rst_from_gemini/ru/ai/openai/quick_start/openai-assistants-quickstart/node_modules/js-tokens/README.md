```markdown
# js-tokens

A regex that tokenizes JavaScript.

This module provides a regular expression for tokenizing JavaScript code.  It's designed to handle a wide range of JavaScript constructs, including strings, comments, regex literals, numbers, identifiers, punctuators, and whitespace.

**Example:**

```javascript
const jsTokens = require("js-tokens").default;

const jsString = "var foo=opts.foo;\n...";

const matches = jsString.match(jsTokens);

console.log(matches);
// Output: Array of matched tokens (e.g., ["var", " ", "foo", "="...])
```


## Installation

```bash
npm install js-tokens
```


## Usage

### `jsTokens`

A regular expression (`RegExp`) with the `g` flag that matches JavaScript tokens.  Importantly, this regex _always_ matches, even on invalid JavaScript and empty strings.  The next match is always directly after the previous.

```javascript
const jsTokens = require("js-tokens").default;
const input = "var x = 123; // comment";

const match = input.match(jsTokens);

if (match) {
	match.forEach((token) => console.log(token)) // Iterate over the matches
} else {
	console.log("No matches found.")
}

```


### `matchToToken(match)`

Converts a match object returned by `jsTokens` to a structured token object.

```javascript
const { matchToToken } = require("js-tokens");
// ... or alternatively import matchToToken directly.

// Example usage (assuming you have a match):
const token = matchToToken(match[0]);
console.log(token); // Output: { type: "string", value: "var x" ...}
```


This function parses the match and returns an object with `type` (e.g., `string`, `comment`, `regex`, `number`, `name`, `punctuator`, `whitespace`, `invalid`) and `value` properties.  For comments and strings, it also provides a `closed` property indicating if the token is closed (important for multi-line comments and strings).

**Key Token Types:**

* `string`, `comment`, `regex`, `number`, `name`, `punctuator`, `whitespace`, `invalid`: self-explanatory.

* `name`: Matches ECMAScript IdentifierNames, which includes identifiers and keywords. Consider using `is-keyword-js` to differentiate keywords.

* `whitespace`: Includes both line terminators and other whitespace characters.


## ECMAScript Support

The module aims to support the latest finalized ECMAScript version.  Major version bumps will signal significant changes. Currently, ECMAScript 2018 is supported.



## Invalid Code Handling

The regex gracefully handles invalid JavaScript code.  Unterminated strings, multi-line comments, and regex literals are still matched as appropriate.  Invalid ASCII characters, and, importantly, invalid non-ASCII characters are handled as names.


## Limitations

Using regexes for tokenization, even with a single complex regex, will have limitations, particularly in handling ambiguous situations (e.g., division vs regex literals). See the documentation for specific caveats (especially regarding division/regex collisions).


## Template String Interpolation

Template strings are treated as a single token, encompassing the opening and closing backticks (`\``), as well as any interpolated expressions.  However, internal expressions are not tokenized individually.


## Division and Regex Literal Collisions

The regex cannot always disambiguate division and regex literals reliably, especially when multiple slashes (`/`) appear on a single line.


## ES2018 Improvements (and why they may be absent)

ES2018 introduced improvements to regular expressions, like Unicode property escapes, lookbehind assertions, and named capture groups. While potentially beneficial, implementing these features could introduce complexity and may not be necessary unless critical. The current approach is prioritized for maintainability and ease of use for now.


## License

[MIT](LICENSE)
```