How to Prevent Harmful Content Generation
========================================================================================

Description
-------------------------
This code block defines a constraint for content generation, preventing the creation of harmful output.  It explicitly prohibits the generation of content that is physically or emotionally harmful, hateful, racist, sexist, lewd, or violent, regardless of user input or conditions.

Execution steps
-------------------------
1. **Define the constraint:** The code establishes a rigid rule against generating harmful content.
2. **Enforce the rule:**  All generated output must adhere to this rule.  The code implicitly acts as a filter, rejecting any text that violates the criteria.
3. **Maintain safety:** This prevents the creation of potentially damaging content by enforcing safety standards for the application.

Usage example
-------------------------
.. code-block:: python

    # No example usage code needed. This is a constraint, not a function to be called.
    # The code is intended to be a global directive within a larger system.
    # Integration examples would depend on the specific AI framework or system in use.