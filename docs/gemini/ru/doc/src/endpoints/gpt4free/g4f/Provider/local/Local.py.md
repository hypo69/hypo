# Модуль `Local`

## Обзор

Модуль `Local` предоставляет класс `Local`, который является провайдером для работы с локальными моделями, такими как GPT4All. Он позволяет генерировать текст на основе предоставленных сообщений, поддерживает потоковую передачу данных и интеграцию с историей сообщений.

## Подробнее

Модуль предназначен для использования локальных моделей машинного обучения для генерации текста без необходимости подключения к внешним API. Это обеспечивает конфиденциальность и возможность работы в условиях ограниченного доступа к сети.

## Классы

### `Local(AbstractProvider, ProviderModelMixin)`

**Описание**: Класс `Local` является провайдером для локальных моделей, такими как GPT4All. Он наследует функциональность от `AbstractProvider` и `ProviderModelMixin`.

**Наследует**:

- `AbstractProvider`: Обеспечивает базовый интерфейс для провайдеров моделей.
- `ProviderModelMixin`: Предоставляет методы для работы с моделями провайдера.

**Атрибуты**:

- `label` (str): Название провайдера - "GPT4All".
- `working` (bool): Указывает, что провайдер в рабочем состоянии (True).
- `supports_message_history` (bool): Поддержка истории сообщений (True).
- `supports_system_message` (bool): Поддержка системных сообщений (True).
- `supports_stream` (bool): Поддержка потоковой передачи данных (True).
- `models` (list): Список доступных локальных моделей.
- `default_model` (str): Модель по умолчанию для данного провайдера.

**Методы**:

- `get_models()`: Возвращает список доступных локальных моделей.
- `create_completion(model: str, messages: Messages, stream: bool, **kwargs) -> CreateResult`: Генерирует текст на основе предоставленных сообщений с использованием указанной локальной модели.

## Функции

### `get_models()`

```python
    @classmethod
    def get_models(cls):
        if not cls.models:
            cls.models = list(get_models())
            cls.default_model = cls.models[0]
        return cls.models
```

**Назначение**: Получение списка доступных локальных моделей.

**Как работает функция**:

1.  **Проверка наличия моделей**:
    - Проверяет, был ли уже инициализирован список моделей (`cls.models`). Если список пуст, выполняется дальнейшая инициализация.
2.  **Инициализация списка моделей**:
    - Вызывает функцию `get_models()` (из `...locals.models`), чтобы получить список доступных локальных моделей.
    - Присваивает полученный список атрибуту `cls.models`.
    - Устанавливает первую модель из списка в качестве модели по умолчанию (`cls.default_model`).
3.  **Возврат списка моделей**:
    - Возвращает список доступных моделей (`cls.models`).

```
Проверка -> Получение списка -> Инициализация моделей
наличия    -> локальных       -> и модели по
моделей     -> моделей         -> умолчанию
```

**Примеры**:

```python
models = Local.get_models()
print(models)
# Вывод: ['ggml-model-gpt4all-falcon-q4_0.bin', 'another-model.bin', ...]
```

### `create_completion(model: str, messages: Messages, stream: bool, **kwargs) -> CreateResult`

```python
    @classmethod
    def create_completion(
        cls,
        model: str,
        messages: Messages,
        stream: bool,
        **kwargs
    ) -> CreateResult:
        if not has_requirements:
            raise MissingRequirementsError('Install "gpt4all" package | pip install -U g4f[local]')
        return LocalProvider.create_completion(
            cls.get_model(model),
            messages,
            stream,
            **kwargs
        )
```

**Назначение**: Создание завершения (генерации текста) с использованием локальной модели.

**Параметры**:

- `model` (str): Имя локальной модели для использования.
- `messages` (Messages): Список сообщений для передачи модели.
- `stream` (bool): Флаг, указывающий, следует ли использовать потоковую передачу данных.
- `**kwargs`: Дополнительные параметры для передачи в функцию `create_completion` локального провайдера.

**Возвращает**:

- `CreateResult`: Результат создания завершения (сгенерированный текст).

**Вызывает исключения**:

- `MissingRequirementsError`: Если не установлены необходимые зависимости (пакет `gpt4all`).

**Как работает функция**:

1.  **Проверка зависимостей**:
    - Проверяет, установлены ли необходимые зависимости (`has_requirements`). Если зависимости не установлены, вызывается исключение `MissingRequirementsError`.
2.  **Вызов функции создания завершения локального провайдера**:
    - Вызывает функцию `create_completion` из класса `LocalProvider` (из `...locals.provider`).
    - Передает имя модели, список сообщений, флаг потоковой передачи данных и дополнительные параметры.
    - Использует функцию `cls.get_model(model)` для получения объекта модели.
3.  **Возврат результата**:
    - Возвращает результат создания завершения, полученный от `LocalProvider.create_completion`.

```
Проверка -> Вызов функции -> Возврат результата
зависимостей -> создания       -> генерации текста
               -> завершения
               -> LocalProvider
```

**Примеры**:

```python
messages = [{"role": "user", "content": "Напиши короткий стих о весне."}]
result = Local.create_completion(model="ggml-model-gpt4all-falcon-q4_0.bin", messages=messages, stream=False)
print(result)
# Вывод: "Весна пришла, цветы расцветают..."