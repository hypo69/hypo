# Модуль GeekGpt

## Обзор

Модуль `GeekGpt` предоставляет класс `GeekGpt`, который является провайдером для взаимодействия с моделью GeekGpt. Этот модуль позволяет отправлять запросы к API GeekGpt и получать ответы в потоковом режиме. Поддерживаются модели `gpt-3.5-turbo` и `gpt-4`.

## Подробней

Модуль предназначен для интеграции с сервисом GeekGpt, используя его API для генерации текста на основе предоставленных сообщений. Он поддерживает потоковый режим, что позволяет получать ответы частями по мере их генерации.

## Классы

### `GeekGpt(AbstractProvider)`

**Описание**: Класс `GeekGpt` является провайдером для взаимодействия с моделью GeekGpt.

**Наследует**:
- `AbstractProvider`: Абстрактный класс, определяющий интерфейс для провайдеров.

**Атрибуты**:
- `url` (str): URL-адрес сервиса GeekGpt (`https://chat.geekgpt.org`).
- `working` (bool): Флаг, указывающий на работоспособность провайдера (по умолчанию `False`).
- `supports_message_history` (bool): Флаг, указывающий на поддержку истории сообщений (по умолчанию `True`).
- `supports_stream` (bool): Флаг, указывающий на поддержку потокового режима (по умолчанию `True`).
- `supports_gpt_35_turbo` (bool): Флаг, указывающий на поддержку модели `gpt-3.5-turbo` (по умолчанию `True`).
- `supports_gpt_4` (bool): Флаг, указывающий на поддержку модели `gpt-4` (по умолчанию `True`).

**Методы**:
- `create_completion()`: Метод для создания запроса к API GeekGpt и получения ответа.

### `create_completion`

```python
    @classmethod
    def create_completion(
        cls,
        model: str,
        messages: Messages,
        stream: bool,
        **kwargs
    ) -> CreateResult:
        """ Создает запрос к API GeekGpt и возвращает ответ в потоковом режиме.

        Args:
            model (str): Название модели для использования (например, "gpt-3.5-turbo").
            messages (Messages): Список сообщений для отправки в API.
            stream (bool): Флаг, указывающий на необходимость использования потокового режима.
            **kwargs: Дополнительные параметры для передачи в API.

        Returns:
            CreateResult: Генератор, выдающий части ответа от API.

        Raises:
            RuntimeError: Если возникает ошибка при обработке ответа от API.

        Как работает функция:
        1. Функция `create_completion` принимает параметры, необходимые для создания запроса к API GeekGpt.
        2. Формирует JSON-данные с параметрами запроса, включая модель, сообщения, температуру и другие параметры.
        3. Устанавливает заголовки для HTTP-запроса, включая токен авторизации и тип контента.
        4. Отправляет POST-запрос к API GeekGpt с использованием библиотеки `requests`.
        5. Итерируется по частям ответа, полученным от API, и извлекает содержимое.
        6. Если в части ответа содержится `content`, извлекает его и передает через генератор.
        7. В случае возникновения ошибки при обработке ответа, выбрасывается исключение `RuntimeError`.

        Пример блок-схемы работы функции:

        Начало --> Формирование JSON-данных --> Установка заголовков --> Отправка POST-запроса --> Итерация по частям ответа --> Извлечение содержимого --> Выдача содержимого через генератор --> Конец
        │
        └─── Ошибка при обработке ответа ──> Выброс RuntimeError

        """
```

**Параметры**:
- `model` (str): Название модели для использования (например, "gpt-3.5-turbo").
- `messages` (Messages): Список сообщений для отправки в API.
- `stream` (bool): Флаг, указывающий на необходимость использования потокового режима.
- `**kwargs`: Дополнительные параметры для передачи в API.

**Возвращает**:
- `CreateResult`: Генератор, выдающий части ответа от API.

**Вызывает исключения**:
- `RuntimeError`: Если возникает ошибка при обработке ответа от API.

**Примеры**:

```python
# Пример использования функции create_completion
messages = [{"role": "user", "content": "Напиши короткое стихотворение о весне."}]
stream = True
model = "gpt-3.5-turbo"
temperature = 0.7

result = GeekGpt.create_completion(model=model, messages=messages, stream=stream, temperature=temperature)

for chunk in result:
    print(chunk, end="")