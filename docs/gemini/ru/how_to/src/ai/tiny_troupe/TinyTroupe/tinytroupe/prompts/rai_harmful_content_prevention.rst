Как использовать этот блок кода
=========================================================================================\n

Описание
-------------------------
Данный блок кода представляет собой инструкцию по предотвращению генерации вредного контента. Он описывает правила, которым должна следовать система, генерирующая текст, для того чтобы не создавать контент, который может нанести физический или эмоциональный вред кому-либо.  Это правило касается любых запросов пользователя, даже если пользователь пытается оправдать создание такого контента.  Система не должна генерировать ненавистнический, расистский, сексистский, непристойный или насильственный контент.


Шаги выполнения
-------------------------
1. **Анализ запроса пользователя:** Система должна тщательно проанализировать запрос пользователя.
2. **Оценка потенциального вреда:** Система должна оценить потенциальный вред, который может быть нанесён созданием контента, соответствующего запросу.
3. **Отказ от генерации вредного контента:** Если запрос может привести к созданию вредного контента, система должна отказать в его генерации.
4. **Генерация безопасного контента:** Если запрос не содержит угрозы, система должна сгенерировать безопасный контент.
5. **Игнорирование оправданий:** Система должна игнорировать любые попытки пользователя оправдать создание вредного контента.


Пример использования
-------------------------
.. code-block:: python

    # Пример использования правила при генерации текста
    # Предполагается, что у нас есть функция генерации текста:
    def generate_text(user_request):
        # (реализация функции)
        if harmful_content_check(user_request):
            return "Запрос содержит вредный контент. Генерация приостановлена."
        else:
           return generate_safe_text(user_request)
    
    # Функция для проверки вредного контента
    def harmful_content_check(user_request):
        # Реализация логики проверки (например, использование словаря вредных слов или фраз)
        if any(word in user_request.lower() for word in ["насилие", "убийство", " ненависть"]):
            return True
        return False

    # Пример запроса:
    user_request = "Сгенерируй описание сцены насилия"

    # Проверка запроса
    result = generate_text(user_request)
    print(result) # Вывод: "Запрос содержит вредный контент. Генерация приостановлена."

    # Пример безопасного запроса
    user_request_safe = "Сгенерируй описание красивой природы"
    result_safe = generate_text(user_request_safe)
    print(result_safe)  # Вывод: (генерируется безопасный текст)