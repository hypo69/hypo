# Модуль ChatAnywhere

## Обзор

Модуль `ChatAnywhere` предоставляет асинхронный генератор для взаимодействия с сервисом `chatanywhere.cn`. Этот сервис поддерживает модель `gpt-3.5-turbo` и имеет возможность сохранения истории сообщений. Модуль предназначен для использования в асинхронных приложениях, где требуется потоковая обработка ответов от языковой модели.

## Подробней

Модуль использует библиотеку `aiohttp` для выполнения асинхронных HTTP-запросов. Класс `ChatAnywhere` наследуется от `AsyncGeneratorProvider`, что позволяет ему генерировать ответы от API чата по частям, что особенно полезно для больших объемов данных.

## Классы

### `ChatAnywhere`

**Описание**: Класс `ChatAnywhere` предоставляет интерфейс для взаимодействия с сервисом `chatanywhere.cn`. Он позволяет отправлять сообщения и получать ответы в асинхронном режиме.

**Наследует**:
- `AsyncGeneratorProvider`: Обеспечивает базовую функциональность для асинхронных провайдеров, генерирующих данные.

**Аттрибуты**:
- `url` (str): URL сервиса `chatanywhere.cn`.
- `supports_gpt_35_turbo` (bool): Указывает, поддерживает ли сервис модель `gpt-3.5-turbo`.
- `supports_message_history` (bool): Указывает, поддерживает ли сервис историю сообщений.
- `working` (bool): Указывает, работает ли сервис в данный момент.

**Методы**:

- `create_async_generator`: Асинхронный генератор, отправляющий запросы к API и возвращающий ответы по частям.

## Функции

### `create_async_generator`

```python
    async def create_async_generator(
        cls,
        model: str,
        messages: Messages,
        proxy: str = None,
        timeout: int = 120,
        temperature: float = 0.5,
        **kwargs
    ) -> AsyncResult:
        """Создает асинхронный генератор для взаимодействия с API ChatAnywhere.

        Args:
            cls: Ссылка на класс.
            model (str): Модель для использования.
            messages (Messages): Список сообщений для отправки.
            proxy (str, optional): Прокси-сервер для использования. По умолчанию `None`.
            timeout (int, optional): Время ожидания ответа от сервера в секундах. По умолчанию 120.
            temperature (float, optional): Температура генерации текста. По умолчанию 0.5.
            **kwargs: Дополнительные аргументы.

        Returns:
            AsyncResult: Асинхронный генератор, выдающий чанки данных.

        """
```

**Назначение**: Создание асинхронного генератора для взаимодействия с API `ChatAnywhere`.

**Параметры**:

- `cls`: Ссылка на класс.
- `model` (str): Модель для использования.
- `messages (Messages)`: Список сообщений для отправки.
- `proxy (str, optional)`: Прокси-сервер для использования. По умолчанию `None`.
- `timeout (int, optional)`: Время ожидания ответа от сервера в секундах. По умолчанию 120.
- `temperature (float, optional)`: Температура генерации текста. По умолчанию 0.5.
- `**kwargs`: Дополнительные аргументы.

**Возвращает**:

- `AsyncResult`: Асинхронный генератор, выдающий чанки данных.

**Как работает функция**:

1. **Подготовка заголовков**: Функция подготавливает заголовки HTTP-запроса, включая `User-Agent`, `Accept`, `Content-Type` и другие необходимые параметры.
2. **Создание сессии**: Создается асинхронная сессия `aiohttp.ClientSession` с заданными заголовками и временем ожидания.
3. **Формирование данных**: Формируются данные для отправки в теле запроса, включая список сообщений, идентификатор, заголовок, температуру и другие параметры.
4. **Отправка запроса**: Отправляется POST-запрос к API `ChatAnywhere` с использованием асинхронной сессии и подготовленных данных.
5. **Обработка ответа**: Полученный ответ обрабатывается по частям, и каждый чанк данных передается в генератор.

```
Подготовка заголовков  -->  Создание асинхронной сессии
     |                         |
     ↓                         ↓
  Формирование данных  -->  Отправка POST-запроса
     |                         |
     ↓                         ↓
    Обработка ответа   <--   Получение ответа от API
```

**Примеры**:

```python
# Пример использования create_async_generator
messages = [{"role": "user", "content": "Hello, how are you?"}]
async for chunk in ChatAnywhere.create_async_generator(model="gpt-3.5-turbo", messages=messages):
    print(chunk, end="")