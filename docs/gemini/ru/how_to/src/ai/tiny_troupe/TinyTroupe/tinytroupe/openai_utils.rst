Как использовать этот блок кода
=========================================================================================

Описание
-------------------------
Этот код определяет классы и функции для взаимодействия с API OpenAI. Он предоставляет способ отправлять запросы на получение текстовых ответов (LLM calls), получать эмбеддинги и кешировать вызовы API.  Код обрабатывает конфигурацию из файла `config.ini`, позволяя гибко настраивать параметры, такие как модель, количество токенов, температуру и кеширование.  Также реализованы механизмы обработки ошибок и экспоненциального замедления для повышения стабильности при работе с API.  Код поддерживает выбор между OpenAI и Azure OpenAI Service.

Шаги выполнения
-------------------------
1. **Импорт необходимых библиотек**: Код импортирует необходимые библиотеки, такие как `openai`, `time`, `json`, `pickle`, `logging`, `configparser`, `tiktoken` и пользовательские утилиты.
2. **Чтение конфигурации**: Функция `utils.read_config_file()` читает конфигурацию из файла `config.ini`.  Это позволяет настраивать параметры для работы с OpenAI API.
3. **Установка значений по умолчанию**: Определяет значения по умолчанию для параметров, используемых в API вызовах. Эти значения могут быть переопределены конфигурацией.
4. **Определение класса `LLMCall`**:  Этот класс представляет вызов модели LLM и содержит необходимые параметры.
    - Метод `__init__` инициализирует класс с именем шаблонов для системных и пользовательских сообщений, а также другими параметрами модели.
    - Метод `call` собирает сообщения, передаёт параметры в вызов модели LLM и возвращает сгенерированный текст, если запрос был успешным.
5. **Определение класса `OpenAIClient`**: Этот класс предоставляет методы для взаимодействия с API OpenAI, включая кеширование вызовов и поддержку различных параметров API.
    - Метод `__init__` инициализирует экземпляр класса, определяя, нужно ли кешировать вызовы и имя файла для кеша.
    - Метод `set_api_cache` включает/выключает кеширование и загружает кеш, если он существует.
    - Метод `_setup_from_config` настраивает OpenAI API в зависимости от API ключа.
    - Метод `send_message` отправляет сообщение в API OpenAI, обрабатывает возможные ошибки, такие как RateLimitError и InvalidRequestError, и кеширует результат вызова. Он также реализует экспоненциальное замедление для обработки потенциальных ограничений скорости.
    - Методы `_raw_model_call`, `_raw_model_response_extractor`, `_count_tokens`, `_save_cache`, `_load_cache`, `get_embedding`, `_raw_embedding_model_call`, `_raw_embedding_model_response_extractor` реализуют низкоуровневое взаимодействие с API OpenAI и кешированием.
6. **Регистрация клиентов**:  Регистрирует клиентов OpenAI и Azure в словаре `_api_type_to_client` для выбора нужного клиента.
7. **Функция `client()`**:  Возвращает зарегистрированного клиента, соответствующего типу API, который указан в конфигурации.


Пример использования
-------------------------
.. code-block:: python

    import os
    # ... (импорты из исходного кода)

    # Установите API-ключ для OpenAI
    os.environ["OPENAI_API_KEY"] = "YOUR_OPENAI_API_KEY"
    # Установите API-ключ для Azure OpenAI Service
    os.environ["AZURE_OPENAI_ENDPOINT"] = "YOUR_AZURE_OPENAI_ENDPOINT"
    os.environ["AZURE_OPENAI_KEY"] = "YOUR_AZURE_OPENAI_KEY"
    
    # Настройка
    config = utils.read_config_file()  # Должно быть определено в utils.py
    
    messages = [
        {"role": "user", "content": "What is the capital of France?"}
    ]
    
    client = client() # Использует OpenAI или Azure в зависимости от конфигурации.
    response = client.send_message(current_messages=messages)
    
    if response:
        print(response)