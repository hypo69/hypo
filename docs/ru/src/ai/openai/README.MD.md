# Модуль src.ai.openai

## Обзор

Данный модуль предназначен для интеграции с OpenAI и содержит инструменты для работы с различными сервисами OpenAI. Включает в себя классы и функции для взаимодействия с моделями OpenAI, обработки текста, выполнения запросов к API и управления токенами.

## Подробнее

Этот модуль обеспечивает основу для использования возможностей OpenAI в проекте `hypotez`. Он включает функциональность для аутентификации, обработки запросов и управления ответами от API OpenAI. Модуль разработан с учетом требований к производительности и надежности, обеспечивая эффективное взаимодействие с сервисами OpenAI.

## Содержание

- [Функции](#Функции)

## Функции

### `j_loads`

```python
def j_loads(path: str) -> Optional[dict]:
    """
    Загружает JSON-файл, возвращает его как словарь.

    Args:
        path (str): Путь к JSON-файлу.

    Returns:
        Optional[dict]: Словарь, представляющий JSON-файл, или None в случае ошибки.
    """
```

**Назначение**: Загрузка содержимого JSON-файла и преобразование его в словарь Python.

**Как работает функция**:
Функция принимает путь к JSON-файлу. Она пытается открыть файл, прочитать его содержимое и преобразовать его в словарь Python с использованием модуля `json`. В случае успешного выполнения возвращается словарь. Если во время выполнения возникают какие-либо исключения (например, файл не найден или имеет неверный формат), функция перехватывает исключение, логирует ошибку и возвращает `None`.

**Параметры**:
- `path` (str): Путь к JSON-файлу.

**Возвращает**:
- `Optional[dict]`: Словарь, представляющий JSON-файл, или `None` в случае ошибки.

**Вызывает исключения**:
- `FileNotFoundError`: Если указанный файл не найден.
- `JSONDecodeError`: Если JSON-файл имеет неверный формат.

### `j_dumps`

```python
def j_dumps(data: dict, path: str) -> None:
    """
    Сохраняет словарь в JSON-файл.

    Args:
        data (dict): Словарь для сохранения в JSON-файл.
        path (str): Путь к JSON-файлу.

    Returns:
        None
    """
```

**Назначение**: Сохранение словаря Python в файл в формате JSON.

**Как работает функция**:
Функция принимает словарь `data` и путь к файлу `path`. Она открывает файл по указанному пути для записи и записывает содержимое словаря в файл в формате JSON с использованием функции `json.dump`. Указывается кодировка `utf-8` для поддержки различных символов. В случае возникновения ошибки во время записи, функция перехватывает исключение, логирует ошибку с использованием модуля `logger`, и завершает свою работу.

**Параметры**:
- `data` (dict): Словарь для сохранения в JSON-файл.
- `path` (str): Путь к JSON-файлу.

**Возвращает**:
- `None`

**Вызывает исключения**:
- `TypeError`: Если `data` не является словарем.
- `IOError`: Если возникает ошибка при записи в файл.

### `count_tokens`

```python
def count_tokens(text: str) -> int:
    """
    Считает количество токенов в тексте.

    Args:
        text (str): Текст для подсчета токенов.

    Returns:
        int: Количество токенов в тексте.
    """
```

**Назначение**: Подсчет количества токенов в заданном тексте.

**Как работает функция**:
Функция принимает строку текста `text` в качестве аргумента. Она использует метод `split()` для разделения текста на отдельные слова (токены). Затем функция возвращает общее количество полученных токенов, которое соответствует количеству слов в тексте.

**Параметры**:
- `text` (str): Текст для подсчета токенов.

**Возвращает**:
- `int`: Количество токенов в тексте.

**Примеры**:
```python
>>> count_tokens("Это пример текста.")
3
>>> count_tokens("Hello world!")
2
```

### `limit_tokens`

```python
def limit_tokens(text: str, max_tokens: int = 2048) -> str:
    """
    Обрезает текст до указанного количества токенов.

    Args:
        text (str): Текст для обрезки.
        max_tokens (int): Максимальное количество токенов в обрезанном тексте. По умолчанию 2048.

    Returns:
        str: Обрезанный текст.
    """
```

**Назначение**: Обрезает входной текст до заданного максимального количества токенов.

**Как работает функция**:
Функция `limit_tokens` принимает текст и максимальное количество токенов в качестве аргументов. Сначала текст разбивается на токены с использованием метода `split()`. Затем, если количество токенов превышает `max_tokens`, функция обрезает список токенов до `max_tokens`. Наконец, обрезанные токены объединяются обратно в строку с использованием метода `join()`, и эта строка возвращается. Если количество токенов в исходном тексте меньше или равно `max_tokens`, возвращается исходный текст без изменений.

**Параметры**:
- `text` (str): Текст, который нужно обрезать.
- `max_tokens` (int): Максимальное количество токенов, до которого нужно обрезать текст. По умолчанию 2048.

**Возвращает**:
- `str`: Обрезанный текст, содержащий не более `max_tokens` токенов.

**Примеры**:
```python
>>> limit_tokens("Это пример текста для обрезки.", max_tokens=3)
'Это пример текста'

>>> limit_tokens("Hello world!", max_tokens=5)
'Hello world!'
```