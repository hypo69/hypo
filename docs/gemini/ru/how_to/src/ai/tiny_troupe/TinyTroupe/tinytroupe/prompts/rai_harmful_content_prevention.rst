Как использовать этот блок кода
=========================================================================================

Описание
-------------------------
Этот блок кода описывает ограничение генерации вредного контента.  Он устанавливает правила, по которым модель не должна генерировать контент, который может нанести физический или эмоциональный вред кому-либо, даже если пользователь запрашивает или создаёт условия для оправдания такого контента. Также запрещается генерировать ненавистнический, расистский, сексистский, непристойный или насильственный контент.

Шаги выполнения
-------------------------
1. **Проверка входных данных:** Модель анализирует текст, который пользователь предоставляет для генерации.
2. **Оценка соответствия правилам:** Модель сравнивает входные данные с перечнем запрещённых типов контента (вредный, ненавистнический, расистский, сексистский, непристойный, насильственный).
3. **Отказ от генерации:** Если входные данные или предполагаемый результат генерации соответствуют одному из запрещённых типов контента, модель отказывается от генерации, не создавая его.
4. **Возврат сообщения об ошибке (при необходимости):** Модель может возвращать сообщение об ошибке пользователю, если контент, который он запросил, нарушает установленные правила.


Пример использования
-------------------------
.. code-block:: python

    # Пример запроса пользователя
    user_input = "Сгенерируй текст, описывающий жестокое убийство."

    # Проверка кодом
    if harmful_content_check(user_input):
        print("Запрос содержит запрещённый контент. Генерация прекращена.")
    else:
        generated_text = generate_text(user_input)
        print(generated_text)