```markdown
# OpenAI Node API Library

[![NPM version](https://img.shields.io/npm/v/openai.svg)](https://npmjs.org/package/openai)

This library provides convenient access to the OpenAI REST API from TypeScript or JavaScript.  It's generated from our OpenAPI specification and leverages Stainless.

To get started with the OpenAI API, consult our [API Reference](https://platform.openai.com/docs/api-reference) and [general documentation](https://platform.openai.com/docs).


## Installation

```bash
npm install openai
```

or for Deno:

<!-- x-release-please-start-version -->

```typescript
import OpenAI from 'https://deno.land/x/openai@v4.46.0/mod.ts';
```

<!-- x-release-please-end -->


## Usage

Detailed API documentation, including code examples, is available in [api.md](api.md).  Here's a basic example for chat completions:

```typescript
import OpenAI from 'openai';

const openai = new OpenAI({
  apiKey: process.env['OPENAI_API_KEY'], // Set your API key here
});

async function main() {
  const chatCompletion = await openai.chat.completions.create({
    messages: [{ role: 'user', content: 'Say this is a test' }],
    model: 'gpt-3.5-turbo',
  });
  console.log(chatCompletion); // Outputs the response
}

main();
```


## Streaming Responses

Utilize Server-Sent Events (SSE) for efficient streaming responses:

```typescript
import OpenAI from 'openai';

const openai = new OpenAI();

async function main() {
  const stream = await openai.chat.completions.create({
    model: 'gpt-4',
    messages: [{ role: 'user', content: 'Generate a poem.' }],
    stream: true,
  });
  for await (const chunk of stream) {
    console.log(chunk.choices[0]?.delta?.content || '');
  }
}

main();
```


## TypeScript Support

This library provides rich TypeScript definitions for all request parameters and response fields.  This improves type safety and developer experience.

```typescript
import OpenAI from 'openai';

const openai = new OpenAI({ apiKey: process.env['OPENAI_API_KEY'] });

async function main() {
  const params: OpenAI.Chat.ChatCompletionCreateParams = {
    messages: [{ role: 'user', content: 'What is the capital of France?' }],
    model: 'gpt-3.5-turbo',
  };
  const chatCompletion: OpenAI.Chat.ChatCompletion = await openai.chat.completions.create(params);
  console.log(chatCompletion.choices[0].message.content); // Access response data
}

main();
```

## Polling Helpers

For asynchronous API actions (like Run creation), use polling helpers to wait for completion.

```typescript
const run = await openai.beta.threads.runs.createAndPoll(threadId, {
  assistant_id: assistantId,
});
```

## File Uploads

This library provides methods to handle file uploads, utilizing `ReadStream`, `File`, and other formats for various API endpoints.  See the full docs for details.


## Error Handling

Handles potential API errors with specific error types for better debugging.

```typescript
try {
  // ... your API call ...
} catch (err) {
  if (err instanceof OpenAI.APIError) {
    console.error("API Error:", err.message, err.status, err.response); // Log detailed error information
  } else {
    console.error("An unexpected error occurred:", err);
  }
}
```


## Further Resources

- [Detailed API Reference](api.md)
- [Code Examples](https://github.com/openai/openai-node/tree/master/examples)
- [v3 to v4 Migration Guide](https://github.com/openai/openai-node/discussions/217)
- [Streaming Helpers Documentation](helpers.md)


## Requirements

TypeScript >= 4.5, Node.js 18 LTS (or later), Deno, Bun, and more are supported.  See the complete list in the README.


```
```