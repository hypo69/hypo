# Модуль для работы с нейронными сетями
==========================================

Модуль содержит класс :class:`neural_networks`, который предоставляет методы для взаимодействия с различными нейронными сетями, такими как FLUX.1-schnell, mistral_large_2407 и free_gpt_4o_mini.

## Обзор

Этот модуль предоставляет класс `neural_networks`, который инкапсулирует функциональность для взаимодействия с различными нейронными сетями. Он включает методы для генерации изображений на основе текстовых запросов и получения ответов на запросы на основе предоставленных сообщений. Модуль использует внешние API, такие как Hugging Face и Mistral AI, для выполнения этих задач.

## Подробней

Данный код предоставляет класс для работы с различными нейронными сетями. Этот класс содержит методы для отправки запросов к API нейронных сетей и обработки полученных ответов. Он используется для генерации изображений на основе текстовых запросов и получения ответов на запросы на основе предоставленных сообщений.

## Классы

### `neural_networks`

**Описание**: Класс для работы с нейронными сетями.

**Принцип работы**: Класс содержит методы для взаимодействия с различными нейронными сетями, такими как FLUX.1-schnell, mistral_large_2407 и free_gpt_4o_mini. Он использует внешние API для выполнения этих задач.

**Методы**:
- `_FLUX_schnell`: Отправляет запрос к нейронной сети FLUX.1-schnell для генерации изображения на основе текстового запроса.
- `__mistral_large_2407`: Отправляет запрос к нейронной сети mistral_large_2407 для получения ответа на запрос на основе предоставленных сообщений.
- `_free_gpt_4o_mini`: Отправляет запрос к нейронной сети free_gpt_4o_mini для получения ответа на запрос на основе предоставленных сообщений.

## Функции

### `_FLUX_schnell`

```python
def _FLUX_schnell(self, prompt: str, size: list[int, int], seed: int, num_inference_steps: int) -> str|None:
    """
    Отправляет запрос к нейронной сети FLUX.1-schnell для генерации изображения на основе текстового запроса.

    Args:
        prompt (str): Текстовый запрос для генерации изображения.
        size (list[int, int]): Размеры изображения (ширина, высота).
        seed (int): Зерно для генерации случайных чисел.
        num_inference_steps (int): Количество шагов для генерации изображения.

    Returns:
        str | None: Изображение в формате PIL Image или `None` в случае ошибки.
    """
    ...
```

**Назначение**: Отправляет запрос к нейронной сети FLUX.1-schnell для генерации изображения на основе текстового запроса.

**Параметры**:
- `prompt` (str): Текстовый запрос для генерации изображения.
- `size` (list[int, int]): Размеры изображения (ширина, высота).
- `seed` (int): Зерно для генерации случайных чисел.
- `num_inference_steps` (int): Количество шагов для генерации изображения.

**Возвращает**:
- `str | None`: Изображение в формате PIL Image или `None` в случае ошибки.

**Как работает функция**:

1. Формирует полезную нагрузку (payload) с текстовым запросом, параметрами генерации изображения (размеры, зерно, количество шагов) и коэффициентом масштабирования.
2. Последовательно выполняет запросы к API Hugging Face, используя разные токены авторизации (HF_TOKEN1 - HF_TOKEN6).
3. Если запрос успешен (код состояния 200), открывает изображение из полученных байтов и возвращает его. Если ни один из запросов не успешен, функция ничего не возвращает.

**ASCII flowchart**:

```
A: Формирование payload
|
B: Цикл по токенам HF_TOKEN1 - HF_TOKEN6
|
C: Отправка POST запроса к API Hugging Face
|
D: Проверка status_code == 200
|
E (status_code == 200): Открытие изображения из байтов
|
F (status_code != 200): Переход к следующему токену
|
G: Возврат изображения
```

**Примеры**:

```python
# Пример вызова функции _FLUX_schnell
prompt = "A beautiful landscape"
size = [512, 512]
seed = 42
num_inference_steps = 50
image = neural_networks()._FLUX_schnell(prompt, size, seed, num_inference_steps)
if image:
    print("Изображение успешно сгенерировано")
    # image.show()  # Отобразить изображение
else:
    print("Не удалось сгенерировать изображение")
```

### `__mistral_large_2407`

```python
def __mistral_large_2407(self, prompt: list[dict[str, str]]) -> tuple[str, int, int]|str:
    """
    Отправляет запрос к нейронной сети mistral_large_2407 для получения ответа на запрос на основе предоставленных сообщений.

    Args:
        prompt (list[dict[str, str]]): Список сообщений для отправки в нейронную сеть.

    Returns:
        tuple[str, int, int] | str: Ответ нейронной сети, количество использованных токенов для запроса и ответа.
    """
    ...
```

**Назначение**: Отправляет запрос к нейронной сети mistral_large_2407 для получения ответа на запрос на основе предоставленных сообщений.

**Параметры**:
- `prompt` (list[dict[str, str]]): Список сообщений для отправки в нейронную сеть.

**Возвращает**:
- `tuple[str, int, int] | str`: Ответ нейронной сети, количество использованных токенов для запроса и ответа.

**Как работает функция**:

1.  **Формирование запроса**: Функция формирует словарь `data`, который включает в себя список сообщений (`prompt`), параметры температуры, `top_p`, максимальное количество токенов и имя модели (`pixtral-12b-2409`).
2.  **Отправка запроса**: Отправляет POST-запрос к API Mistral AI (`https://api.mistral.ai/v1/chat/completions`) с использованием библиотеки `requests`. Запрос включает в себя заголовок `Content-Type: application/json` и токен авторизации, полученный из переменной окружения `MISTRAL_TOKEN`.
3.  **Обработка ответа**: После получения ответа, функция преобразует текст ответа из формата JSON в словарь Python. Затем извлекает текст сообщения из `response["choices"][0]["message"]`, а также количество токенов, использованных для запроса и ответа, из `response["usage"]["prompt_tokens"]` и `response["usage"]["completion_tokens"]` соответственно.
4.  **Возврат данных**: Функция возвращает кортеж, содержащий текст сообщения, количество использованных токенов для запроса и количество токенов для ответа.

**ASCII flowchart**:

```
A: Формирование запроса (data)
|
B: Отправка POST запроса к API Mistral AI
|
C: Преобразование JSON ответа в словарь Python
|
D: Извлечение текста сообщения и количества токенов
|
E: Возврат кортежа (текст сообщения, токены запроса, токены ответа)
```

**Примеры**:

```python
# Пример вызова функции __mistral_large_2407
prompt = [{"role": "user", "content": "Hello, how are you?"}]
response = neural_networks().__mistral_large_2407(prompt)
print(f"Ответ: {response[0]}")
print(f"Токены запроса: {response[1]}")
print(f"Токены ответа: {response[2]}")
```

### `_free_gpt_4o_mini`

```python
def _free_gpt_4o_mini(self, prompt: list[dict[str, str]]) -> tuple[str, int, int]|str:
    """
    Отправляет запрос к нейронной сети free_gpt_4o_mini для получения ответа на запрос на основе предоставленных сообщений.

    Args:
        prompt (list[dict[str, str]]): Список сообщений для отправки в нейронную сеть.

    Returns:
        tuple[str, int, int] | str: Ответ нейронной сети, количество использованных токенов для запроса и ответа.
    """
    ...
```

**Назначение**: Отправляет запрос к нейронной сети free_gpt_4o_mini для получения ответа на запрос на основе предоставленных сообщений.

**Параметры**:
- `prompt` (list[dict[str, str]]): Список сообщений для отправки в нейронную сеть.

**Возвращает**:
- `tuple[str, int, int] | str`: Ответ нейронной сети, количество использованных токенов для запроса и ответа.

**Как работает функция**:

1.  **Формирование запроса**: Функция формирует словарь `data`, который включает в себя список сообщений (`prompt`), параметры температуры, `top_p`, максимальное количество токенов и имя модели (`gpt-4o-mini`).
2.  **Отправка запроса**: Функция пытается отправить POST-запрос к API `models.inference.ai.azure.com` несколько раз (до 6 раз), используя разные токены авторизации из переменных окружения `GIT_TOKEN{i}`. Если запрос успешен (код состояния 200), функция преобразует ответ из JSON в словарь Python и извлекает текст сообщения из `response["choices"][0]["message"]`, а также количество токенов, использованных для запроса и ответа, из `response["usage"]["prompt_tokens"]` и `response["usage"]["completion_tokens"]` соответственно.
3.  **Обработка неудачи**: Если ни один из запросов к `free_gpt_4o_mini` не удался (например, из-за проблем с аутентификацией или сетью), функция переключается на использование `__mistral_large_2407` для обработки запроса.
4.  **Возврат данных**: Функция возвращает кортеж, содержащий текст сообщения, количество использованных токенов для запроса и количество токенов для ответа.

**ASCII flowchart**:

```
A: Формирование запроса (data)
|
B: Цикл по токенам GIT_TOKEN1 - GIT_TOKEN6
|
C: Отправка POST запроса к API models.inference.ai.azure.com
|
D: Проверка status_code == 200
|
E (status_code == 200): Преобразование JSON ответа в словарь Python, извлечение текста и токенов
|
F (status_code != 200): Переход к следующему токену
|
G: Если все токены исчерпаны, вызов __mistral_large_2407(prompt)
|
H: Возврат кортежа (текст сообщения, токены запроса, токены ответа)
```

**Примеры**:

```python
# Пример вызова функции _free_gpt_4o_mini
prompt = [{"role": "user", "content": "Translate 'Hello, how are you?' to Russian."}]
response = neural_networks()._free_gpt_4o_mini(prompt)
print(f"Ответ: {response[0]}")
print(f"Токены запроса: {response[1]}")
print(f"Токены ответа: {response[2]}")