# TinyTroupe: Responsible AI FAQ

## Обзор

Данный документ содержит часто задаваемые вопросы (FAQ) по библиотеке TinyTroupe, предназначенной для моделирования поведения людей с определенными личностями, интересами и целями.  Документ описывает возможности, ограничения и принципы ответственного использования библиотеки.

## Содержание

* [Что такое TinyTroupe?](#что-такое-tinytroupe)
* [Что может делать TinyTroupe?](#что-может-делать-tinytroupe)
* [Каково/каковы предполагаемое/ые использование/ия TinyTroupe?](#каковокаковы-предполагаемоеые-использованиеия-tinytroupe)
* [Как оценивался TinyTroupe? Какие метрики используются для измерения производительности?](#как-оценивался-tinytroupe-какие-метрики-используются-для-измерения-производительности)
* [Какие ограничения у TinyTroupe? Как пользователи могут минимизировать влияние ограничений TinyTroupe при использовании системы?](#какие-ограничения-у-tinytroupe-как-пользователи-могут-минимизировать-влияние-ограничений-tinytroupe-при-использовании-системы)
* [Какие операционные факторы и настройки позволяют эффективно и ответственно использовать TinyTroupe?](#какие-операционные-факторы-и-настройки-позволяют-эффективно-и-ответственно-использовать-tinytroupe)


## Что такое TinyTroupe?

*TinyTroupe* — это экспериментальная Python-библиотека, позволяющая моделировать людей с конкретными личностями, интересами и целями. Эти искусственные агенты — `TinyPerson` — могут слушать нас и друг друга, отвечать и действовать в имитируемых средах `TinyWorld`. Это достигается за счет использования возможностей больших языковых моделей (LLM), в частности GPT-4, для генерации реалистичного имитируемого поведения. Это позволяет исследовать широкий спектр реалистичных взаимодействий и типов потребителей с высоконастраиваемыми персонами в заданных условиях.  Фокус на понимании поведения человека, а не на его непосредственной поддержке (как, например, в случае с помощниками на основе ИИ). Это приводит к специализированным механизмам и решениям, имеющим смысл только в имитационной среде.  Это имеет последствия для аспектов ответственного ИИ, как описано в остальной части данного FAQ.

Подход TinyTroupe — программистский: симуляции определяются как программы Python, использующие элементы TinyTroupe, и затем выполняются. Входные данные для симуляции включают описание персон (например, возраст, национальность, местоположение, интересы, работа и т. д.) и диалоги (например, программист может «разговаривать» с агентами). Выходные данные включают мысли и слова агентов, а также структурированные выдержки из них (например, сводка диалогов).


## Что может делать TinyTroupe?

TinyTroupe сама по себе не является моделью искусственного интеллекта (ИИ) или машинного обучения (МО). Вместо этого она полагается на внешние API для обеспечения своих интеллектуальных возможностей.  TinyTroupe предоставляет элементы для:

* моделирования персон агентов, включая их мысли и слова;
* моделирования сред, в которых агенты взаимодействуют;
* извлечения структурированных данных из симуляций для последующего использования (например, JSON с различными извлеченными элементами);
* обогащения артефактов симуляций для повышения реалистичности;
* предоставления помощи в рассказываниях для повышения интереса к симуляции.

## Каково/каковы предполагаемое/ые использование/ия TinyTroupe?

TinyTroupe предназначена для:

* анализа поведения искусственных людей посредством моделирования;
* генерации синтетических артефактов посредством моделирования;
* дополнения, а не замены, генерации идей человеком;
* исследования различных возможностей вычислительных когнитивных архитектур, которые могут или не могут отражать реальную когнитивную деятельность человека.

TinyTroupe НЕ предназначена для:

* прямого взаимодействия с пользователями. Вместо этого программисты, использующие TinyTroupe для создания продуктов, должны создать собственный уровень ответственного ИИ для обеспечения соответствия результатов моделирования.
* принятия решений по политике или иным последствиям. Любое решение, принятое с использованием симуляций TinyTroupe, должно учитывать то, что результаты симуляций могут не отражать реальность, и поэтому их следует использовать очень осторожно для всего, что имеет последствия в реальном мире.


## Как оценивался TinyTroupe? Какие метрики используются для измерения производительности?

TinyTroupe была оценена в различных сценариях использования, часть из которых приведена в качестве примеров в библиотеке. Она подходит для использования в этих сценариях в той степени, в которой это демонстрируют примеры. Всё, что выходит за рамки этого, остаётся исследовательской и экспериментальной работой. Обширное тестирование отдельных модулей и сценариев также является частью библиотеки.


## Какие ограничения у TinyTroupe? Как пользователи могут минимизировать влияние ограничений TinyTroupe при использовании системы?

TinyTroupe НЕ доказала способность отражать реальное поведение человека, и поэтому любая такая возможность остаётся лишь исследовательской или экспериментальной работой. Хотя в ходе наших различных тестов это не наблюдалось, TinyTroupe теоретически способна генерировать результаты, которые могут считаться злонамеренными. Причина этого заключается в том, что важным теоретическим сценарием использования TinyTroupe является проверка других систем ИИ на выявление подобных злонамеренных выходов, так что ничего не ограничивает её от моделирования зловредных актеров. ПОЭТОМУ программисты, использующие TinyTroupe для создания собственных продуктов или услуг, ДОЛЖНЫ предоставить свои собственные гарантии ответственного ИИ, поскольку сама TinyTroupe не предназначена для ограничения выходов таким образом. То же самое относится к любым другим базовым библиотекам LLM, таким как LangChain или Semantic Kernel, которые, так же как и TinyTroupe, являются всего лишь ИНСТРУМЕНТАМИ, которые следует использовать с осторожностью.


## Какие операционные факторы и настройки позволяют эффективно и ответственно использовать TinyTroupe?

TinyTroupe можно использовать ответственно,

* используя внешние API моделей, которые сами по себе предоставляют механизмы безопасности (например, Azure OpenAI предоставляет обширные ресурсы для этого);
* предоставляя подходящие описания персон (то есть не злонамеренные персоны);
* не провоцировать истории симуляций или поведение агентов для генерации злонамерственного контента. Если это делается, необходимо понимать, что единственно допустимое использование этого — проверка других систем ИИ на выявление нежелательных выходов;
* НЕ допускать контроля симуляций реальных механизмов, если не предусмотрены соответствующие механизмы контроля ущерба для предотвращения реального вреда;
* если вы используете TinyTroupe в качестве основы для собственного продукта или сервиса, ВЫ ДОЛЖНЫ обеспечить собственные гарантии ответственного ИИ, такие как проверка выходов.