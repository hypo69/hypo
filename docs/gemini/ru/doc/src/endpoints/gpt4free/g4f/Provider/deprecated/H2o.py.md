# Модуль для взаимодействия с H2O.ai
## Обзор

Модуль `H2o.py` предоставляет асинхронный интерфейс для взаимодействия с моделью `h2oai/h2ogpt-gm-oasst1-en-2048-falcon-40b-v1` на платформе `gpt-gm.h2o.ai`. Он позволяет отправлять запросы к модели и получать ответы в виде асинхронного генератора.

## Подробней

Модуль предназначен для интеграции с другими частями проекта `hypotez`, требующими доступа к возможностям языковой модели H2O. Он использует асинхронные запросы для обеспечения неблокирующего взаимодействия с API.

## Классы

### `H2o`

**Описание**: Класс `H2o` предоставляет функциональность для взаимодействия с сервисом `gpt-gm.h2o.ai`.

**Наследует**:
- `AsyncGeneratorProvider`: H2o наследует `AsyncGeneratorProvider`

**Атрибуты**:
- `url` (str): Базовый URL для взаимодействия с API H2O.
- `model` (str): Наименование используемой модели. В данном случае `h2oai/h2ogpt-gm-oasst1-en-2048-falcon-40b-v1`.

**Методы**:
- `create_async_generator`: Создаёт асинхронный генератор для получения ответов от модели.

## Функции

### `create_async_generator`

```python
    @classmethod
    async def create_async_generator(
        cls,
        model: str,
        messages: Messages,
        proxy: str = None,
        **kwargs
    ) -> AsyncResult:
        """
        Создает асинхронный генератор для получения ответов от модели H2O.

        Args:
            model (str): Название модели, которую необходимо использовать.
            messages (Messages): Список сообщений для отправки в модель.
            proxy (str, optional): Адрес прокси-сервера для использования. По умолчанию `None`.
            **kwargs: Дополнительные параметры для передачи в модель.

        Returns:
            AsyncResult: Асинхронный генератор, возвращающий текстовые фрагменты ответа модели.
        """
```

**Назначение**: Создает асинхронный генератор, который отправляет сообщения в модель H2O и возвращает результаты в виде асинхронного потока текста.

**Параметры**:
- `cls`: Ссылка на класс. Используется для доступа к атрибутам класса, таким как `url` и `model`.
- `model` (str): Имя модели, которую нужно использовать. Если не указано, используется значение по умолчанию из атрибута `cls.model`.
- `messages` (Messages): Список сообщений, отформатированных для отправки в модель.
- `proxy` (str, optional): URL прокси-сервера (если требуется). По умолчанию `None`.
- `kwargs (dict): Дополнительные параметры конфигурации, которые будут переданы модели.

**Возвращает**:
- `AsyncResult`: Асинхронный генератор, который выдает текстовые фрагменты ответа от модели H2O.

**Как работает функция**:

1. **Инициализация**:
   - Функция `create_async_generator` принимает параметры, необходимые для запроса к модели H2O.
   - Если `model` не указана, используется значение по умолчанию `cls.model`.
   - Определяются заголовки (`headers`), включающие `Referer` для указания источника запроса.
   ```
   Начало
       ↓
   Установка параметров (модель, сообщения, прокси)
       ↓
   Инициализация ClientSession с заголовками
   ```
2. **Создание асинхронной сессии**:
   - Используется `aiohttp.ClientSession` для выполнения асинхронных HTTP-запросов.
   - В сессию передаются заголовки.
   ```
       ↓
   Отправка POST запроса к /settings для принятия условий
       ↓
   Отправка POST запроса к /conversation для получения conversationId
   ```
3. **Настройка параметров**:
   - Создается словарь `data` с настройками для запроса, включая принятие условий использования, выбор модели и включение поиска.
   - Отправляется POST-запрос к `/settings` для установки этих настроек.
   ```
       ↓
   Формирование данных запроса с параметрами модели
       ↓
   Отправка POST запроса к /conversation/{conversationId} с данными
   ```
4. **Получение `conversationId`**:
   - Отправляется POST-запрос к `/conversation` с указанием используемой модели.
   - Из ответа извлекается `conversationId`, который будет использоваться в последующих запросах.
   ```
       ↓
   Асинхронный перебор ответа от модели
       ↓
   Извлечение и фильтрация текстовых токенов
   ```
5. **Формирование данных для запроса**:
   - Создается словарь `data` с входными данными (`inputs`) в формате `messages`, параметрами модели (температура, максимальное количество токенов и т.д.) и опциями запроса (уникальные идентификаторы, настройки кэширования и т.д.).
   ```
       ↓
   Отправка DELETE запроса к /conversation/{conversationId} для завершения
       ↓
   Конец
   ```
6. **Отправка запроса и обработка ответа**:
   - Отправляется POST-запрос к `/conversation/{conversationId}` с данными запроса.
   - Асинхронно обрабатывается ответ от сервера, который приходит в виде потока данных.
   - Каждая строка ответа декодируется и проверяется на наличие префикса `data:`.
   - Если строка содержит данные, она преобразуется из JSON.
   - Извлекается текстовый фрагмент (`line["token"]["text"]`) и передается в генератор, если токен не является специальным (`not line["token"]["special"]`).

7. **Удаление разговора**:
   - После завершения обработки ответа отправляется DELETE-запрос к `/conversation/{conversationId}` для удаления разговора на сервере.

```mermaid
graph TD
    A[Начало] --> B(Установка параметров (модель, сообщения, прокси));
    B --> C(Инициализация ClientSession с заголовками);
    C --> D(Отправка POST запроса к /settings для принятия условий);
    D --> E(Отправка POST запроса к /conversation для получения conversationId);
    E --> F(Формирование данных запроса с параметрами модели);
    F --> G(Отправка POST запроса к /conversation/{conversationId} с данными);
    G --> H(Асинхронный перебор ответа от модели);
    H --> I{Извлечение и фильтрация текстовых токенов};
    I -- Да --> J(Выдача токена в генератор);
    I -- Нет --> H;
    J --> H;
    H --> K(Отправка DELETE запроса к /conversation/{conversationId} для завершения);
    K --> L(Конец);
```

**Примеры**:

```python
# Пример использования create_async_generator
messages = [{"role": "user", "content": "Hello, how are you?"}]
async def main():
    generator = await H2o.create_async_generator(model="h2oai/h2ogpt-gm-oasst1-en-2048-falcon-40b-v1", messages=messages)
    async for message in generator:
        print(message, end="")

# Запуск примера
# import asyncio
# asyncio.run(main())
```
```python
# Пример с указанием прокси
messages = [{"role": "user", "content": "Tell me a joke"}]
async def main():
    generator = await H2o.create_async_generator(model="h2oai/h2ogpt-gm-oasst1-en-2048-falcon-40b-v1", messages=messages, proxy="http://your-proxy:8080")
    async for message in generator:
        print(message, end="")

# Запуск примера
# import asyncio
# asyncio.run(main())
```
```python
# Пример с дополнительными параметрами
messages = [{"role": "user", "content": "Write a short story"}]
async def main():
    generator = await H2o.create_async_generator(model="h2oai/h2ogpt-gm-oasst1-en-2048-falcon-40b-v1", messages=messages, temperature=0.7, max_new_tokens=500)
    async for message in generator:
        print(message, end="")

# Запуск примера
# import asyncio
# asyncio.run(main())