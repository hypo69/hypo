# Модуль для работы с AiAsk (g4f)
## Обзор

Модуль `AiAsk` предоставляет асинхронный генератор для взаимодействия с сервисом aiask.me. Он поддерживает модели GPT-3.5 Turbo и позволяет вести историю сообщений. Этот модуль является частью пакета `g4f` и предназначен для использования в асинхронных приложениях.

## Подробней

Модуль предназначен для организации взаимодействия с сервисом AiAsk через асинхронные запросы. Он использует `aiohttp` для выполнения HTTP-запросов и предоставляет механизм для обработки потоковых ответов от сервера. Поддерживает прокси и позволяет настраивать температуру генерации текста.

## Классы

### `AiAsk`

**Описание**: Класс `AiAsk` предоставляет интерфейс для взаимодействия с сервисом aiask.me. Он наследует `AsyncGeneratorProvider` и реализует метод `create_async_generator` для создания асинхронного генератора, который отправляет запросы к сервису и возвращает ответы.

**Принцип работы**:
1.  При инициализации класса задаются URL, поддержка истории сообщений, поддержка GPT-3.5 Turbo и флаг `working`.
2.  Метод `create_async_generator` создает асинхронную сессию с заданными заголовками.
3.  Формируется JSON-запрос с сообщениями, моделью и параметрами.
4.  Отправляется POST-запрос к сервису aiask.me.
5.  Полученные чанки данных декодируются и возвращаются через генератор.
6.  Обрабатываются ошибки, такие как достижение лимита запросов.

**Методы**:

*   `create_async_generator`: Создает асинхронный генератор для взаимодействия с API.

## Функции

### `create_async_generator`

```python
    @classmethod
    async def create_async_generator(
        cls,
        model: str,
        messages: Messages,
        proxy: str = None,
        **kwargs
    ) -> AsyncResult:
        """
        Создает асинхронный генератор для взаимодействия с API aiask.me.

        Args:
            model (str): Модель для использования.
            messages (Messages): Список сообщений для отправки.
            proxy (str, optional): Адрес прокси-сервера. По умолчанию `None`.
            **kwargs: Дополнительные параметры, такие как температура.

        Returns:
            AsyncResult: Асинхронный генератор, возвращающий чанки текста ответа.

        Raises:
            RuntimeError: Если достигнут лимит запросов.

        Примеры:
            # Пример использования create_async_generator
            messages = [{"role": "user", "content": "Hello, how are you?"}]
            async for chunk in AiAsk.create_async_generator(model="gpt-3.5-turbo", messages=messages):
                print(chunk, end="")
        """
```

**Назначение**:
Функция `create_async_generator` создает асинхронный генератор, который отправляет сообщения к API `aiask.me` и возвращает ответы в виде чанков текста.

**Параметры**:

*   `cls`: Ссылка на класс `AiAsk`.
*   `model` (str): Имя модели, которую необходимо использовать для генерации ответа.
*   `messages` (Messages): Список сообщений, представляющих собой историю диалога. Каждое сообщение содержит роль (`user` или `assistant`) и содержимое.
*   `proxy` (str, optional): URL прокси-сервера, через который будет осуществляться подключение. По умолчанию `None`.
*   `**kwargs`: Дополнительные параметры, такие как `temperature`, которые можно передать в API.

**Возвращает**:

*   `AsyncResult`: Асинхронный генератор, который при каждой итерации возвращает часть ответа от API.

**Вызывает исключения**:

*   `RuntimeError`: Вызывается, если достигнут лимит запросов (`Rate limit reached`).

**Как работает функция**:

1.  Функция создает словарь `headers` с необходимыми HTTP-заголовками, включая `accept`, `origin` и `referer`.
2.  Создается асинхронная сессия `aiohttp.ClientSession` с использованием заданных заголовков.
3.  Формируется словарь `data`, который содержит параметры запроса, такие как история сообщений (`messages`), модель (`models`), и другие параметры, такие как `temperature`.
4.  Отправляется POST-запрос к API `aiask.me` с использованием асинхронной сессии и сформированных данных. Если указан `proxy`, он также используется при отправке запроса.
5.  Функция итерируется по чанкам данных, полученным из ответа сервера (`response.content.iter_any()`).
6.  Каждый чанк декодируется в строку и добавляется к буферу (`buffer`).
7.  Проверяется, не является ли текущий буфер началом сообщения об ограничении скорости (`rate_limit`).
8.  Если буфер не соответствует началу сообщения об ограничении скорости, он возвращается через генератор, и буфер очищается.
9.  Если буфер полностью соответствует сообщению об ограничении скорости, вызывается исключение `RuntimeError`.

**Примеры**:

```python
messages = [{"role": "user", "content": "Напиши Hello World на Python"}]
async for chunk in AiAsk.create_async_generator(model="gpt-3.5-turbo", messages=messages):
    print(chunk, end="")
```