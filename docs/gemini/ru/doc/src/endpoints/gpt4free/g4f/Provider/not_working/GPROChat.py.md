# Модуль GPROChat

## Обзор

Модуль `GPROChat` предназначен для взаимодействия с GPROChat API. Он предоставляет функциональность для генерации текста на основе предоставленных сообщений с использованием асинхронных генераторов. Модуль поддерживает потоковую передачу данных, сохранение истории сообщений и выбор различных моделей, таких как `gemini-1.5-pro`.

## Подробней

Модуль `GPROChat` является частью проекта `hypotez` и предназначен для работы с сервисом GPROChat, предоставляющим API для генерации текста. Он использует асинхронные запросы для взаимодействия с API и предоставляет возможность потоковой передачи данных, что позволяет получать результаты генерации текста по частям. Это особенно полезно для больших объемов данных, так как позволяет снизить нагрузку на память и улучшить пользовательский опыт. Модуль также поддерживает сохранение истории сообщений, что позволяет использовать контекст предыдущих сообщений для генерации более релевантных ответов.

## Классы

### `GPROChat`

**Описание**: Класс `GPROChat` предоставляет методы для взаимодействия с API GPROChat. Он наследуется от `AsyncGeneratorProvider` и `ProviderModelMixin`, что обеспечивает поддержку асинхронной генерации и выбор моделей.

**Наследует**:
- `AsyncGeneratorProvider`: Обеспечивает асинхронную генерацию данных.
- `ProviderModelMixin`: Предоставляет функциональность для выбора моделей.

**Атрибуты**:
- `url` (str): URL сервиса GPROChat (`https://gprochat.com`).
- `api_endpoint` (str): URL API для генерации текста (`https://gprochat.com/api/generate`).
- `working` (bool): Указывает, работает ли провайдер (в данном случае `False`).
- `supports_stream` (bool): Указывает, поддерживает ли провайдер потоковую передачу данных (`True`).
- `supports_message_history` (bool): Указывает, поддерживает ли провайдер историю сообщений (`True`).
- `default_model` (str): Модель, используемая по умолчанию (`gemini-1.5-pro`).

**Методы**:
- `generate_signature(timestamp: int, message: str) -> str`: Генерирует подпись для запроса к API.
- `create_async_generator(model: str, messages: Messages, proxy: str = None, **kwargs) -> AsyncResult`: Создает асинхронный генератор для получения данных от API.

## Функции

### `generate_signature`

```python
def generate_signature(timestamp: int, message: str) -> str:
    """Генерирует подпись для запроса к API GPROChat.

    Args:
        timestamp (int): Временная метка в миллисекундах.
        message (str): Сообщение для подписи.

    Returns:
        str: Сгенерированная подпись.
    """
    ...
```

**Назначение**: Функция `generate_signature` генерирует подпись для запроса к API GPROChat, используя алгоритм SHA256. Подпись используется для проверки подлинности запроса.

**Параметры**:
- `timestamp` (int): Временная метка в миллисекундах, используемая для генерации подписи.
- `message` (str): Сообщение, которое необходимо подписать.

**Возвращает**:
- `str`: Сгенерированная подпись в виде шестнадцатеричной строки.

**Как работает функция**:
1. Функция принимает временную метку и сообщение в качестве входных данных.
2. Определяется секретный ключ `secret_key`.
3. Формируется строка `hash_input` путем объединения временной метки, сообщения и секретного ключа через двоеточие.
4. Строка `hash_input` кодируется в UTF-8.
5. Вычисляется SHA256 хеш от закодированной строки.
6. Хеш преобразуется в шестнадцатеричную строку и возвращается.

```text
Начало --> Формирование hash_input (timestamp:message:secret_key) --> Кодирование в UTF-8 --> Вычисление SHA256 хеша --> Преобразование в hex --> Конец
```

**Примеры**:

```python
timestamp = int(time.time() * 1000)
message = "Test message"
signature = GPROChat.generate_signature(timestamp, message)
print(f"Signature: {signature}")
```

### `create_async_generator`

```python
@classmethod
async def create_async_generator(
    cls,
    model: str,
    messages: Messages,
    proxy: str = None,
    **kwargs
) -> AsyncResult:
    """Создает асинхронный генератор для получения данных от API GPROChat.

    Args:
        model (str): Модель для генерации текста.
        messages (Messages): Список сообщений для отправки в API.
        proxy (str, optional): URL прокси-сервера. По умолчанию `None`.

    Returns:
        AsyncResult: Асинхронный генератор, выдающий части сгенерированного текста.
    """
    ...
```

**Назначение**: Функция `create_async_generator` создает асинхронный генератор, который отправляет запрос к API GPROChat и возвращает части сгенерированного текста по мере их поступления.

**Параметры**:
- `model` (str): Модель, используемая для генерации текста.
- `messages` (Messages): Список сообщений, используемых в качестве входных данных для генерации текста.
- `proxy` (str, optional): URL прокси-сервера для использования при подключении к API. По умолчанию `None`.
- `**kwargs`: Дополнительные аргументы.

**Возвращает**:
- `AsyncResult`: Асинхронный генератор, выдающий части сгенерированного текста.

**Как работает функция**:
1. Функция принимает модель, список сообщений и URL прокси-сервера в качестве входных данных.
2. Получает модель с помощью `cls.get_model(model)`.
3. Генерирует временную метку `timestamp`.
4. Форматирует список сообщений в строку `prompt`.
5. Генерирует подпись `sign` с помощью функции `cls.generate_signature(timestamp, prompt)`.
6. Определяет заголовки `headers` для HTTP-запроса.
7. Формирует данные `data` для отправки в API.
8. Создает асинхронную сессию `ClientSession` с заданными заголовками.
9. Отправляет POST-запрос к API `cls.api_endpoint` с данными и прокси-сервером (если указан).
10. Получает ответ от API и итерируется по частям содержимого ответа.
11. Декодирует каждую часть содержимого и выдает ее через генератор.

```text
Начало --> Получение модели --> Генерация timestamp --> Форматирование prompt --> Генерация подписи --> Определение заголовков --> Формирование данных --> Создание асинхронной сессии --> Отправка POST-запроса --> Итерация по частям ответа --> Декодирование и выдача частей --> Конец
```

**Примеры**:

```python
messages = [{"role": "user", "content": "Hello, how are you?"}]
async for chunk in GPROChat.create_async_generator(model="gemini-1.5-pro", messages=messages):
    print(chunk, end="")