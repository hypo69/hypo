# Модуль `ToolBox_n_networks`

## Обзор

Модуль `ToolBox_n_networks.py` содержит класс `neural_networks`, который предоставляет методы для взаимодействия с различными нейронными сетями. 
В частности, он включает функции для генерации изображений с использованием модели FLUX.1-schnell и для взаимодействия с моделями Mistral и GPT-4o-mini для обработки текста.

## Подробней

Этот модуль обеспечивает абстракцию для работы с различными API нейронных сетей, упрощая интеграцию этих сервисов в проект `hypotez`. Он позволяет генерировать изображения на основе текстовых запросов и обрабатывать текстовые данные с использованием моделей машинного обучения.
Использование нескольких токенов авторизации (HF_TOKEN, MISTRAL_TOKEN, GIT_TOKEN) позволяет повысить отказоустойчивость при работе с API.

## Классы

### `neural_networks`

**Описание**:
Класс `neural_networks` предоставляет методы для взаимодействия с различными нейронными сетями.

**Как работает класс**:
Класс содержит методы для отправки запросов к различным API нейронных сетей и обработки ответов.
Он использует переменные окружения для хранения токенов авторизации и предоставляет интерфейс для генерации изображений и обработки текста.

**Методы**:
- `_FLUX_schnell`: Отправляет запрос к модели FLUX.1-schnell для генерации изображений.
- `__mistral_large_2407`: Отправляет запрос к модели Mistral для обработки текста.
- `_free_gpt_4o_mini`: Отправляет запрос к модели GPT-4o-mini для обработки текста.

## Функции

### `_FLUX_schnell`

```python
def _FLUX_schnell(self, prompt: str, size: list[int, int], seed: int, num_inference_steps: int) -> str|None:
    """
    Args:
        prompt (str): Текстовый запрос для генерации изображения.
        size (list[int, int]): Список с шириной и высотой изображения `[width, height]`.
        seed (int): Зерно для генерации случайных чисел.
        num_inference_steps (int): Количество шагов для генерации изображения.

    Returns:
        str | None: Объект `Image` с сгенерированным изображением или `None` в случае ошибки.
    """
```

**Описание**: Отправляет запрос к модели FLUX.1-schnell для генерации изображений на основе текстового запроса.

**Как работает функция**:
Функция формирует полезную нагрузку (payload) с параметрами запроса, включая текстовый запрос, размеры изображения, зерно и количество шагов для генерации.
Затем она отправляет POST-запрос к API FLUX.1-schnell, используя токен авторизации из переменных окружения.
Если запрос успешен (статус код 200), функция открывает изображение из полученного содержимого и возвращает его.

**Параметры**:
- `prompt` (str): Текстовый запрос для генерации изображения.
- `size` (list[int, int]): Список с шириной и высотой изображения `[width, height]`.
- `seed` (int): Зерно для генерации случайных чисел.
- `num_inference_steps` (int): Количество шагов для генерации изображения.

**Возвращает**:
- `str | None`: Объект `Image` с сгенерированным изображением или `None` в случае ошибки.

**Примеры**:

```python
# Пример вызова функции
image = neural_networks()._FLUX_schnell(prompt='a cat', size=[512, 512], seed=123, num_inference_steps=50)
if image:
    image.show()
```

### `__mistral_large_2407`

```python
def __mistral_large_2407(self, prompt: list[dict[str, str]]) -> tuple[str, int, int]|str:
    """
    Args:
        prompt (list[dict[str, str]]): Список сообщений для модели Mistral.

    Returns:
        tuple[str, int, int] | str: Кортеж с ответом модели, количеством использованных токенов для запроса и количеством использованных токенов для ответа или строку с ошибкой.
    """
```

**Описание**: Отправляет запрос к модели Mistral для обработки текста.

**Как работает функция**:
Функция формирует полезную нагрузку с сообщениями для модели Mistral, температурой, top_p, максимальным количеством токенов и названием модели.
Затем она отправляет POST-запрос к API Mistral, используя токен авторизации из переменных окружения.
Если запрос успешен (статус код 200), функция извлекает ответ модели, количество использованных токенов для запроса и количество использованных токенов для ответа и возвращает их.

**Параметры**:
- `prompt` (list[dict[str, str]]): Список сообщений для модели Mistral.

**Возвращает**:
- `tuple[str, int, int] | str`: Кортеж с ответом модели, количеством использованных токенов для запроса и количеством использованных токенов для ответа или строку с ошибкой.

**Примеры**:

```python
# Пример вызова функции
prompt = [{"role": "user", "content": "Translate to french: Hello, how are you?"}]
response, prompt_tokens, completion_tokens = neural_networks().__mistral_large_2407(prompt)
print(f"Response: {response}")
print(f"Prompt tokens: {prompt_tokens}")
print(f"Completion tokens: {completion_tokens}")
```

### `_free_gpt_4o_mini`

```python
def _free_gpt_4o_mini(self, prompt: list[dict[str, str]]) -> tuple[str, int, int]|str:
    """
    Args:
        prompt (list[dict[str, str]]): Список сообщений для модели GPT-4o-mini.

    Returns:
        tuple[str, int, int] | str: Кортеж с ответом модели, количеством использованных токенов для запроса и количеством использованных токенов для ответа или строку с ошибкой.
    """
```

**Описание**: Отправляет запрос к модели GPT-4o-mini для обработки текста.

**Как работает функция**:
Функция формирует полезную нагрузку с сообщениями для модели GPT-4o-mini, температурой, top_p, максимальным количеством токенов и названием модели.
Затем она пытается отправить POST-запрос к API GPT-4o-mini, используя токены авторизации из переменных окружения.
Если запрос успешен (статус код 200), функция извлекает ответ модели, количество использованных токенов для запроса и количество использованных токенов для ответа и возвращает их.
Если ни один из запросов не удался, функция вызывает метод `__mistral_large_2407` и возвращает его результат.

**Параметры**:
- `prompt` (list[dict[str, str]]): Список сообщений для модели GPT-4o-mini.

**Возвращает**:
- `tuple[str, int, int] | str`: Кортеж с ответом модели, количеством использованных токенов для запроса и количеством использованных токенов для ответа или строку с ошибкой.

**Примеры**:

```python
# Пример вызова функции
prompt = [{"role": "user", "content": "Write a short story about a cat."}]
response, prompt_tokens, completion_tokens = neural_networks()._free_gpt_4o_mini(prompt)
print(f"Response: {response}")
print(f"Prompt tokens: {prompt_tokens}")
print(f"Completion tokens: {completion_tokens}")