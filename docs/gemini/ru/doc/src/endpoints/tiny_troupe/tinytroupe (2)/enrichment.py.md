# Модуль для обогащения контента с использованием LLM
=====================================================

Модуль `enrichment.py` содержит класс `TinyEnricher`, который используется для обогащения контента с использованием больших языковых моделей (LLM). Он позволяет добавлять контекстную информацию и использовать прошлые результаты для улучшения качества обогащения.

Пример использования
----------------------

```python
enricher = TinyEnricher(use_past_results_in_context=True)
enriched_content = enricher.enrich_content(
    requirements="Добавить ключевые слова",
    content="Текст для обогащения",
    content_type="Описание продукта",
    context_info="Информация о контексте",
    context_cache=["Предыдущий результат"]
)
print(enriched_content)
```

## Обзор

Модуль предоставляет класс `TinyEnricher` для обогащения контента с использованием LLM. Класс позволяет настраивать использование прошлых результатов в контексте и предоставляет метод для обогащения контента на основе заданных требований, типа контента и контекстной информации.

## Подробнее

Этот модуль предназначен для использования в процессах, где требуется автоматическое обогащение контента, например, для улучшения описаний продуктов, добавления ключевых слов или генерации аннотаций.

## Классы

### `TinyEnricher`

**Описание**: Класс для обогащения контента с использованием больших языковых моделей.

**Принцип работы**:
1.  Инициализация класса с возможностью настройки использования прошлых результатов в контексте.
2.  Метод `enrich_content` принимает требования, контент, тип контента, контекстную информацию и кэш контекста.
3.  Формирует сообщения для LLM на основе шаблонов Mustache.
4.  Отправляет сообщения в LLM и получает результат.
5.  Извлекает кодовый блок из результата, если он есть.
6.  Возвращает обогащенный контент.

**Атрибуты**:

*   `use_past_results_in_context` (bool): Флаг, указывающий, следует ли использовать прошлые результаты в контексте.
*   `context_cache` (list): Список для хранения контекстной информации.

**Методы**:

*   `__init__(self, use_past_results_in_context=False)`: Инициализирует экземпляр класса `TinyEnricher`.
*   `enrich_content(self, requirements: str, content: str, content_type: str = None, context_info: str = "", context_cache: list = None, verbose: bool = False)`: Обогащает контент с использованием LLM.

## Функции

### `__init__`

```python
def __init__(self, use_past_results_in_context=False) -> None:
    """
    Инициализирует экземпляр класса TinyEnricher.

    Args:
        use_past_results_in_context (bool, optional): Флаг, указывающий, следует ли использовать прошлые результаты в контексте. По умолчанию False.

    Returns:
        None

    """
    ...
```

**Назначение**: Инициализация класса `TinyEnricher`.

**Параметры**:

*   `use_past_results_in_context` (bool, optional): Флаг, указывающий, следует ли использовать прошлые результаты в контексте. По умолчанию `False`.

**Возвращает**:

*   `None`

**Как работает функция**:

1.  Устанавливает значение атрибута `use_past_results_in_context` на основе переданного параметра.
2.  Инициализирует пустой список `context_cache` для хранения контекстной информации.

### `enrich_content`

```python
def enrich_content(self, requirements: str, content: str, content_type: str = None, context_info: str = "", context_cache: list = None, verbose: bool = False) -> str | None:
    """
    Обогащает контент с использованием LLM.

    Args:
        requirements (str): Требования к обогащению контента.
        content (str): Контент для обогащения.
        content_type (str, optional): Тип контента. По умолчанию None.
        context_info (str, optional): Контекстная информация. По умолчанию "".
        context_cache (list, optional): Кэш контекста. По умолчанию None.
        verbose (bool, optional): Флаг для вывода отладочной информации. По умолчанию False.

    Returns:
        str | None: Обогащенный контент или None, если не удалось обогатить.

    Raises:
        Exception: Если возникает ошибка при взаимодействии с LLM.

    """
    ...
```

**Назначение**: Обогащение контента с использованием больших языковых моделей.

**Параметры**:

*   `requirements` (str): Требования к обогащению контента.
*   `content` (str): Контент, который необходимо обогатить.
*   `content_type` (str, optional): Тип контента. По умолчанию `None`.
*   `context_info` (str, optional): Контекстная информация. По умолчанию `""`.
*   `context_cache` (list, optional): Кэш контекста. По умолчанию `None`.
*   `verbose` (bool, optional): Флаг для вывода отладочной информации. По умолчанию `False`.

**Возвращает**:

*   `str | None`: Обогащенный контент или `None`, если не удалось обогатить.

**Как работает функция**:

1.  Формирует словарь `rendering_configs`, содержащий требования, контент, тип контента, контекстную информацию и кэш контекста.
2.  Использует функцию `utils.compose_initial_LLM_messages_with_templates` для создания списка сообщений для LLM на основе шаблонов Mustache (`enricher.system.mustache` и `enricher.user.mustache`).
3.  Отправляет сообщения в LLM с помощью `openai_utils.client().send_message`, устанавливая температуру на 0.4.
4.  Логирует и, если указано, выводит отладочное сообщение, содержащее результат обогащения.
5.  Извлекает кодовый блок из результата с помощью `utils.extract_code_block`.
6.  Возвращает извлеченный кодовый блок или `None`, если сообщение от LLM отсутствует.

**ASCII flowchart**:

```
    Начало
    │
    └───> Формирование rendering_configs
    │
    └───> Создание сообщений для LLM с использованием шаблонов (compose_initial_LLM_messages_with_templates)
    │
    └───> Отправка сообщений в LLM (openai_utils.client().send_message)
    │
    └───> Логирование результата
    │
    └───> Извлечение кодового блока (extract_code_block)
    │
    └───> Возврат результата
    │
    Конец
```

**Примеры**:

```python
enricher = TinyEnricher()
enriched_content = enricher.enrich_content(
    requirements="Добавить ключевые слова: AI, машинное обучение",
    content="В этой статье рассматриваются новые методы в области искусственного интеллекта.",
    content_type="Статья",
    context_info="Опубликовано в журнале 'Искусственный интеллект и машинное обучение'",
    verbose=True
)
if enriched_content:
    print(f"Обогащенный контент: {enriched_content}")
else:
    print("Не удалось обогатить контент.")