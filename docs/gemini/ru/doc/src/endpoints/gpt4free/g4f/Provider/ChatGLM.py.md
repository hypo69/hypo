# Модуль ChatGLM

## Обзор

Модуль `ChatGLM.py` предоставляет асинхронную поддержку для взаимодействия с моделью ChatGLM. Он позволяет генерировать текст на основе предоставленных сообщений, используя API ChatGLM.

## Подробней

Этот модуль является частью проекта `hypotez` и предназначен для интеграции с другими компонентами, требующими функциональности ChatGLM. Он обеспечивает асинхронное взаимодействие с API ChatGLM, обрабатывает ответы в формате `text/event-stream` и возвращает сгенерированный текст.

## Классы

### `ChatGLM`

**Описание**: Класс `ChatGLM` является асинхронным провайдером, реализующим взаимодействие с API ChatGLM. Он поддерживает потоковую передачу данных, но не поддерживает системные сообщения и историю сообщений.

**Принцип работы**:

Класс использует `aiohttp.ClientSession` для отправки запросов к API ChatGLM. Он формирует запрос с необходимыми заголовками и данными, а затем асинхронно обрабатывает входящие чанки данных из потока ответов. Полученные данные декодируются и преобразуются в текст, который передается вызывающей стороне через асинхронный генератор.

**Методы**:

- `create_async_generator`: Асинхронный генератор, который отправляет запросы к API ChatGLM и возвращает сгенерированный текст.

## Функции

### `create_async_generator`

```python
    @classmethod
    async def create_async_generator(
        cls,
        model: str,
        messages: Messages,
        proxy: str = None,
        **kwargs
    ) -> AsyncResult:
        """
        Создает асинхронный генератор для взаимодействия с API ChatGLM.

        Args:
            model (str): Имя модели ChatGLM.
            messages (Messages): Список сообщений для отправки в API.
            proxy (str, optional): URL прокси-сервера. По умолчанию `None`.
            **kwargs: Дополнительные аргументы.

        Returns:
            AsyncResult: Асинхронный генератор, возвращающий сгенерированный текст.

        Как работает функция:
        1. Генерируется уникальный `device_id`.
        2. Определяются заголовки запроса, включая `Content-Type`, `User-Agent` и `X-Device-Id`.
        3. Формируется JSON-данные запроса, включая `assistant_id`, `conversation_id`, `meta_data` и `messages`.
        4. Отправляется POST-запрос к `cls.api_endpoint` с использованием `aiohttp.ClientSession`.
        5. Обрабатывается поток ответов, декодируются чанки данных и извлекается текстовое содержимое.
        6. Сгенерированный текст возвращается через `yield`.
        7. Если в ответе содержится статус `finish`, возвращается `FinishReason("stop")`.

        Внутри функции происходят следующие действия и преобразования:
        A. Генерация `device_id`.
        |
        B. Определение `headers` запроса.
        |
        C. Формирование `data` для запроса.
        |
        D. Отправка `POST` запроса к API ChatGLM.
        |
        E. Обработка `chunks` ответа.
        |
        F. Извлечение и возврат текста.

        Примеры:
        >>> async for text in ChatGLM.create_async_generator(model='glm-4', messages=[{'role': 'user', 'content': 'Hello'}]):
        ...     print(text)
        """