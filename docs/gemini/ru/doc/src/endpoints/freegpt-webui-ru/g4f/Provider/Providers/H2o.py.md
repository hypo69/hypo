# Модуль для работы с H2o API
=================================================

Модуль содержит функции для взаимодействия с API H2o для получения ответов от различных AI-моделей, таких как falcon-40b, falcon-7b и llama-13b.

## Обзор

Этот модуль предоставляет способ взаимодействия с API H2o для получения ответов от различных AI-моделей. Он включает в себя функцию `_create_completion`, которая отправляет запросы к API H2o и возвращает ответы в виде потока токенов. Модуль также определяет параметры для работы с API, такие как URL, список поддерживаемых моделей и флаги, указывающие на поддержку потоковой передачи и необходимость аутентификации.

## Подробней

Модуль предназначен для использования в проектах, требующих взаимодействия с API H2o для получения ответов от AI-моделей. Он предоставляет удобный интерфейс для отправки запросов и обработки ответов, а также обеспечивает поддержку потоковой передачи данных.

## Функции

### `_create_completion`

```python
def _create_completion(model: str, messages: list, stream: bool, **kwargs):
    """
    Создает запрос к API H2o и возвращает ответ в виде потока токенов.

    Args:
        model (str): Имя используемой модели.
        messages (list): Список сообщений в формате [{"role": "user" | "assistant", "content": str}].
        stream (bool): Флаг, указывающий, следует ли использовать потоковую передачу.
        **kwargs: Дополнительные параметры запроса, такие как температура, максимальное количество токенов и т.д.

    Returns:
        Generator[str, None, None]: Генератор токенов, полученных от API.

    Raises:
        Exception: В случае ошибки при выполнении запроса.

    """
```

**Назначение**:
Функция `_create_completion` отправляет запрос к API H2o и возвращает ответ в виде потока токенов.

**Параметры**:
- `model` (str): Имя используемой модели.
- `messages` (list): Список сообщений, представляющих собой историю разговора, где каждое сообщение имеет роль (`role`) и содержание (`content`).
- `stream` (bool): Флаг, определяющий, использовать ли потоковый режим для получения ответа.
- `**kwargs`: Дополнительные параметры запроса, такие как `temperature` (температура модели), `truncate` (максимальная длина входного текста), `max_new_tokens` (максимальное количество новых токенов в ответе), `do_sample` (флаг, указывающий, использовать ли дискретизацию), `repetition_penalty` (штраф за повторение токенов) и `return_full_text` (флаг, указывающий, возвращать ли полный текст).

**Возвращает**:
- `Generator[str, None, None]`: Генератор токенов, полученных от API.

**Вызывает исключения**:
- `Exception`: В случае ошибки при выполнении запроса.

**Как работает функция**:

1. **Формирование контекста разговора**: Функция начинает с формирования контекста разговора (`conversation`) на основе переданных сообщений (`messages`).

2. **Создание сессии**: Далее создается сессия (`client`) с использованием библиотеки `requests`.

3. **Настройка заголовков**: Устанавливаются необходимые заголовки для HTTP-запросов, включая `authority`, `origin`, `referer`, `sec-ch-ua`, `sec-ch-ua-mobile`, `sec-ch-ua-platform`, `sec-fetch-dest`, `sec-fetch-mode`, `sec-fetch-site`, `sec-fetch-user`, `upgrade-insecure-requests` и `user-agent`.

4. **Выполнение запроса к API**: Выполняется POST-запрос к API H2o с использованием сформированного контекста разговора и дополнительных параметров.

5. **Обработка потока ответов**: Функция итерируется по строкам ответа, полученного от API, и извлекает токены из каждой строки.

6. **Генерация токенов**: Каждый извлеченный токен передается в генератор, который возвращает его вызывающей стороне.

```
A: Формирование контекста разговора
│
B: Создание сессии и настройка заголовков
│
C: Выполнение POST-запроса к API H2o
│
D: Обработка потока ответов
│
E: Извлечение токенов из каждой строки
│
F: Генерация токенов
```

**Примеры**:

```python
# Пример вызова функции _create_completion
model_name = 'falcon-7b'
messages = [
    {'role': 'user', 'content': 'Привет! Как дела?'},
    {'role': 'assistant', 'content': 'Привет! У меня все хорошо, спасибо. А у тебя?'}
]
stream = True
kwargs = {'temperature': 0.7, 'max_new_tokens': 50}

# Вызов функции _create_completion
response_generator = _create_completion(model_name, messages, stream, **kwargs)

# Итерация по токенам, возвращаемым генератором
for token in response_generator:
    print(token, end='')