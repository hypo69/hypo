# Модуль H2o

## Обзор

Модуль `H2o.py` предоставляет возможность взаимодействия с AI-моделями, размещенными на платформе `gpt-gm.h2o.ai`. 
Он поддерживает модели `falcon-40b`, `falcon-7b` и `llama-13b` и позволяет генерировать ответы на основе предоставленных сообщений в формате диалога.

## Подробнее

Модуль предназначен для создания диалогов с AI-ассистентом, используя API `gpt-gm.h2o.ai`. Он настраивает сессию, отправляет сообщения и обрабатывает ответы в потоковом режиме. Модуль можно использовать для интеграции в различные приложения, требующие генерации текста на основе AI-моделей.
В данном коде не используются объекты webdriver

## Функции

### `_create_completion`

```python
def _create_completion(model: str, messages: list, stream: bool, **kwargs):
    """
    Создает запрос на завершение диалога к AI-модели на платформе h2o.ai.

    Args:
        model (str): Название модели для использования (например, 'falcon-40b').
        messages (list): Список сообщений в формате диалога, где каждое сообщение содержит 'role' (роль) и 'content' (содержание).
        stream (bool): Флаг, указывающий, следует ли использовать потоковый режим для получения ответа.
        **kwargs: Дополнительные параметры, такие как температура, максимальное количество новых токенов и т.д.

    Returns:
        Generator[str, None, None]: Генератор токенов, полученных от AI-модели в потоковом режиме.

    Raises:
        requests.exceptions.RequestException: В случае ошибки при выполнении HTTP-запроса.

    Как работает функция:
    1. Формирует строку `conversation` из списка сообщений, представляющую собой диалог между пользователем и AI-ассистентом.
    2. Создает HTTP-сессию с необходимыми заголовками.
    3. Выполняет GET-запрос к `https://gpt-gm.h2o.ai/` для инициализации сессии.
    4. Отправляет POST-запрос к `https://gpt-gm.h2o.ai/settings` для установки параметров сессии, таких как принятие этических норм и выбор активной модели.
    5. Отправляет POST-запрос к `https://gpt-gm.h2o.ai/conversation` для создания нового диалога и получения `conversationId`.
    6. Отправляет POST-запрос к `https://gpt-gm.h2o.ai/conversation/{conversationId}` с параметром `stream=True` для получения ответа в потоковом режиме.
    7. Итерируется по строкам ответа, декодирует каждую строку, извлекает текст токена и передает его через генератор.
    8. Завершает генерацию, если получен токен `<|endoftext|>`.

    Внутри функции происходят следующие действия и преобразования:
    Формирование диалога: Формируется строка `conversation` из списка сообщений для передачи в запросе.
    |
    -- Настройка HTTP-сессии: Создается и настраивается HTTP-сессия с необходимыми заголовками для взаимодействия с API.
    |
    Получение `conversationId`: Отправляется запрос для создания диалога и извлекается `conversationId` для последующих запросов.
    |
    Отправка запроса на completion: Отправляется POST-запрос с параметром `stream=True` для получения ответа в потоковом режиме.
    |
    Обработка потока токенов: Итерация по строкам ответа, декодирование, извлечение и генерация токенов до получения `<|endoftext|>`.

    Примеры:
        Пример 1: Генерация ответа с использованием модели 'falcon-7b' и минимальной температурой.
        >>> messages = [{'role': 'user', 'content': 'Hello, how are you?'}]
        >>> generator = _create_completion(model='falcon-7b', messages=messages, stream=True, temperature=0.1)
        >>> for token in generator:
        ...     print(token, end='')

        Пример 2: Генерация ответа с ограничением на максимальное количество новых токенов.
        >>> messages = [{'role': 'user', 'content': 'Tell me a story.'}]
        >>> generator = _create_completion(model='falcon-40b', messages=messages, stream=True, max_new_tokens=50)
        >>> for token in generator:
        ...     print(token, end='')

        Пример 3: Генерация ответа с использованием всех параметров по умолчанию.
        >>> messages = [{'role': 'user', 'content': 'What is the meaning of life?'}]
        >>> generator = _create_completion(model='llama-13b', messages=messages, stream=True)
        >>> for token in generator:
        ...     print(token, end='')
    """
    ...
```

### params

```python
params: str
```

Строка `params` содержит информацию о поддерживаемых типах параметров для функции `_create_completion`.

## Переменные

- `url (str)`: URL-адрес платформы `gpt-gm.h2o.ai`.
- `model (list)`: Список поддерживаемых моделей AI.
- `supports_stream (bool)`: Флаг, указывающий, поддерживается ли потоковый режим.
- `needs_auth (bool)`: Флаг, указывающий, требуется ли аутентификация.
- `models (dict)`: Словарь, сопоставляющий названия моделей с их идентификаторами на платформе `h2o.ai`.