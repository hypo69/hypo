# Модуль Ollama

## Обзор

Модуль `Ollama` предназначен для взаимодействия с локально установленными моделями Ollama. Он предоставляет функциональность для получения списка доступных моделей и создания асинхронных генераторов для работы с этими моделями. Модуль наследуется от класса `OpenaiAPI` и использует библиотеку `requests` для выполнения HTTP-запросов к API Ollama.

## Подробней

Модуль `Ollama` позволяет пользователям использовать локально развернутые модели Ollama для генерации текста. Это особенно полезно для тех, кто хочет иметь полный контроль над своими данными и вычислительными ресурсами. Для работы с модулем необходимо установить Ollama и убедиться, что API доступен по указанному адресу.

## Классы

### `Ollama`

**Описание**: Класс `Ollama` предоставляет интерфейс для взаимодействия с API Ollama.

**Наследует**: `OpenaiAPI`

**Атрибуты**:
- `label` (str): Метка, идентифицирующая провайдера как "Ollama".
- `url` (str): URL веб-сайта Ollama.
- `login_url` (None): URL для входа в систему (отсутствует, так как не требуется аутентификация).
- `needs_auth` (bool): Флаг, указывающий на необходимость аутентификации (равен `False`, так как не требуется аутентификация).
- `working` (bool): Флаг, указывающий на работоспособность провайдера (равен `True`).
- `models` (list): Список доступных моделей.
- `default_model` (str): Модель по умолчанию.

**Методы**:
- `get_models()`: Получает список доступных моделей Ollama.
- `create_async_generator()`: Создает асинхронный генератор для работы с моделями Ollama.

## Функции

### `get_models`

```python
@classmethod
def get_models(cls, api_base: str = None, **kwargs):
    """
    Получает список доступных моделей Ollama.

    Args:
        api_base (str, optional): Базовый URL API Ollama. По умолчанию `None`.
        **kwargs: Дополнительные аргументы.

    Returns:
        list: Список доступных моделей.
    """
    ...
```

**Назначение**: Получение списка доступных моделей от API Ollama.

**Параметры**:
- `cls` (type): Ссылка на класс.
- `api_base` (str, optional): Базовый URL API Ollama. Если не указан, используется значение из переменных окружения `OLLAMA_HOST` и `OLLAMA_PORT`. По умолчанию `None`.
- `**kwargs`: Дополнительные аргументы, которые могут быть переданы в функцию.

**Возвращает**:
- `list`: Список доступных моделей, полученных от API Ollama.

**Как работает функция**:

1. **Проверка наличия моделей в кэше**: Проверяет, был ли уже получен список моделей и сохранен в атрибуте `cls.models`.
2. **Определение URL API**: Если `api_base` не указан, формирует URL на основе переменных окружения `OLLAMA_HOST` и `OLLAMA_PORT`.
3. **Выполнение HTTP-запроса**: Выполняет GET-запрос к API Ollama для получения списка моделей.
4. **Обработка ответа**: Извлекает имена моделей из JSON-ответа и сохраняет их в `cls.models`.
5. **Установка модели по умолчанию**: Устанавливает первую модель из списка в качестве модели по умолчанию (`cls.default_model`).
6. **Возврат списка моделей**: Возвращает список доступных моделей.

```
A: Проверка cls.models
|
B: Определение URL API (из api_base или переменных окружения)
|
C: Выполнение GET-запроса к API Ollama
|
D: Извлечение имен моделей из JSON-ответа
|
E: Установка default_model
|
F: Возврат списка моделей
```

**Примеры**:

```python
# Пример вызова функции без указания api_base
models = Ollama.get_models()
print(models)  # Вывод: ['llama2', 'codellama', ...]

# Пример вызова функции с указанием api_base
models = Ollama.get_models(api_base="http://localhost:11434/v1")
print(models)  # Вывод: ['llama2', 'codellama', ...]
```

### `create_async_generator`

```python
@classmethod
def create_async_generator(
    cls,
    model: str,
    messages: Messages,
    api_base: str = None,
    **kwargs
) -> AsyncResult:
    """
    Создает асинхронный генератор для работы с моделями Ollama.

    Args:
        model (str): Название модели для использования.
        messages (Messages): Список сообщений для передачи в модель.
        api_base (str, optional): Базовый URL API Ollama. По умолчанию `None`.
        **kwargs: Дополнительные аргументы.

    Returns:
        AsyncResult: Асинхронный генератор для работы с моделью.
    """
    ...
```

**Назначение**: Создание асинхронного генератора для взаимодействия с API Ollama.

**Параметры**:
- `cls` (type): Ссылка на класс.
- `model` (str): Название модели, которую необходимо использовать для генерации текста.
- `messages` (Messages): Список сообщений, которые будут переданы в модель для генерации ответа.
- `api_base` (str, optional): Базовый URL API Ollama. Если не указан, используется значение из переменных окружения `OLLAMA_HOST` и `OLLAMA_PORT`. По умолчанию `None`.
- `**kwargs`: Дополнительные аргументы, которые могут быть переданы в функцию.

**Возвращает**:
- `AsyncResult`: Асинхронный генератор, который можно использовать для получения ответов от модели Ollama.

**Как работает функция**:

1. **Определение URL API**: Если `api_base` не указан, формирует URL на основе переменных окружения `OLLAMA_HOST` и `OLLAMA_PORT`.
2. **Вызов родительского метода**: Вызывает метод `create_async_generator` родительского класса `OpenaiAPI` с указанными параметрами.

```
A: Определение URL API (из api_base или переменных окружения)
|
B: Вызов super().create_async_generator()
|
C: Возврат AsyncResult
```

**Примеры**:

```python
# Пример вызова функции
messages = [{"role": "user", "content": "Привет, как дела?"}]
generator = Ollama.create_async_generator(model="llama2", messages=messages)

# Пример использования генератора (предполагается, что AsyncResult - это асинхронный генератор)
# async for response in generator:
#     print(response)