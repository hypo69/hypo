# Модуль `crawlee_python`

## Обзор

Этот модуль предоставляет класс `CrawleePython` для управления веб-скрапингом с помощью Playwright.  Класс позволяет настроить параметры сканирования, запустить сканирование с заданными URL-адресами, экспортировать собранные данные в JSON-файл и получить доступ к собранным данным.

## Классы

### `CrawleePython`

**Описание**: Класс для управления веб-скрапингом с использованием Playwright.

**Методы**:

#### `__init__(self, max_requests: int = 5, headless: bool = False, browser_type: str = 'firefox')`

**Описание**: Инициализирует экземпляр `CrawleePython` с заданными параметрами.

**Параметры**:

- `max_requests` (int, по умолчанию 5): Максимальное количество запросов для каждого сканирования.
- `headless` (bool, по умолчанию False): Флаг, определяющий работу браузера в фоновом режиме (True) или в обычном режиме (False).
- `browser_type` (str, по умолчанию 'firefox'): Тип браузера для использования (например, 'chromium', 'firefox').


#### `setup_crawler(self)`

**Описание**: Настраивает экземпляр `PlaywrightCrawler`.

**Возвращает**:  None.


#### `run_crawler(self, urls: list[str])`

**Описание**: Запускает сканирование с заданным списком URL-адресов.

**Параметры**:

- `urls` (list[str]): Список URL-адресов для начала сканирования.

**Возвращает**:  None.


#### `export_data(self, file_path: str)`

**Описание**: Экспортирует собранные данные в JSON-файл.

**Параметры**:

- `file_path` (str): Путь к файлу для сохранения экспортированных данных в формате JSON.

**Возвращает**:  None.


#### `get_data(self) -> dict`

**Описание**: Получает собранные данные.

**Возвращает**: dict: Собранные данные в формате словаря.


#### `run(self, urls: list[str])`

**Описание**: Основной метод для настройки, запуска сканирования и экспорта данных.

**Параметры**:

- `urls` (list[str]): Список URL-адресов для начала сканирования.

**Возвращает**:  None.



## Функции

(В этом модуле нет функций, кроме тех, которые определены в классах)


## Пример использования

```python
if __name__ == '__main__':
    async def main():
        experiment = CrawleePython(max_requests=5, headless=False, browser_type='firefox')
        await experiment.run(['https://ksp.co.il'])

    asyncio.run(main())
```

Этот пример демонстрирует использование класса `CrawleePython` для сканирования сайта `https://ksp.co.il` с параметрами по умолчанию.  Обратите внимание на использование `asyncio.run()` для асинхронного выполнения кода.