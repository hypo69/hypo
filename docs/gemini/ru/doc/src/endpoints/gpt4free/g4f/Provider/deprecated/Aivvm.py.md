# Модуль `Aivvm.py`

## Обзор

Модуль `Aivvm.py` предоставляет класс `Aivvm`, который является провайдером для взаимодействия с API Aivvm. Он позволяет создавать запросы к моделям, поддерживаемым Aivvm, таким как GPT-3.5 и GPT-4. Модуль предназначен для использования в проекте `hypotez` для обеспечения доступа к различным языковым моделям.

## Подробнее

Модуль содержит класс `Aivvm`, который наследуется от `AbstractProvider`. Он определяет параметры подключения к API Aivvm и методы для отправки запросов.

## Классы

### `Aivvm(AbstractProvider)`

Описание: Класс `Aivvm` является провайдером для работы с API Aivvm. Он наследуется от `AbstractProvider` и реализует методы для отправки запросов к API.

**Наследует**:
- `AbstractProvider`: Абстрактный класс, определяющий интерфейс для всех провайдеров.

**Атрибуты**:
- `url` (str): URL-адрес API Aivvm.
- `supports_stream` (bool): Флаг, указывающий, поддерживает ли провайдер потоковую передачу данных.
- `working` (bool): Флаг, указывающий, работает ли провайдер в данный момент.
- `supports_gpt_35_turbo` (bool): Флаг, указывающий, поддерживает ли провайдер модель GPT-3.5 Turbo.
- `supports_gpt_4` (bool): Флаг, указывающий, поддерживает ли провайдер модель GPT-4.

**Методы**:
- `create_completion`: Создает запрос к API Aivvm и возвращает результат.

## Функции

### `create_completion(model: str, messages: Messages, stream: bool, **kwargs) -> CreateResult`

**Назначение**: Создает запрос к API Aivvm для получения ответа от языковой модели.

**Параметры**:
- `model` (str): Идентификатор модели, которую необходимо использовать.
- `messages` (Messages): Список сообщений, составляющих контекст запроса.
- `stream` (bool): Флаг, указывающий, следует ли использовать потоковую передачу данных.
- `**kwargs`: Дополнительные параметры запроса, такие как `system_message` и `temperature`.

**Возвращает**:
- `CreateResult`: Результат запроса к API.

**Вызывает исключения**:
- `ValueError`: Если указанная модель не поддерживается.

**Как работает функция**:

1.  **Выбор модели**: Если модель не указана, используется модель "gpt-3.5-turbo". Проверяется, поддерживается ли указанная модель. Если модель не найдена в списке поддерживаемых моделей, вызывается исключение `ValueError`.
2.  **Подготовка данных**: Формируется словарь `json_data`, содержащий информацию о модели, сообщениях, ключе, системном сообщении и температуре. Системное сообщение по умолчанию: "You are ChatGPT, a large language model trained by OpenAI. Follow the user's instructions carefully. Respond using markdown."
3.  **Преобразование данных в JSON**: Словарь `json_data` преобразуется в строку JSON с помощью `json.dumps()`.
4.  **Формирование заголовков**: Создается словарь `headers`, содержащий заголовки HTTP-запроса. Указываются параметры, такие как `accept`, `content-type`, `user-agent` и другие.
5.  **Отправка запроса**: Отправляется POST-запрос к API Aivvm по адресу `https://chat.aivvm.com/api/chat` с использованием библиотеки `requests`. Передаются заголовки и данные JSON.
6.  **Обработка ответа**: Обрабатывается ответ от API Aivvm. Используется потоковая передача данных, если она поддерживается. Результат возвращается в виде генератора.
7.  **Декодирование чанков**: Каждый чанк данных декодируется из формата "utf-8". В случае ошибки `UnicodeDecodeError` применяется декодирование "unicode-escape".

```
    Выбор модели
    │
    ├── Проверка модели (поддерживается ли)
    │   └── Генерация ValueError если модель не поддерживается
    │
    └── Подготовка данных (json_data)
        │
        └── Преобразование в JSON (data)
            │
            └── Формирование заголовков (headers)
                │
                └── Отправка POST запроса (response)
                    │
                    └── Обработка ответа (chunk)
                        │
                        └── Декодирование (utf-8)
                            │
                            └── Генерация результата
```

**Примеры**:

```python
# Пример вызова функции create_completion с минимальными параметрами
result = Aivvm.create_completion(model="gpt-3.5-turbo", messages=[{"role": "user", "content": "Hello"}], stream=False)

# Пример вызова функции create_completion с указанием системного сообщения и температуры
result = Aivvm.create_completion(model="gpt-4", messages=[{"role": "user", "content": "Translate to French: Hello"}], stream=True, system_message="You are a translator.", temperature=0.9)
```