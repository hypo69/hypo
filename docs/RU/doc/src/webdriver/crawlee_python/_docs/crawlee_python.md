# Модуль crawlee_python

## Обзор

Этот модуль предоставляет класс `CrawleePython` для выполнения веб-скрейпинга с использованием библиотеки `crawlee` и фреймворка Playwright.  Класс позволяет настроить веб-скрейпер, извлечь данные с веб-страниц, и экспортировать собранные данные в файл JSON.

## Классы

### `CrawleePython`

**Описание**:  Класс `CrawleePython` отвечает за инициализацию, настройку и запуск процесса веб-скрейпинга. Он использует `PlaywrightCrawler` для управления запросами и извлечением данных.

**Методы**:

#### `__init__(max_requests: int, headless: bool = True, browser_type: str = 'chromium')`

**Описание**: Конструктор класса. Инициализирует экземпляр `PlaywrightCrawler` с заданными параметрами.

**Параметры**:

- `max_requests` (int): Максимальное количество запросов, выполняемых при выполнении скрейпинга.
- `headless` (bool, по умолчанию `True`): Флаг, указывающий, запускать ли браузер в бесклеточном режиме (без графического интерфейса).
- `browser_type` (str, по умолчанию `'chromium'`): Тип браузера, который будет использован (например, 'chromium', 'firefox').


#### `setup_crawler()`

**Описание**: Настраивает веб-скрейпер, определяя обработчик запросов по умолчанию. Обработчик обрабатывает каждый запрос, извлекает данные со страницы и добавляет ссылки для дальнейшего скрейпинга.

**Возвращает**:
- `None`

#### `run_crawler(urls: list)`

**Описание**: Запускает процесс скрейпинга с указанным списком начальных URL.

**Параметры**:

- `urls` (list): Список начальных URL для начала скрейпинга.

**Возвращает**:
- `None`

#### `export_data(filename: str)`

**Описание**: Экспортирует собранные данные в файл JSON.

**Параметры**:

- `filename` (str): Имя файла для экспорта данных (с расширением `.json`).

**Возвращает**:
- `None`

#### `get_data()`

**Описание**: Возвращает собранные данные в виде словаря.

**Возвращает**:
- `dict`: Словарь с извлечёнными данными.


#### `run()`

**Описание**: Главная функция запуска. Инициализирует скрейпер, настраивает его, выполняет скрейпинг, экспортирует данные и выводит собранные данные.

**Параметры**:
- Нет

**Возвращает**:
- `None`


## Пример использования

```python
# Пример использования класса CrawleePython
from crawlee_python import CrawleePython
import asyncio
import os


async def main():
    crawler = CrawleePython(max_requests=10, headless=False, browser_type='chromium')
    await crawler.run(urls=['https://news.ycombinator.com/'])

if __name__ == '__main__':
    asyncio.run(main())
```

**Примечание**: Для работы данного кода, необходимо установить необходимые библиотеки, такие как `crawlee`, `playwright`, и т.д.
```